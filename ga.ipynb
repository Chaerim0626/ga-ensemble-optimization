{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GA RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def roulette_wheel_selection(population, fitness_scores):\n",
    "    \"\"\"\n",
    "    룰렛 휠 선택 방식으로 부모 개체를 선택\n",
    "    Args:\n",
    "        population: 현재 개체군 (가중치 배열)\n",
    "        fitness_scores: 각 개체의 RMSE (낮을수록 좋음)\n",
    "    Returns:\n",
    "        선택된 부모 개체\n",
    "    \"\"\"\n",
    "    fitness_list = []\n",
    "    max_fitness = max(fitness_scores)\n",
    "    min_fitness = min(fitness_scores)\n",
    "    adjustment = (max_fitness - min_fitness) / 2 if max_fitness != min_fitness else 1  # 조정 값\n",
    "\n",
    "    for m in range(len(fitness_scores)):\n",
    "        # fitness 계산\n",
    "        fitness = max_fitness - fitness_scores[m] + adjustment\n",
    "        fitness_list.append(fitness)\n",
    "\n",
    "    fitness_list = np.array(fitness_list)\n",
    "    total_fitness = np.sum(fitness_list)\n",
    "\n",
    "    # total_fitness가 0인 경우 예외 처리\n",
    "    if total_fitness == 0:\n",
    "        raise ValueError(\"Total fitness is 0, cannot calculate probabilities.\")\n",
    "\n",
    "    probabilities = fitness_list / total_fitness\n",
    "\n",
    "    # 룰렛 휠 방식으로 부모 선택\n",
    "    selected_index = np.random.choice(len(population), p=probabilities)\n",
    "    return population[selected_index]\n",
    "\n",
    "\n",
    "def genetic_algorithm_with_elitism(model_predictions, true_values, population_size=100, generations=100, mutation_rate=0.03):\n",
    "    \"\"\"\n",
    "    GA를 사용하여 최적의 가중치 찾기\n",
    "    Args:\n",
    "        model_predictions: (n_samples, models, time_window, 2) 형태의 모델 예측값\n",
    "        true_values: (n_samples, time_window, 2) 형태의 실제값\n",
    "        population_size: 초기 개체군 크기\n",
    "        generations: 세대 수\n",
    "        mutation_rate: 돌연변이 확률\n",
    "    Returns:\n",
    "        최적 가중치 배열\n",
    "    \"\"\"\n",
    "    num_models = model_predictions.shape[1]  # 모델 수\n",
    "    population = np.random.dirichlet(np.ones(num_models), size=population_size)  # 초기 가중치 개체군\n",
    "\n",
    "    for generation in range(generations):\n",
    "        fitness_scores = []\n",
    "\n",
    "        # 현재 population의 fitness (RMSE) 계산\n",
    "        for individual in population:\n",
    "            ensemble_prediction = np.sum(\n",
    "                [weight * model_predictions[:, i, :, :] for i, weight in enumerate(individual)],\n",
    "                axis=0\n",
    "            )\n",
    "            rmse = np.sqrt(np.mean((true_values - ensemble_prediction) ** 2))\n",
    "            fitness_scores.append(rmse)\n",
    "        \n",
    "        fitness_scores = np.array(fitness_scores)\n",
    "\n",
    "        # 새로운 population 생성\n",
    "        new_population = []\n",
    "        while len(new_population) < population_size:\n",
    "            # 부모 선택\n",
    "            parent1 = roulette_wheel_selection(population, fitness_scores)\n",
    "            parent2 = roulette_wheel_selection(population, fitness_scores)\n",
    "\n",
    "            # 교차 연산\n",
    "            crossover_point = np.random.randint(1, num_models)\n",
    "            child = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))\n",
    "\n",
    "            # 돌연변이\n",
    "            if np.random.rand() < mutation_rate:\n",
    "                mutation_vector = np.random.normal(0, 0.1, size=num_models)\n",
    "                child = np.clip(child + mutation_vector, 0, 1)\n",
    "\n",
    "            # 정규화\n",
    "            child = child / np.sum(child)\n",
    "            new_population.append(child)\n",
    "        \n",
    "        new_population = np.array(new_population)\n",
    "\n",
    "        # 엘리티즘 적용\n",
    "        combined_population = np.vstack((population, new_population))\n",
    "        combined_fitness = np.concatenate((fitness_scores, np.zeros(len(new_population))))\n",
    "\n",
    "        for idx, individual in enumerate(new_population):\n",
    "            ensemble_prediction = np.sum(\n",
    "                [weight * model_predictions[:, i, :, :] for i, weight in enumerate(individual)],\n",
    "                axis=0\n",
    "            )\n",
    "            combined_fitness[len(fitness_scores) + idx] = np.sqrt(np.mean((true_values - ensemble_prediction) ** 2))\n",
    "\n",
    "        sorted_indices = np.argsort(combined_fitness)\n",
    "        population = combined_population[sorted_indices][:population_size]\n",
    "\n",
    "        print(f\"Generation {generation + 1}/{generations}, Best RMSE: {combined_fitness[sorted_indices][0]}\")\n",
    "\n",
    "    # 최적 개체 반환\n",
    "    best_weights = population[0]\n",
    "    print(f\"Optimal Weights: {best_weights}\")\n",
    "    return best_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def load_and_process_validation_data(input_directory, month, models=5, time_window=48):\n",
    "    model_predictions = []  # 각 모델의 예측값 저장\n",
    "\n",
    "    for model_idx in range(1, models + 1):\n",
    "        model_dir = os.path.join(input_directory, f\"model{model_idx}\")\n",
    "        file_path = os.path.join(model_dir, f'val_month_{month}_model_{model_idx}_results.csv')\n",
    "\n",
    "        # 🔍 파일 존재 여부 확인\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"파일이 존재하지 않습니다: {file_path}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"CSV 파일을 읽는 중 오류 발생: {file_path}, 오류: {e}\")\n",
    "            continue\n",
    "\n",
    "        # 🔍 컬럼 존재 여부 확인\n",
    "        pred_u_col = f\"Model {model_idx} Val Pred U\"\n",
    "        pred_v_col = f\"Model {model_idx} Val Pred V\"\n",
    "\n",
    "        if pred_u_col not in df.columns or pred_v_col not in df.columns:\n",
    "            print(f\"예측 컬럼이 존재하지 않습니다: {pred_u_col}, {pred_v_col}\")\n",
    "            continue\n",
    "\n",
    "        pred_u = df[pred_u_col].values\n",
    "        pred_v = df[pred_v_col].values\n",
    "\n",
    "        # True 값은 모델 1에서만 추출\n",
    "        if model_idx == 1:\n",
    "            if \"True U\" not in df.columns or \"True V\" not in df.columns:\n",
    "                print(f\"True 값 컬럼이 존재하지 않습니다.\")\n",
    "                continue\n",
    "\n",
    "            true_u = df[\"True U\"].values\n",
    "            true_v = df[\"True V\"].values\n",
    "\n",
    "        # 🔍 데이터 길이 확인 및 예외 처리\n",
    "        n_samples = len(pred_u) // time_window\n",
    "        if n_samples == 0:\n",
    "            print(f\"{file_path}: 데이터가 부족합니다. (데이터 길이: {len(pred_u)})\")\n",
    "            continue\n",
    "\n",
    "        pred_u = np.array(pred_u[:n_samples * time_window]).reshape(n_samples, time_window, 1)\n",
    "        pred_v = np.array(pred_v[:n_samples * time_window]).reshape(n_samples, time_window, 1)\n",
    "        model_predictions.append(np.concatenate([pred_u, pred_v], axis=2))  # (n_samples, 48, 2)\n",
    "\n",
    "        # True 값 병합 (한 번만 실행)\n",
    "        if model_idx == 1:\n",
    "            true_u = np.array(true_u[:n_samples * time_window]).reshape(n_samples, time_window, 1)\n",
    "            true_v = np.array(true_v[:n_samples * time_window]).reshape(n_samples, time_window, 1)\n",
    "            true_values = np.concatenate([true_u, true_v], axis=2)  # (n_samples, 48, 2)\n",
    "\n",
    "    # 🔍 예측값이 없는 경우 예외 처리\n",
    "    if not model_predictions:\n",
    "        print(f\"{month}월: 모델 예측값이 없습니다.\")\n",
    "        return np.array([]), np.array([])\n",
    "\n",
    "    # 🔍 모델 예측값 형태 변환: (n_samples, models, 48, 2)\n",
    "    try:\n",
    "        model_predictions = np.stack(model_predictions, axis=1)\n",
    "    except ValueError as e:\n",
    "        print(f\"모델 예측값 병합 중 오류 발생: {e}\")\n",
    "        return np.array([]), np.array([])\n",
    "\n",
    "    return model_predictions, true_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 5, 48, 2) (25, 48, 2)\n",
      "Generation 1/100, Best RMSE: 2.2776612552401785\n",
      "Generation 2/100, Best RMSE: 2.2766196785739576\n",
      "Generation 3/100, Best RMSE: 2.2760045730339993\n",
      "Generation 4/100, Best RMSE: 2.2754268155036628\n",
      "Generation 5/100, Best RMSE: 2.2752889030020236\n",
      "Generation 6/100, Best RMSE: 2.2752768751689527\n",
      "Generation 7/100, Best RMSE: 2.2752690786487415\n",
      "Generation 8/100, Best RMSE: 2.2752387204168287\n",
      "Generation 9/100, Best RMSE: 2.275173768291438\n",
      "Generation 10/100, Best RMSE: 2.2750043261809787\n",
      "Generation 11/100, Best RMSE: 2.274799034176094\n",
      "Generation 12/100, Best RMSE: 2.2747788565662983\n",
      "Generation 13/100, Best RMSE: 2.2747728535766076\n",
      "Generation 14/100, Best RMSE: 2.2747652134862117\n",
      "Generation 15/100, Best RMSE: 2.2747587421148094\n",
      "Generation 16/100, Best RMSE: 2.274710212113445\n",
      "Generation 17/100, Best RMSE: 2.274710212113445\n",
      "Generation 18/100, Best RMSE: 2.274710212113445\n",
      "Generation 19/100, Best RMSE: 2.2747055744470415\n",
      "Generation 20/100, Best RMSE: 2.2747054174303045\n",
      "Generation 21/100, Best RMSE: 2.2747054174303045\n",
      "Generation 22/100, Best RMSE: 2.2747048720037486\n",
      "Generation 23/100, Best RMSE: 2.2747039271880354\n",
      "Generation 24/100, Best RMSE: 2.274703452537821\n",
      "Generation 25/100, Best RMSE: 2.27470318722504\n",
      "Generation 26/100, Best RMSE: 2.274702759352386\n",
      "Generation 27/100, Best RMSE: 2.274702300391525\n",
      "Generation 28/100, Best RMSE: 2.274702300391525\n",
      "Generation 29/100, Best RMSE: 2.2747020340982687\n",
      "Generation 30/100, Best RMSE: 2.2747020340982687\n",
      "Generation 31/100, Best RMSE: 2.2747019775550084\n",
      "Generation 32/100, Best RMSE: 2.274701922841517\n",
      "Generation 33/100, Best RMSE: 2.2747017977369075\n",
      "Generation 34/100, Best RMSE: 2.2747016579081825\n",
      "Generation 35/100, Best RMSE: 2.2747016579081825\n",
      "Generation 36/100, Best RMSE: 2.2747016579081825\n",
      "Generation 37/100, Best RMSE: 2.274701645733942\n",
      "Generation 38/100, Best RMSE: 2.274701612919849\n",
      "Generation 39/100, Best RMSE: 2.2747015429007202\n",
      "Generation 40/100, Best RMSE: 2.2747015429007202\n",
      "Generation 41/100, Best RMSE: 2.2747015373162953\n",
      "Generation 42/100, Best RMSE: 2.274701486216622\n",
      "Generation 43/100, Best RMSE: 2.274701461044686\n",
      "Generation 44/100, Best RMSE: 2.2747013965472065\n",
      "Generation 45/100, Best RMSE: 2.2747013965472065\n",
      "Generation 46/100, Best RMSE: 2.274701358115091\n",
      "Generation 47/100, Best RMSE: 2.274701321484983\n",
      "Generation 48/100, Best RMSE: 2.2747012978215566\n",
      "Generation 49/100, Best RMSE: 2.2747012910335793\n",
      "Generation 50/100, Best RMSE: 2.2747012910335793\n",
      "Generation 51/100, Best RMSE: 2.2747012910335793\n",
      "Generation 52/100, Best RMSE: 2.2747012910335793\n",
      "Generation 53/100, Best RMSE: 2.2747012910335793\n",
      "Generation 54/100, Best RMSE: 2.2747012877358292\n",
      "Generation 55/100, Best RMSE: 2.2747012836638953\n",
      "Generation 56/100, Best RMSE: 2.274701278555191\n",
      "Generation 57/100, Best RMSE: 2.274701278555191\n",
      "Generation 58/100, Best RMSE: 2.2747012743553445\n",
      "Generation 59/100, Best RMSE: 2.2747012679573597\n",
      "Generation 60/100, Best RMSE: 2.2747012636525787\n",
      "Generation 61/100, Best RMSE: 2.2747012635131942\n",
      "Generation 62/100, Best RMSE: 2.2747012635131942\n",
      "Generation 63/100, Best RMSE: 2.2747012635131942\n",
      "Generation 64/100, Best RMSE: 2.2747012635131942\n",
      "Generation 65/100, Best RMSE: 2.2747012635131942\n",
      "Generation 66/100, Best RMSE: 2.2747012635131942\n",
      "Generation 67/100, Best RMSE: 2.2747012621591898\n",
      "Generation 68/100, Best RMSE: 2.2747012621591898\n",
      "Generation 69/100, Best RMSE: 2.2747012621591898\n",
      "Generation 70/100, Best RMSE: 2.2747012621591898\n",
      "Generation 71/100, Best RMSE: 2.2747012621591898\n",
      "Generation 72/100, Best RMSE: 2.2747012615146893\n",
      "Generation 73/100, Best RMSE: 2.2747012615146893\n",
      "Generation 74/100, Best RMSE: 2.2747012611802733\n",
      "Generation 75/100, Best RMSE: 2.2747012610748656\n",
      "Generation 76/100, Best RMSE: 2.2747012608302715\n",
      "Generation 77/100, Best RMSE: 2.2747012606286834\n",
      "Generation 78/100, Best RMSE: 2.2747012604135928\n",
      "Generation 79/100, Best RMSE: 2.2747012604135928\n",
      "Generation 80/100, Best RMSE: 2.2747012603606915\n",
      "Generation 81/100, Best RMSE: 2.2747012602222423\n",
      "Generation 82/100, Best RMSE: 2.2747012600319207\n",
      "Generation 83/100, Best RMSE: 2.2747012600319207\n",
      "Generation 84/100, Best RMSE: 2.274701259921525\n",
      "Generation 85/100, Best RMSE: 2.274701259921525\n",
      "Generation 86/100, Best RMSE: 2.27470125981776\n",
      "Generation 87/100, Best RMSE: 2.2747012596230234\n",
      "Generation 88/100, Best RMSE: 2.2747012596230234\n",
      "Generation 89/100, Best RMSE: 2.2747012594978657\n",
      "Generation 90/100, Best RMSE: 2.2747012594325726\n",
      "Generation 91/100, Best RMSE: 2.2747012594263976\n",
      "Generation 92/100, Best RMSE: 2.2747012593732374\n",
      "Generation 93/100, Best RMSE: 2.2747012593732374\n",
      "Generation 94/100, Best RMSE: 2.274701259289901\n",
      "Generation 95/100, Best RMSE: 2.2747012591845452\n",
      "Generation 96/100, Best RMSE: 2.2747012591804854\n",
      "Generation 97/100, Best RMSE: 2.274701259085478\n",
      "Generation 98/100, Best RMSE: 2.274701259085478\n",
      "Generation 99/100, Best RMSE: 2.274701259085478\n",
      "Generation 100/100, Best RMSE: 2.274701259085478\n",
      "Optimal Weights: [0.57055253 0.         0.01078756 0.16910843 0.24955148]\n",
      "(28, 5, 48, 2) (28, 48, 2)\n",
      "Generation 1/100, Best RMSE: 2.18922442657838\n",
      "Generation 2/100, Best RMSE: 2.157276972614986\n",
      "Generation 3/100, Best RMSE: 2.157276972614986\n",
      "Generation 4/100, Best RMSE: 2.1565703879510445\n",
      "Generation 5/100, Best RMSE: 2.1565703879510445\n",
      "Generation 6/100, Best RMSE: 2.1561170376800827\n",
      "Generation 7/100, Best RMSE: 2.1556561495388915\n",
      "Generation 8/100, Best RMSE: 2.1556561495388915\n",
      "Generation 9/100, Best RMSE: 2.1556521931824646\n",
      "Generation 10/100, Best RMSE: 2.155349781637895\n",
      "Generation 11/100, Best RMSE: 2.1551821970720444\n",
      "Generation 12/100, Best RMSE: 2.155153189351073\n",
      "Generation 13/100, Best RMSE: 2.1551516333878293\n",
      "Generation 14/100, Best RMSE: 2.1550118533255302\n",
      "Generation 15/100, Best RMSE: 2.15500955934473\n",
      "Generation 16/100, Best RMSE: 2.15500955934473\n",
      "Generation 17/100, Best RMSE: 2.15500955934473\n",
      "Generation 18/100, Best RMSE: 2.155002299759682\n",
      "Generation 19/100, Best RMSE: 2.15499857915235\n",
      "Generation 20/100, Best RMSE: 2.154997489962672\n",
      "Generation 21/100, Best RMSE: 2.1549935965066824\n",
      "Generation 22/100, Best RMSE: 2.154992735563196\n",
      "Generation 23/100, Best RMSE: 2.154992665544262\n",
      "Generation 24/100, Best RMSE: 2.154992665544262\n",
      "Generation 25/100, Best RMSE: 2.1549926528012335\n",
      "Generation 26/100, Best RMSE: 2.1549926528012335\n",
      "Generation 27/100, Best RMSE: 2.1549926409455047\n",
      "Generation 28/100, Best RMSE: 2.154992597992649\n",
      "Generation 29/100, Best RMSE: 2.1549924199244255\n",
      "Generation 30/100, Best RMSE: 2.154992329798504\n",
      "Generation 31/100, Best RMSE: 2.1549922649478885\n",
      "Generation 32/100, Best RMSE: 2.15499218913804\n",
      "Generation 33/100, Best RMSE: 2.1549921703963526\n",
      "Generation 34/100, Best RMSE: 2.154992141312284\n",
      "Generation 35/100, Best RMSE: 2.154992141312284\n",
      "Generation 36/100, Best RMSE: 2.154992065510051\n",
      "Generation 37/100, Best RMSE: 2.1549920528570237\n",
      "Generation 38/100, Best RMSE: 2.1549920426734324\n",
      "Generation 39/100, Best RMSE: 2.1549920362470973\n",
      "Generation 40/100, Best RMSE: 2.1549920222536145\n",
      "Generation 41/100, Best RMSE: 2.1549920222536145\n",
      "Generation 42/100, Best RMSE: 2.1549920174043136\n",
      "Generation 43/100, Best RMSE: 2.1549920124598465\n",
      "Generation 44/100, Best RMSE: 2.1549920092945407\n",
      "Generation 45/100, Best RMSE: 2.154992008761226\n",
      "Generation 46/100, Best RMSE: 2.1549920057363883\n",
      "Generation 47/100, Best RMSE: 2.1549920057363883\n",
      "Generation 48/100, Best RMSE: 2.154992005618377\n",
      "Generation 49/100, Best RMSE: 2.154992005618377\n",
      "Generation 50/100, Best RMSE: 2.1549920052868092\n",
      "Generation 51/100, Best RMSE: 2.1549920044774447\n",
      "Generation 52/100, Best RMSE: 2.1549920043778634\n",
      "Generation 53/100, Best RMSE: 2.1549920041651225\n",
      "Generation 54/100, Best RMSE: 2.1549920041050408\n",
      "Generation 55/100, Best RMSE: 2.1549920037728505\n",
      "Generation 56/100, Best RMSE: 2.1549920037728505\n",
      "Generation 57/100, Best RMSE: 2.1549920037728505\n",
      "Generation 58/100, Best RMSE: 2.15499200284961\n",
      "Generation 59/100, Best RMSE: 2.15499200284961\n",
      "Generation 60/100, Best RMSE: 2.1549920027102414\n",
      "Generation 61/100, Best RMSE: 2.154992002613337\n",
      "Generation 62/100, Best RMSE: 2.1549920025846006\n",
      "Generation 63/100, Best RMSE: 2.1549920025846006\n",
      "Generation 64/100, Best RMSE: 2.1549920025516935\n",
      "Generation 65/100, Best RMSE: 2.1549920025505602\n",
      "Generation 66/100, Best RMSE: 2.154992002543709\n",
      "Generation 67/100, Best RMSE: 2.154992002543709\n",
      "Generation 68/100, Best RMSE: 2.15499200253544\n",
      "Generation 69/100, Best RMSE: 2.154992002508272\n",
      "Generation 70/100, Best RMSE: 2.154992002450124\n",
      "Generation 71/100, Best RMSE: 2.154992002428167\n",
      "Generation 72/100, Best RMSE: 2.1549920024238456\n",
      "Generation 73/100, Best RMSE: 2.1549920024198217\n",
      "Generation 74/100, Best RMSE: 2.1549920024198217\n",
      "Generation 75/100, Best RMSE: 2.1549920024012303\n",
      "Generation 76/100, Best RMSE: 2.154992002358329\n",
      "Generation 77/100, Best RMSE: 2.1549920023565683\n",
      "Generation 78/100, Best RMSE: 2.15499200233792\n",
      "Generation 79/100, Best RMSE: 2.15499200233792\n",
      "Generation 80/100, Best RMSE: 2.1549920023341023\n",
      "Generation 81/100, Best RMSE: 2.1549920023334326\n",
      "Generation 82/100, Best RMSE: 2.15499200233289\n",
      "Generation 83/100, Best RMSE: 2.1549920023254754\n",
      "Generation 84/100, Best RMSE: 2.15499200232178\n",
      "Generation 85/100, Best RMSE: 2.15499200232178\n",
      "Generation 86/100, Best RMSE: 2.15499200232178\n",
      "Generation 87/100, Best RMSE: 2.1549920023215328\n",
      "Generation 88/100, Best RMSE: 2.154992002320355\n",
      "Generation 89/100, Best RMSE: 2.1549920023198244\n",
      "Generation 90/100, Best RMSE: 2.1549920023192977\n",
      "Generation 91/100, Best RMSE: 2.1549920023182074\n",
      "Generation 92/100, Best RMSE: 2.154992002317677\n",
      "Generation 93/100, Best RMSE: 2.1549920023169804\n",
      "Generation 94/100, Best RMSE: 2.1549920023169196\n",
      "Generation 95/100, Best RMSE: 2.154992002316853\n",
      "Generation 96/100, Best RMSE: 2.154992002316135\n",
      "Generation 97/100, Best RMSE: 2.154992002316135\n",
      "Generation 98/100, Best RMSE: 2.1549920023160514\n",
      "Generation 99/100, Best RMSE: 2.1549920023159714\n",
      "Generation 100/100, Best RMSE: 2.1549920023159133\n",
      "Optimal Weights: [0.89326787 0.01718011 0.08480656 0.         0.00474546]\n",
      "(20, 5, 48, 2) (20, 48, 2)\n",
      "Generation 1/100, Best RMSE: 2.293558820125326\n",
      "Generation 2/100, Best RMSE: 2.290528194540216\n",
      "Generation 3/100, Best RMSE: 2.2578862321747946\n",
      "Generation 4/100, Best RMSE: 2.2578862321747946\n",
      "Generation 5/100, Best RMSE: 2.2537401245595508\n",
      "Generation 6/100, Best RMSE: 2.2537401245595508\n",
      "Generation 7/100, Best RMSE: 2.2537401245595508\n",
      "Generation 8/100, Best RMSE: 2.252027829221935\n",
      "Generation 9/100, Best RMSE: 2.2499603905432637\n",
      "Generation 10/100, Best RMSE: 2.248207981181927\n",
      "Generation 11/100, Best RMSE: 2.2478355723322783\n",
      "Generation 12/100, Best RMSE: 2.2469122688001137\n",
      "Generation 13/100, Best RMSE: 2.2464907143926833\n",
      "Generation 14/100, Best RMSE: 2.2464347690525255\n",
      "Generation 15/100, Best RMSE: 2.2463757887899334\n",
      "Generation 16/100, Best RMSE: 2.2463755564744554\n",
      "Generation 17/100, Best RMSE: 2.2463700645032345\n",
      "Generation 18/100, Best RMSE: 2.2463639386968475\n",
      "Generation 19/100, Best RMSE: 2.2463594331865866\n",
      "Generation 20/100, Best RMSE: 2.2463594331865866\n",
      "Generation 21/100, Best RMSE: 2.2463587963986327\n",
      "Generation 22/100, Best RMSE: 2.2463587846966875\n",
      "Generation 23/100, Best RMSE: 2.2463587846966875\n",
      "Generation 24/100, Best RMSE: 2.2463587582968243\n",
      "Generation 25/100, Best RMSE: 2.246358721799322\n",
      "Generation 26/100, Best RMSE: 2.246358721799322\n",
      "Generation 27/100, Best RMSE: 2.246358632514662\n",
      "Generation 28/100, Best RMSE: 2.246358592127562\n",
      "Generation 29/100, Best RMSE: 2.2463584463698925\n",
      "Generation 30/100, Best RMSE: 2.2463583925796224\n",
      "Generation 31/100, Best RMSE: 2.24635837054469\n",
      "Generation 32/100, Best RMSE: 2.246358339679785\n",
      "Generation 33/100, Best RMSE: 2.2463583131734355\n",
      "Generation 34/100, Best RMSE: 2.2463583041622943\n",
      "Generation 35/100, Best RMSE: 2.2463582808126663\n",
      "Generation 36/100, Best RMSE: 2.2463582530285264\n",
      "Generation 37/100, Best RMSE: 2.2463582529861763\n",
      "Generation 38/100, Best RMSE: 2.246358223350971\n",
      "Generation 39/100, Best RMSE: 2.2463582010835794\n",
      "Generation 40/100, Best RMSE: 2.246358185112489\n",
      "Generation 41/100, Best RMSE: 2.246358176772762\n",
      "Generation 42/100, Best RMSE: 2.2463581694689494\n",
      "Generation 43/100, Best RMSE: 2.2463336173123296\n",
      "Generation 44/100, Best RMSE: 2.246333221753218\n",
      "Generation 45/100, Best RMSE: 2.2463328626168972\n",
      "Generation 46/100, Best RMSE: 2.2463304255015397\n",
      "Generation 47/100, Best RMSE: 2.2463301262145623\n",
      "Generation 48/100, Best RMSE: 2.2463285493170178\n",
      "Generation 49/100, Best RMSE: 2.2463285493170178\n",
      "Generation 50/100, Best RMSE: 2.2463285493170178\n",
      "Generation 51/100, Best RMSE: 2.2463285493170178\n",
      "Generation 52/100, Best RMSE: 2.2463285493170178\n",
      "Generation 53/100, Best RMSE: 2.2463285493170178\n",
      "Generation 54/100, Best RMSE: 2.2463285493170178\n",
      "Generation 55/100, Best RMSE: 2.2463285493170178\n",
      "Generation 56/100, Best RMSE: 2.246328529855272\n",
      "Generation 57/100, Best RMSE: 2.246328529855272\n",
      "Generation 58/100, Best RMSE: 2.246328529855272\n",
      "Generation 59/100, Best RMSE: 2.246328529855272\n",
      "Generation 60/100, Best RMSE: 2.246328529855272\n",
      "Generation 61/100, Best RMSE: 2.246328529855272\n",
      "Generation 62/100, Best RMSE: 2.246328529855272\n",
      "Generation 63/100, Best RMSE: 2.246328529855272\n",
      "Generation 64/100, Best RMSE: 2.246328529855272\n",
      "Generation 65/100, Best RMSE: 2.246328529855272\n",
      "Generation 66/100, Best RMSE: 2.246328529855272\n",
      "Generation 67/100, Best RMSE: 2.246328529855272\n",
      "Generation 68/100, Best RMSE: 2.246328529855272\n",
      "Generation 69/100, Best RMSE: 2.246328529855272\n",
      "Generation 70/100, Best RMSE: 2.246328529855272\n",
      "Generation 71/100, Best RMSE: 2.246328529855272\n",
      "Generation 72/100, Best RMSE: 2.2463285298529305\n",
      "Generation 73/100, Best RMSE: 2.2463285298518842\n",
      "Generation 74/100, Best RMSE: 2.2463285298518842\n",
      "Generation 75/100, Best RMSE: 2.2463285298517652\n",
      "Generation 76/100, Best RMSE: 2.246328529851737\n",
      "Generation 77/100, Best RMSE: 2.246328529851737\n",
      "Generation 78/100, Best RMSE: 2.246328529851737\n",
      "Generation 79/100, Best RMSE: 2.246328529851737\n",
      "Generation 80/100, Best RMSE: 2.246328529851737\n",
      "Generation 81/100, Best RMSE: 2.246328529851671\n",
      "Generation 82/100, Best RMSE: 2.246328529851671\n",
      "Generation 83/100, Best RMSE: 2.246328529851671\n",
      "Generation 84/100, Best RMSE: 2.246328529851671\n",
      "Generation 85/100, Best RMSE: 2.2463285298516698\n",
      "Generation 86/100, Best RMSE: 2.2463285298516698\n",
      "Generation 87/100, Best RMSE: 2.2463285298516698\n",
      "Generation 88/100, Best RMSE: 2.2463285298516698\n",
      "Generation 89/100, Best RMSE: 2.2463285298516698\n",
      "Generation 90/100, Best RMSE: 2.2463285298516698\n",
      "Generation 91/100, Best RMSE: 2.2463285298516698\n",
      "Generation 92/100, Best RMSE: 2.2463285298516698\n",
      "Generation 93/100, Best RMSE: 2.2463285298516698\n",
      "Generation 94/100, Best RMSE: 2.2463285298516698\n",
      "Generation 95/100, Best RMSE: 2.2463285298516698\n",
      "Generation 96/100, Best RMSE: 2.2463285298516698\n",
      "Generation 97/100, Best RMSE: 2.2463285298516698\n",
      "Generation 98/100, Best RMSE: 2.2463285298516698\n",
      "Generation 99/100, Best RMSE: 2.2463285298516698\n",
      "Generation 100/100, Best RMSE: 2.2463285298516698\n",
      "Optimal Weights: [0.87158191 0.         0.01500284 0.         0.11341526]\n",
      "(18, 5, 48, 2) (18, 48, 2)\n",
      "Generation 1/100, Best RMSE: 1.7261475348720108\n",
      "Generation 2/100, Best RMSE: 1.7261475348720108\n",
      "Generation 3/100, Best RMSE: 1.7254039791928706\n",
      "Generation 4/100, Best RMSE: 1.7251246329567806\n",
      "Generation 5/100, Best RMSE: 1.7251246329567806\n",
      "Generation 6/100, Best RMSE: 1.7250902702340498\n",
      "Generation 7/100, Best RMSE: 1.7250494434396042\n",
      "Generation 8/100, Best RMSE: 1.7250406009121417\n",
      "Generation 9/100, Best RMSE: 1.7250406009121417\n",
      "Generation 10/100, Best RMSE: 1.7250367523700603\n",
      "Generation 11/100, Best RMSE: 1.7250244606404674\n",
      "Generation 12/100, Best RMSE: 1.7250196254408923\n",
      "Generation 13/100, Best RMSE: 1.725019478303616\n",
      "Generation 14/100, Best RMSE: 1.725018640019077\n",
      "Generation 15/100, Best RMSE: 1.725016853447434\n",
      "Generation 16/100, Best RMSE: 1.7250159027226872\n",
      "Generation 17/100, Best RMSE: 1.7250158536083169\n",
      "Generation 18/100, Best RMSE: 1.7250126743976852\n",
      "Generation 19/100, Best RMSE: 1.7250125624592219\n",
      "Generation 20/100, Best RMSE: 1.7250053691000569\n",
      "Generation 21/100, Best RMSE: 1.725005223655073\n",
      "Generation 22/100, Best RMSE: 1.7250052179807955\n",
      "Generation 23/100, Best RMSE: 1.7250051761568517\n",
      "Generation 24/100, Best RMSE: 1.725004990624918\n",
      "Generation 25/100, Best RMSE: 1.7250049156948999\n",
      "Generation 26/100, Best RMSE: 1.7250049156948999\n",
      "Generation 27/100, Best RMSE: 1.7250049156948999\n",
      "Generation 28/100, Best RMSE: 1.725004912113801\n",
      "Generation 29/100, Best RMSE: 1.7250049120848212\n",
      "Generation 30/100, Best RMSE: 1.7250049062044026\n",
      "Generation 31/100, Best RMSE: 1.7250049020675542\n",
      "Generation 32/100, Best RMSE: 1.7250049002643923\n",
      "Generation 33/100, Best RMSE: 1.7250048990600477\n",
      "Generation 34/100, Best RMSE: 1.7250048989163744\n",
      "Generation 35/100, Best RMSE: 1.7250048974296686\n",
      "Generation 36/100, Best RMSE: 1.7250048966810987\n",
      "Generation 37/100, Best RMSE: 1.7250048966810987\n",
      "Generation 38/100, Best RMSE: 1.7250048965991094\n",
      "Generation 39/100, Best RMSE: 1.7250048961956557\n",
      "Generation 40/100, Best RMSE: 1.7250048960252427\n",
      "Generation 41/100, Best RMSE: 1.7250048960024795\n",
      "Generation 42/100, Best RMSE: 1.7250048959205007\n",
      "Generation 43/100, Best RMSE: 1.7250048959205007\n",
      "Generation 44/100, Best RMSE: 1.7250048958687325\n",
      "Generation 45/100, Best RMSE: 1.725004895812664\n",
      "Generation 46/100, Best RMSE: 1.725004895812664\n",
      "Generation 47/100, Best RMSE: 1.7250048958047124\n",
      "Generation 48/100, Best RMSE: 1.7250048957934951\n",
      "Generation 49/100, Best RMSE: 1.7250048957934951\n",
      "Generation 50/100, Best RMSE: 1.7250048957729804\n",
      "Generation 51/100, Best RMSE: 1.7250048957716348\n",
      "Generation 52/100, Best RMSE: 1.7250048957716348\n",
      "Generation 53/100, Best RMSE: 1.7250048957665993\n",
      "Generation 54/100, Best RMSE: 1.7250048957655015\n",
      "Generation 55/100, Best RMSE: 1.725004895761874\n",
      "Generation 56/100, Best RMSE: 1.7250048957609718\n",
      "Generation 57/100, Best RMSE: 1.7250048957609718\n",
      "Generation 58/100, Best RMSE: 1.7250048957609718\n",
      "Generation 59/100, Best RMSE: 1.7250048957590163\n",
      "Generation 60/100, Best RMSE: 1.7250048957586919\n",
      "Generation 61/100, Best RMSE: 1.7250048957573962\n",
      "Generation 62/100, Best RMSE: 1.7250048957571416\n",
      "Generation 63/100, Best RMSE: 1.7250048957571416\n",
      "Generation 64/100, Best RMSE: 1.7250048957569197\n",
      "Generation 65/100, Best RMSE: 1.725004895756549\n",
      "Generation 66/100, Best RMSE: 1.7250048957556814\n",
      "Generation 67/100, Best RMSE: 1.7250048957556814\n",
      "Generation 68/100, Best RMSE: 1.7250048957556798\n",
      "Generation 69/100, Best RMSE: 1.7250048957556798\n",
      "Generation 70/100, Best RMSE: 1.725004895755409\n",
      "Generation 71/100, Best RMSE: 1.7250048957553779\n",
      "Generation 72/100, Best RMSE: 1.725004895755323\n",
      "Generation 73/100, Best RMSE: 1.7250048957552866\n",
      "Generation 74/100, Best RMSE: 1.7250048957551394\n",
      "Generation 75/100, Best RMSE: 1.725004895755108\n",
      "Generation 76/100, Best RMSE: 1.7250048957550665\n",
      "Generation 77/100, Best RMSE: 1.7250048957550415\n",
      "Generation 78/100, Best RMSE: 1.7250048957550401\n",
      "Generation 79/100, Best RMSE: 1.7250048957550344\n",
      "Generation 80/100, Best RMSE: 1.7250048957550226\n",
      "Generation 81/100, Best RMSE: 1.725004895755004\n",
      "Generation 82/100, Best RMSE: 1.7250048957550028\n",
      "Generation 83/100, Best RMSE: 1.7250048957549975\n",
      "Generation 84/100, Best RMSE: 1.7250048957549937\n",
      "Generation 85/100, Best RMSE: 1.7250048957549917\n",
      "Generation 86/100, Best RMSE: 1.725004895754991\n",
      "Generation 87/100, Best RMSE: 1.7250048957549864\n",
      "Generation 88/100, Best RMSE: 1.725004895754984\n",
      "Generation 89/100, Best RMSE: 1.7250048957549824\n",
      "Generation 90/100, Best RMSE: 1.7250048957549822\n",
      "Generation 91/100, Best RMSE: 1.7250048957549806\n",
      "Generation 92/100, Best RMSE: 1.7250048957549804\n",
      "Generation 93/100, Best RMSE: 1.7250048957549786\n",
      "Generation 94/100, Best RMSE: 1.7250048957549786\n",
      "Generation 95/100, Best RMSE: 1.7250048957549786\n",
      "Generation 96/100, Best RMSE: 1.725004895754978\n",
      "Generation 97/100, Best RMSE: 1.7250048957549777\n",
      "Generation 98/100, Best RMSE: 1.7250048957549773\n",
      "Generation 99/100, Best RMSE: 1.725004895754977\n",
      "Generation 100/100, Best RMSE: 1.725004895754977\n",
      "Optimal Weights: [0.48293436 0.         0.         0.01971699 0.49734865]\n",
      "(18, 5, 48, 2) (18, 48, 2)\n",
      "Generation 1/100, Best RMSE: 2.171157621988335\n",
      "Generation 2/100, Best RMSE: 2.171157621988335\n",
      "Generation 3/100, Best RMSE: 2.171157621988335\n",
      "Generation 4/100, Best RMSE: 2.1683143215126384\n",
      "Generation 5/100, Best RMSE: 2.1683143215126384\n",
      "Generation 6/100, Best RMSE: 2.165274942891947\n",
      "Generation 7/100, Best RMSE: 2.1641519871073536\n",
      "Generation 8/100, Best RMSE: 2.1631204745257864\n",
      "Generation 9/100, Best RMSE: 2.1623184374766957\n",
      "Generation 10/100, Best RMSE: 2.158966606117721\n",
      "Generation 11/100, Best RMSE: 2.1584194298799746\n",
      "Generation 12/100, Best RMSE: 2.1584194298799746\n",
      "Generation 13/100, Best RMSE: 2.1579003008519857\n",
      "Generation 14/100, Best RMSE: 2.157735800970356\n",
      "Generation 15/100, Best RMSE: 2.1577166872601747\n",
      "Generation 16/100, Best RMSE: 2.1576849743298676\n",
      "Generation 17/100, Best RMSE: 2.1576843964545214\n",
      "Generation 18/100, Best RMSE: 2.1576843570322213\n",
      "Generation 19/100, Best RMSE: 2.1576843570322213\n",
      "Generation 20/100, Best RMSE: 2.157684357027735\n",
      "Generation 21/100, Best RMSE: 2.157684357027735\n",
      "Generation 22/100, Best RMSE: 2.157684357027735\n",
      "Generation 23/100, Best RMSE: 2.1576843570235753\n",
      "Generation 24/100, Best RMSE: 2.1576843570235753\n",
      "Generation 25/100, Best RMSE: 2.157684357023565\n",
      "Generation 26/100, Best RMSE: 2.157684357023528\n",
      "Generation 27/100, Best RMSE: 2.157684357023528\n",
      "Generation 28/100, Best RMSE: 2.157684357023528\n",
      "Generation 29/100, Best RMSE: 2.1576843570235273\n",
      "Generation 30/100, Best RMSE: 2.1576843570235273\n",
      "Generation 31/100, Best RMSE: 2.1576843570235273\n",
      "Generation 32/100, Best RMSE: 2.1576843570235273\n",
      "Generation 33/100, Best RMSE: 2.1576843570235273\n",
      "Generation 34/100, Best RMSE: 2.1576843570235273\n",
      "Generation 35/100, Best RMSE: 2.1576843570235273\n",
      "Generation 36/100, Best RMSE: 2.1576843570235273\n",
      "Generation 37/100, Best RMSE: 2.1576843570235273\n",
      "Generation 38/100, Best RMSE: 2.1576843570235273\n",
      "Generation 39/100, Best RMSE: 2.1576843570235273\n",
      "Generation 40/100, Best RMSE: 2.1576843570235273\n",
      "Generation 41/100, Best RMSE: 2.1576843570235273\n",
      "Generation 42/100, Best RMSE: 2.1576843570235273\n",
      "Generation 43/100, Best RMSE: 2.1576843570235273\n",
      "Generation 44/100, Best RMSE: 2.1576843570235273\n",
      "Generation 45/100, Best RMSE: 2.1576843570235273\n",
      "Generation 46/100, Best RMSE: 2.1576843570235273\n",
      "Generation 47/100, Best RMSE: 2.1576843570235273\n",
      "Generation 48/100, Best RMSE: 2.1576843570235273\n",
      "Generation 49/100, Best RMSE: 2.1576843570235273\n",
      "Generation 50/100, Best RMSE: 2.1576843570235273\n",
      "Generation 51/100, Best RMSE: 2.1576843570235273\n",
      "Generation 52/100, Best RMSE: 2.1576843570235273\n",
      "Generation 53/100, Best RMSE: 2.1576843570235273\n",
      "Generation 54/100, Best RMSE: 2.1576843570235273\n",
      "Generation 55/100, Best RMSE: 2.1576843570235273\n",
      "Generation 56/100, Best RMSE: 2.1576843570235273\n",
      "Generation 57/100, Best RMSE: 2.1576843570235273\n",
      "Generation 58/100, Best RMSE: 2.1576843570235273\n",
      "Generation 59/100, Best RMSE: 2.1576843570235273\n",
      "Generation 60/100, Best RMSE: 2.1576843570235273\n",
      "Generation 61/100, Best RMSE: 2.1576843570235273\n",
      "Generation 62/100, Best RMSE: 2.1576843570235273\n",
      "Generation 63/100, Best RMSE: 2.1576843570235273\n",
      "Generation 64/100, Best RMSE: 2.1576843570235273\n",
      "Generation 65/100, Best RMSE: 2.1576843570235273\n",
      "Generation 66/100, Best RMSE: 2.1576843570235273\n",
      "Generation 67/100, Best RMSE: 2.1576843570235273\n",
      "Generation 68/100, Best RMSE: 2.1576843570235273\n",
      "Generation 69/100, Best RMSE: 2.1576843570235273\n",
      "Generation 70/100, Best RMSE: 2.1576843570235273\n",
      "Generation 71/100, Best RMSE: 2.1576843570235273\n",
      "Generation 72/100, Best RMSE: 2.1576843570235273\n",
      "Generation 73/100, Best RMSE: 2.1576843570235273\n",
      "Generation 74/100, Best RMSE: 2.1576843570235273\n",
      "Generation 75/100, Best RMSE: 2.1576843570235273\n",
      "Generation 76/100, Best RMSE: 2.1576843570235273\n",
      "Generation 77/100, Best RMSE: 2.1576843570235273\n",
      "Generation 78/100, Best RMSE: 2.1576843570235273\n",
      "Generation 79/100, Best RMSE: 2.1576843570235273\n",
      "Generation 80/100, Best RMSE: 2.1576843570235273\n",
      "Generation 81/100, Best RMSE: 2.1576843570235273\n",
      "Generation 82/100, Best RMSE: 2.1576843570235273\n",
      "Generation 83/100, Best RMSE: 2.1576843570235273\n",
      "Generation 84/100, Best RMSE: 2.1576843570235273\n",
      "Generation 85/100, Best RMSE: 2.1576843570235273\n",
      "Generation 86/100, Best RMSE: 2.1576843570235273\n",
      "Generation 87/100, Best RMSE: 2.1576843570235273\n",
      "Generation 88/100, Best RMSE: 2.1576843570235273\n",
      "Generation 89/100, Best RMSE: 2.1576843570235273\n",
      "Generation 90/100, Best RMSE: 2.1576843570235273\n",
      "Generation 91/100, Best RMSE: 2.1576843570235273\n",
      "Generation 92/100, Best RMSE: 2.1576843570235273\n",
      "Generation 93/100, Best RMSE: 2.1576843570235273\n",
      "Generation 94/100, Best RMSE: 2.1576843570235273\n",
      "Generation 95/100, Best RMSE: 2.1576843570235273\n",
      "Generation 96/100, Best RMSE: 2.1576843570235273\n",
      "Generation 97/100, Best RMSE: 2.1576843570235273\n",
      "Generation 98/100, Best RMSE: 2.1576843570235273\n",
      "Generation 99/100, Best RMSE: 2.1576843570235273\n",
      "Generation 100/100, Best RMSE: 2.1576843570235273\n",
      "Optimal Weights: [0.73229964 0.         0.         0.         0.26770036]\n",
      "(15, 5, 48, 2) (15, 48, 2)\n",
      "Generation 1/100, Best RMSE: 2.2499661496370953\n",
      "Generation 2/100, Best RMSE: 2.2499661496370953\n",
      "Generation 3/100, Best RMSE: 2.2475819388444855\n",
      "Generation 4/100, Best RMSE: 2.2475819388444855\n",
      "Generation 5/100, Best RMSE: 2.2470861146826415\n",
      "Generation 6/100, Best RMSE: 2.246962219119004\n",
      "Generation 7/100, Best RMSE: 2.2466106712335807\n",
      "Generation 8/100, Best RMSE: 2.2466106712335807\n",
      "Generation 9/100, Best RMSE: 2.2466106712335807\n",
      "Generation 10/100, Best RMSE: 2.246579690640002\n",
      "Generation 11/100, Best RMSE: 2.2465718743500234\n",
      "Generation 12/100, Best RMSE: 2.2465682212745177\n",
      "Generation 13/100, Best RMSE: 2.246566552585471\n",
      "Generation 14/100, Best RMSE: 2.246566552585471\n",
      "Generation 15/100, Best RMSE: 2.2465662773679096\n",
      "Generation 16/100, Best RMSE: 2.246566216027726\n",
      "Generation 17/100, Best RMSE: 2.2465661906245877\n",
      "Generation 18/100, Best RMSE: 2.2465661125982206\n",
      "Generation 19/100, Best RMSE: 2.246566072053108\n",
      "Generation 20/100, Best RMSE: 2.2465660109870913\n",
      "Generation 21/100, Best RMSE: 2.2465660109870913\n",
      "Generation 22/100, Best RMSE: 2.2465660071903817\n",
      "Generation 23/100, Best RMSE: 2.2465660008700086\n",
      "Generation 24/100, Best RMSE: 2.2465660008700086\n",
      "Generation 25/100, Best RMSE: 2.2465660008700086\n",
      "Generation 26/100, Best RMSE: 2.24656600078226\n",
      "Generation 27/100, Best RMSE: 2.24656600078226\n",
      "Generation 28/100, Best RMSE: 2.246566000767769\n",
      "Generation 29/100, Best RMSE: 2.246566000767769\n",
      "Generation 30/100, Best RMSE: 2.2465660007354584\n",
      "Generation 31/100, Best RMSE: 2.2465660007354584\n",
      "Generation 32/100, Best RMSE: 2.2465660007225887\n",
      "Generation 33/100, Best RMSE: 2.2465660007225887\n",
      "Generation 34/100, Best RMSE: 2.246566000722464\n",
      "Generation 35/100, Best RMSE: 2.246566000721513\n",
      "Generation 36/100, Best RMSE: 2.2465660007215025\n",
      "Generation 37/100, Best RMSE: 2.2465660007215025\n",
      "Generation 38/100, Best RMSE: 2.246566000721461\n",
      "Generation 39/100, Best RMSE: 2.2465660007212667\n",
      "Generation 40/100, Best RMSE: 2.2465660007212667\n",
      "Generation 41/100, Best RMSE: 2.246566000721262\n",
      "Generation 42/100, Best RMSE: 2.246566000721261\n",
      "Generation 43/100, Best RMSE: 2.2465660007212533\n",
      "Generation 44/100, Best RMSE: 2.2465660007212502\n",
      "Generation 45/100, Best RMSE: 2.24656600072125\n",
      "Generation 46/100, Best RMSE: 2.2465660007212493\n",
      "Generation 47/100, Best RMSE: 2.2465660007212493\n",
      "Generation 48/100, Best RMSE: 2.246566000721249\n",
      "Generation 49/100, Best RMSE: 2.246566000721249\n",
      "Generation 50/100, Best RMSE: 2.246566000721249\n",
      "Generation 51/100, Best RMSE: 2.246566000721249\n",
      "Generation 52/100, Best RMSE: 2.246566000721249\n",
      "Generation 53/100, Best RMSE: 2.246566000721249\n",
      "Generation 54/100, Best RMSE: 2.246566000721249\n",
      "Generation 55/100, Best RMSE: 2.246566000721249\n",
      "Generation 56/100, Best RMSE: 2.246566000721249\n",
      "Generation 57/100, Best RMSE: 2.246566000721249\n",
      "Generation 58/100, Best RMSE: 2.246566000721249\n",
      "Generation 59/100, Best RMSE: 2.246566000721249\n",
      "Generation 60/100, Best RMSE: 2.246566000721249\n",
      "Generation 61/100, Best RMSE: 2.246566000721249\n",
      "Generation 62/100, Best RMSE: 2.246566000721249\n",
      "Generation 63/100, Best RMSE: 2.246566000721249\n",
      "Generation 64/100, Best RMSE: 2.246566000721249\n",
      "Generation 65/100, Best RMSE: 2.246566000721249\n",
      "Generation 66/100, Best RMSE: 2.246566000721249\n",
      "Generation 67/100, Best RMSE: 2.246566000721249\n",
      "Generation 68/100, Best RMSE: 2.246566000721249\n",
      "Generation 69/100, Best RMSE: 2.246566000721249\n",
      "Generation 70/100, Best RMSE: 2.246566000721249\n",
      "Generation 71/100, Best RMSE: 2.246566000721249\n",
      "Generation 72/100, Best RMSE: 2.246566000721249\n",
      "Generation 73/100, Best RMSE: 2.246566000721249\n",
      "Generation 74/100, Best RMSE: 2.246566000721249\n",
      "Generation 75/100, Best RMSE: 2.246566000721249\n",
      "Generation 76/100, Best RMSE: 2.246566000721249\n",
      "Generation 77/100, Best RMSE: 2.246566000721249\n",
      "Generation 78/100, Best RMSE: 2.246566000721249\n",
      "Generation 79/100, Best RMSE: 2.246566000721249\n",
      "Generation 80/100, Best RMSE: 2.246566000721249\n",
      "Generation 81/100, Best RMSE: 2.246566000721249\n",
      "Generation 82/100, Best RMSE: 2.246566000721249\n",
      "Generation 83/100, Best RMSE: 2.246566000721249\n",
      "Generation 84/100, Best RMSE: 2.246566000721249\n",
      "Generation 85/100, Best RMSE: 2.246566000721249\n",
      "Generation 86/100, Best RMSE: 2.246566000721249\n",
      "Generation 87/100, Best RMSE: 2.246566000721249\n",
      "Generation 88/100, Best RMSE: 2.246566000721249\n",
      "Generation 89/100, Best RMSE: 2.246566000721249\n",
      "Generation 90/100, Best RMSE: 2.246566000721249\n",
      "Generation 91/100, Best RMSE: 2.246566000721249\n",
      "Generation 92/100, Best RMSE: 2.246566000721249\n",
      "Generation 93/100, Best RMSE: 2.246566000721249\n",
      "Generation 94/100, Best RMSE: 2.246566000721249\n",
      "Generation 95/100, Best RMSE: 2.246566000721249\n",
      "Generation 96/100, Best RMSE: 2.246566000721249\n",
      "Generation 97/100, Best RMSE: 2.246566000721249\n",
      "Generation 98/100, Best RMSE: 2.246566000721249\n",
      "Generation 99/100, Best RMSE: 2.246566000721249\n",
      "Generation 100/100, Best RMSE: 2.246566000721249\n",
      "Optimal Weights: [0.29015045 0.19695908 0.34140963 0.         0.17148084]\n",
      "(24, 5, 48, 2) (24, 48, 2)\n",
      "Generation 1/100, Best RMSE: 2.15560002762977\n",
      "Generation 2/100, Best RMSE: 2.1436865184262515\n",
      "Generation 3/100, Best RMSE: 2.1436865184262515\n",
      "Generation 4/100, Best RMSE: 2.1436552412947196\n",
      "Generation 5/100, Best RMSE: 2.1436552412947196\n",
      "Generation 6/100, Best RMSE: 2.1407784579548075\n",
      "Generation 7/100, Best RMSE: 2.140580947373119\n",
      "Generation 8/100, Best RMSE: 2.140580947373119\n",
      "Generation 9/100, Best RMSE: 2.140580947373119\n",
      "Generation 10/100, Best RMSE: 2.140579741612795\n",
      "Generation 11/100, Best RMSE: 2.1403264876467585\n",
      "Generation 12/100, Best RMSE: 2.1400128081186867\n",
      "Generation 13/100, Best RMSE: 2.140001129363328\n",
      "Generation 14/100, Best RMSE: 2.139894293616546\n",
      "Generation 15/100, Best RMSE: 2.139863034074665\n",
      "Generation 16/100, Best RMSE: 2.139863034074665\n",
      "Generation 17/100, Best RMSE: 2.139863034074665\n",
      "Generation 18/100, Best RMSE: 2.139863034074665\n",
      "Generation 19/100, Best RMSE: 2.139863034074665\n",
      "Generation 20/100, Best RMSE: 2.139863034074665\n",
      "Generation 21/100, Best RMSE: 2.139863034074665\n",
      "Generation 22/100, Best RMSE: 2.139863034074665\n",
      "Generation 23/100, Best RMSE: 2.139863034074665\n",
      "Generation 24/100, Best RMSE: 2.139863034074665\n",
      "Generation 25/100, Best RMSE: 2.139863034074665\n",
      "Generation 26/100, Best RMSE: 2.139863034074665\n",
      "Generation 27/100, Best RMSE: 2.139863034074665\n",
      "Generation 28/100, Best RMSE: 2.139863034074665\n",
      "Generation 29/100, Best RMSE: 2.139863034074665\n",
      "Generation 30/100, Best RMSE: 2.139863034074665\n",
      "Generation 31/100, Best RMSE: 2.139863034074665\n",
      "Generation 32/100, Best RMSE: 2.139863034074665\n",
      "Generation 33/100, Best RMSE: 2.139863034074665\n",
      "Generation 34/100, Best RMSE: 2.139863034074665\n",
      "Generation 35/100, Best RMSE: 2.139863034074665\n",
      "Generation 36/100, Best RMSE: 2.139863034074665\n",
      "Generation 37/100, Best RMSE: 2.139863034074665\n",
      "Generation 38/100, Best RMSE: 2.139863034074665\n",
      "Generation 39/100, Best RMSE: 2.1398629599090238\n",
      "Generation 40/100, Best RMSE: 2.1398629599090238\n",
      "Generation 41/100, Best RMSE: 2.1398629599090238\n",
      "Generation 42/100, Best RMSE: 2.139862939585533\n",
      "Generation 43/100, Best RMSE: 2.139862931157897\n",
      "Generation 44/100, Best RMSE: 2.139862886015351\n",
      "Generation 45/100, Best RMSE: 2.1398628660002834\n",
      "Generation 46/100, Best RMSE: 2.1398628633919277\n",
      "Generation 47/100, Best RMSE: 2.139862843757486\n",
      "Generation 48/100, Best RMSE: 2.139862823500893\n",
      "Generation 49/100, Best RMSE: 2.139862823500893\n",
      "Generation 50/100, Best RMSE: 2.139862806842946\n",
      "Generation 51/100, Best RMSE: 2.139862780389693\n",
      "Generation 52/100, Best RMSE: 2.1398627523599973\n",
      "Generation 53/100, Best RMSE: 2.1398627420564273\n",
      "Generation 54/100, Best RMSE: 2.1398627193512\n",
      "Generation 55/100, Best RMSE: 2.13986270111098\n",
      "Generation 56/100, Best RMSE: 2.1398626838598167\n",
      "Generation 57/100, Best RMSE: 2.1398626677983303\n",
      "Generation 58/100, Best RMSE: 2.1398626677983303\n",
      "Generation 59/100, Best RMSE: 2.139862653063032\n",
      "Generation 60/100, Best RMSE: 2.139862653063032\n",
      "Generation 61/100, Best RMSE: 2.139862653063032\n",
      "Generation 62/100, Best RMSE: 2.139862653063032\n",
      "Generation 63/100, Best RMSE: 2.1398626530247875\n",
      "Generation 64/100, Best RMSE: 2.1398626465238166\n",
      "Generation 65/100, Best RMSE: 2.1398626465238166\n",
      "Generation 66/100, Best RMSE: 2.1398626428167\n",
      "Generation 67/100, Best RMSE: 2.139862639166604\n",
      "Generation 68/100, Best RMSE: 2.139862634147851\n",
      "Generation 69/100, Best RMSE: 2.139862634147851\n",
      "Generation 70/100, Best RMSE: 2.139862633655552\n",
      "Generation 71/100, Best RMSE: 2.139862628962652\n",
      "Generation 72/100, Best RMSE: 2.139862628962652\n",
      "Generation 73/100, Best RMSE: 2.1398626278121142\n",
      "Generation 74/100, Best RMSE: 2.1398626256542466\n",
      "Generation 75/100, Best RMSE: 2.139862624820248\n",
      "Generation 76/100, Best RMSE: 2.1398626241160925\n",
      "Generation 77/100, Best RMSE: 2.139862623979788\n",
      "Generation 78/100, Best RMSE: 2.1398626205362588\n",
      "Generation 79/100, Best RMSE: 2.139862619379343\n",
      "Generation 80/100, Best RMSE: 2.1398613331322465\n",
      "Generation 81/100, Best RMSE: 2.1398547284515783\n",
      "Generation 82/100, Best RMSE: 2.139854727399344\n",
      "Generation 83/100, Best RMSE: 2.139854727399344\n",
      "Generation 84/100, Best RMSE: 2.139854727399344\n",
      "Generation 85/100, Best RMSE: 2.1398546387527895\n",
      "Generation 86/100, Best RMSE: 2.139854470500113\n",
      "Generation 87/100, Best RMSE: 2.1398544657959695\n",
      "Generation 88/100, Best RMSE: 2.1398543579539986\n",
      "Generation 89/100, Best RMSE: 2.1398543579539986\n",
      "Generation 90/100, Best RMSE: 2.139854217616756\n",
      "Generation 91/100, Best RMSE: 2.139854217616756\n",
      "Generation 92/100, Best RMSE: 2.139854217616756\n",
      "Generation 93/100, Best RMSE: 2.139854217616756\n",
      "Generation 94/100, Best RMSE: 2.139854217616756\n",
      "Generation 95/100, Best RMSE: 2.139854217616756\n",
      "Generation 96/100, Best RMSE: 2.139854217616756\n",
      "Generation 97/100, Best RMSE: 2.139854217616756\n",
      "Generation 98/100, Best RMSE: 2.139854217616756\n",
      "Generation 99/100, Best RMSE: 2.1398542039000352\n",
      "Generation 100/100, Best RMSE: 2.1398541856379394\n",
      "Optimal Weights: [0.43500006 0.         0.         0.14708702 0.41791292]\n",
      "(21, 5, 48, 2) (21, 48, 2)\n",
      "Generation 1/100, Best RMSE: 2.8053488746897846\n",
      "Generation 2/100, Best RMSE: 2.8053488746897846\n",
      "Generation 3/100, Best RMSE: 2.797260749387276\n",
      "Generation 4/100, Best RMSE: 2.797260749387276\n",
      "Generation 5/100, Best RMSE: 2.7894871717911434\n",
      "Generation 6/100, Best RMSE: 2.7894871717911434\n",
      "Generation 7/100, Best RMSE: 2.7862364538516067\n",
      "Generation 8/100, Best RMSE: 2.7859701521733187\n",
      "Generation 9/100, Best RMSE: 2.785778273027299\n",
      "Generation 10/100, Best RMSE: 2.7855906945569844\n",
      "Generation 11/100, Best RMSE: 2.7855906945569844\n",
      "Generation 12/100, Best RMSE: 2.7855745329400885\n",
      "Generation 13/100, Best RMSE: 2.7855745329400885\n",
      "Generation 14/100, Best RMSE: 2.7855745329400885\n",
      "Generation 15/100, Best RMSE: 2.785548533327041\n",
      "Generation 16/100, Best RMSE: 2.785548533327041\n",
      "Generation 17/100, Best RMSE: 2.78545435720327\n",
      "Generation 18/100, Best RMSE: 2.785449235221229\n",
      "Generation 19/100, Best RMSE: 2.785448454745668\n",
      "Generation 20/100, Best RMSE: 2.7854474495488506\n",
      "Generation 21/100, Best RMSE: 2.7854469158815984\n",
      "Generation 22/100, Best RMSE: 2.7854455489392573\n",
      "Generation 23/100, Best RMSE: 2.7854455489392573\n",
      "Generation 24/100, Best RMSE: 2.7854443527716084\n",
      "Generation 25/100, Best RMSE: 2.7852081475223103\n",
      "Generation 26/100, Best RMSE: 2.7852081475223103\n",
      "Generation 27/100, Best RMSE: 2.7852081475223103\n",
      "Generation 28/100, Best RMSE: 2.785208118696871\n",
      "Generation 29/100, Best RMSE: 2.785205967559333\n",
      "Generation 30/100, Best RMSE: 2.7852059672600924\n",
      "Generation 31/100, Best RMSE: 2.785205510828268\n",
      "Generation 32/100, Best RMSE: 2.7852055058527263\n",
      "Generation 33/100, Best RMSE: 2.785205150742625\n",
      "Generation 34/100, Best RMSE: 2.7852049054470713\n",
      "Generation 35/100, Best RMSE: 2.7852049054470713\n",
      "Generation 36/100, Best RMSE: 2.785204889774166\n",
      "Generation 37/100, Best RMSE: 2.7852048855664204\n",
      "Generation 38/100, Best RMSE: 2.7852048855664204\n",
      "Generation 39/100, Best RMSE: 2.7852048568168692\n",
      "Generation 40/100, Best RMSE: 2.78520482198645\n",
      "Generation 41/100, Best RMSE: 2.7852048206277034\n",
      "Generation 42/100, Best RMSE: 2.7852048206277034\n",
      "Generation 43/100, Best RMSE: 2.7852048172451775\n",
      "Generation 44/100, Best RMSE: 2.78520481280592\n",
      "Generation 45/100, Best RMSE: 2.78520481280592\n",
      "Generation 46/100, Best RMSE: 2.7852048112723633\n",
      "Generation 47/100, Best RMSE: 2.7852048109498333\n",
      "Generation 48/100, Best RMSE: 2.785204806474977\n",
      "Generation 49/100, Best RMSE: 2.785204804577783\n",
      "Generation 50/100, Best RMSE: 2.7852048021990043\n",
      "Generation 51/100, Best RMSE: 2.7852048004055683\n",
      "Generation 52/100, Best RMSE: 2.7852048000067655\n",
      "Generation 53/100, Best RMSE: 2.785204799323171\n",
      "Generation 54/100, Best RMSE: 2.78520479765751\n",
      "Generation 55/100, Best RMSE: 2.78520479602596\n",
      "Generation 56/100, Best RMSE: 2.785204795479395\n",
      "Generation 57/100, Best RMSE: 2.7852047948921497\n",
      "Generation 58/100, Best RMSE: 2.7852047936169964\n",
      "Generation 59/100, Best RMSE: 2.7852047934580844\n",
      "Generation 60/100, Best RMSE: 2.785204792530801\n",
      "Generation 61/100, Best RMSE: 2.785204792530801\n",
      "Generation 62/100, Best RMSE: 2.7852047910778293\n",
      "Generation 63/100, Best RMSE: 2.7852047910778293\n",
      "Generation 64/100, Best RMSE: 2.785204789705044\n",
      "Generation 65/100, Best RMSE: 2.785204789705044\n",
      "Generation 66/100, Best RMSE: 2.7852047894834233\n",
      "Generation 67/100, Best RMSE: 2.7852047886164577\n",
      "Generation 68/100, Best RMSE: 2.785204788349637\n",
      "Generation 69/100, Best RMSE: 2.7852047876871158\n",
      "Generation 70/100, Best RMSE: 2.785204787504253\n",
      "Generation 71/100, Best RMSE: 2.785204786731588\n",
      "Generation 72/100, Best RMSE: 2.7852047862647473\n",
      "Generation 73/100, Best RMSE: 2.785204786143175\n",
      "Generation 74/100, Best RMSE: 2.7852047858989715\n",
      "Generation 75/100, Best RMSE: 2.7852047856850333\n",
      "Generation 76/100, Best RMSE: 2.785204785453138\n",
      "Generation 77/100, Best RMSE: 2.785204785453138\n",
      "Generation 78/100, Best RMSE: 2.785204785066526\n",
      "Generation 79/100, Best RMSE: 2.7852047845686574\n",
      "Generation 80/100, Best RMSE: 2.7852047844968886\n",
      "Generation 81/100, Best RMSE: 2.7852047840868828\n",
      "Generation 82/100, Best RMSE: 2.7852047840868828\n",
      "Generation 83/100, Best RMSE: 2.7852047840868828\n",
      "Generation 84/100, Best RMSE: 2.7852047838103\n",
      "Generation 85/100, Best RMSE: 2.7852047836242875\n",
      "Generation 86/100, Best RMSE: 2.7852047834706624\n",
      "Generation 87/100, Best RMSE: 2.785204783186344\n",
      "Generation 88/100, Best RMSE: 2.785204782969336\n",
      "Generation 89/100, Best RMSE: 2.7852047829440494\n",
      "Generation 90/100, Best RMSE: 2.7852047829413045\n",
      "Generation 91/100, Best RMSE: 2.785204782785522\n",
      "Generation 92/100, Best RMSE: 2.785204782785109\n",
      "Generation 93/100, Best RMSE: 2.785204782705393\n",
      "Generation 94/100, Best RMSE: 2.785204782668563\n",
      "Generation 95/100, Best RMSE: 2.7852047825740316\n",
      "Generation 96/100, Best RMSE: 2.785204782494993\n",
      "Generation 97/100, Best RMSE: 2.785204782444249\n",
      "Generation 98/100, Best RMSE: 2.7852047823996577\n",
      "Generation 99/100, Best RMSE: 2.785204782390651\n",
      "Generation 100/100, Best RMSE: 2.785204782390651\n",
      "Optimal Weights: [0.83995537 0.         0.         0.12841461 0.03163001]\n",
      "(14, 5, 48, 2) (14, 48, 2)\n",
      "Generation 1/100, Best RMSE: 2.0856938693192904\n",
      "Generation 2/100, Best RMSE: 2.077276935701292\n",
      "Generation 3/100, Best RMSE: 2.0735311016026055\n",
      "Generation 4/100, Best RMSE: 2.0735311016026055\n",
      "Generation 5/100, Best RMSE: 2.0735311016026055\n",
      "Generation 6/100, Best RMSE: 2.072530014231473\n",
      "Generation 7/100, Best RMSE: 2.072530014231473\n",
      "Generation 8/100, Best RMSE: 2.072521419477083\n",
      "Generation 9/100, Best RMSE: 2.072521419477083\n",
      "Generation 10/100, Best RMSE: 2.072502328212154\n",
      "Generation 11/100, Best RMSE: 2.072448119887234\n",
      "Generation 12/100, Best RMSE: 2.072448119887234\n",
      "Generation 13/100, Best RMSE: 2.072448119887234\n",
      "Generation 14/100, Best RMSE: 2.0724465389396025\n",
      "Generation 15/100, Best RMSE: 2.072418203005812\n",
      "Generation 16/100, Best RMSE: 2.0722985216451937\n",
      "Generation 17/100, Best RMSE: 2.0722985216451937\n",
      "Generation 18/100, Best RMSE: 2.0722282178950375\n",
      "Generation 19/100, Best RMSE: 2.0720976595784575\n",
      "Generation 20/100, Best RMSE: 2.072032229872418\n",
      "Generation 21/100, Best RMSE: 2.072025730350591\n",
      "Generation 22/100, Best RMSE: 2.0720230978302436\n",
      "Generation 23/100, Best RMSE: 2.0720226322343946\n",
      "Generation 24/100, Best RMSE: 2.072019981302527\n",
      "Generation 25/100, Best RMSE: 2.072019224835735\n",
      "Generation 26/100, Best RMSE: 2.072019224835735\n",
      "Generation 27/100, Best RMSE: 2.0720190897782973\n",
      "Generation 28/100, Best RMSE: 2.0720190716454163\n",
      "Generation 29/100, Best RMSE: 2.072019028510365\n",
      "Generation 30/100, Best RMSE: 2.072018963140884\n",
      "Generation 31/100, Best RMSE: 2.0720189442354804\n",
      "Generation 32/100, Best RMSE: 2.0720189442354804\n",
      "Generation 33/100, Best RMSE: 2.0720189357768306\n",
      "Generation 34/100, Best RMSE: 2.072018933918924\n",
      "Generation 35/100, Best RMSE: 2.0720189278350656\n",
      "Generation 36/100, Best RMSE: 2.0720189278350656\n",
      "Generation 37/100, Best RMSE: 2.072018924880219\n",
      "Generation 38/100, Best RMSE: 2.0720189240147198\n",
      "Generation 39/100, Best RMSE: 2.0720189236968625\n",
      "Generation 40/100, Best RMSE: 2.072018923357692\n",
      "Generation 41/100, Best RMSE: 2.072018923357692\n",
      "Generation 42/100, Best RMSE: 2.072018923357692\n",
      "Generation 43/100, Best RMSE: 2.072018923357692\n",
      "Generation 44/100, Best RMSE: 2.072018923357114\n",
      "Generation 45/100, Best RMSE: 2.072018923357114\n",
      "Generation 46/100, Best RMSE: 2.072018923356997\n",
      "Generation 47/100, Best RMSE: 2.0720189233564494\n",
      "Generation 48/100, Best RMSE: 2.072018923356377\n",
      "Generation 49/100, Best RMSE: 2.0720189233563047\n",
      "Generation 50/100, Best RMSE: 2.0720189233563047\n",
      "Generation 51/100, Best RMSE: 2.072018923356274\n",
      "Generation 52/100, Best RMSE: 2.072018923356274\n",
      "Generation 53/100, Best RMSE: 2.0720189233562647\n",
      "Generation 54/100, Best RMSE: 2.0720189233562643\n",
      "Generation 55/100, Best RMSE: 2.0720189233562643\n",
      "Generation 56/100, Best RMSE: 2.0720189233562643\n",
      "Generation 57/100, Best RMSE: 2.0720189233562634\n",
      "Generation 58/100, Best RMSE: 2.072018923356263\n",
      "Generation 59/100, Best RMSE: 2.072018923356263\n",
      "Generation 60/100, Best RMSE: 2.072018923356263\n",
      "Generation 61/100, Best RMSE: 2.0720189233562625\n",
      "Generation 62/100, Best RMSE: 2.0720189233562625\n",
      "Generation 63/100, Best RMSE: 2.0720189233562625\n",
      "Generation 64/100, Best RMSE: 2.0720189233562625\n",
      "Generation 65/100, Best RMSE: 2.0720189233562625\n",
      "Generation 66/100, Best RMSE: 2.0720189233562625\n",
      "Generation 67/100, Best RMSE: 2.0720189233562625\n",
      "Generation 68/100, Best RMSE: 2.0720189233562625\n",
      "Generation 69/100, Best RMSE: 2.0720189233562625\n",
      "Generation 70/100, Best RMSE: 2.0720189233562625\n",
      "Generation 71/100, Best RMSE: 2.0720189233562625\n",
      "Generation 72/100, Best RMSE: 2.0720189233562625\n",
      "Generation 73/100, Best RMSE: 2.0720189233562625\n",
      "Generation 74/100, Best RMSE: 2.0720189233562625\n",
      "Generation 75/100, Best RMSE: 2.0720189233562625\n",
      "Generation 76/100, Best RMSE: 2.0720189233562625\n",
      "Generation 77/100, Best RMSE: 2.0720189233562625\n",
      "Generation 78/100, Best RMSE: 2.0720189233562625\n",
      "Generation 79/100, Best RMSE: 2.0720189233562625\n",
      "Generation 80/100, Best RMSE: 2.0720189233562625\n",
      "Generation 81/100, Best RMSE: 2.0720189233562625\n",
      "Generation 82/100, Best RMSE: 2.0720189233562625\n",
      "Generation 83/100, Best RMSE: 2.0720189233562625\n",
      "Generation 84/100, Best RMSE: 2.0720189233562625\n",
      "Generation 85/100, Best RMSE: 2.0720189233562625\n",
      "Generation 86/100, Best RMSE: 2.0720189233562625\n",
      "Generation 87/100, Best RMSE: 2.0720189233562625\n",
      "Generation 88/100, Best RMSE: 2.0720189233562625\n",
      "Generation 89/100, Best RMSE: 2.0720189233562625\n",
      "Generation 90/100, Best RMSE: 2.0720189233562625\n",
      "Generation 91/100, Best RMSE: 2.0720189233562625\n",
      "Generation 92/100, Best RMSE: 2.0720189233562625\n",
      "Generation 93/100, Best RMSE: 2.0720189233562625\n",
      "Generation 94/100, Best RMSE: 2.0720189233562625\n",
      "Generation 95/100, Best RMSE: 2.0720189233562625\n",
      "Generation 96/100, Best RMSE: 2.0720189233562625\n",
      "Generation 97/100, Best RMSE: 2.0720189233562625\n",
      "Generation 98/100, Best RMSE: 2.0720189233562625\n",
      "Generation 99/100, Best RMSE: 2.0720189233562625\n",
      "Generation 100/100, Best RMSE: 2.0720189233562625\n",
      "Optimal Weights: [0.58545155 0.         0.27482755 0.         0.1397209 ]\n",
      "(23, 5, 48, 2) (23, 48, 2)\n",
      "Generation 1/100, Best RMSE: 1.9540020522706856\n",
      "Generation 2/100, Best RMSE: 1.9540020522706856\n",
      "Generation 3/100, Best RMSE: 1.9519836223103342\n",
      "Generation 4/100, Best RMSE: 1.9476269459803508\n",
      "Generation 5/100, Best RMSE: 1.9469866226378636\n",
      "Generation 6/100, Best RMSE: 1.9456115474980185\n",
      "Generation 7/100, Best RMSE: 1.9456115474980185\n",
      "Generation 8/100, Best RMSE: 1.9453400858444603\n",
      "Generation 9/100, Best RMSE: 1.9452786579083947\n",
      "Generation 10/100, Best RMSE: 1.9452786579083947\n",
      "Generation 11/100, Best RMSE: 1.9452373996957393\n",
      "Generation 12/100, Best RMSE: 1.9452355646183046\n",
      "Generation 13/100, Best RMSE: 1.945208603216113\n",
      "Generation 14/100, Best RMSE: 1.945182841744004\n",
      "Generation 15/100, Best RMSE: 1.945182841744004\n",
      "Generation 16/100, Best RMSE: 1.9451722941586926\n",
      "Generation 17/100, Best RMSE: 1.945023139991087\n",
      "Generation 18/100, Best RMSE: 1.945023139991087\n",
      "Generation 19/100, Best RMSE: 1.9450097951582566\n",
      "Generation 20/100, Best RMSE: 1.9450072062816024\n",
      "Generation 21/100, Best RMSE: 1.9450072062816024\n",
      "Generation 22/100, Best RMSE: 1.9450000121291602\n",
      "Generation 23/100, Best RMSE: 1.9449995251328034\n",
      "Generation 24/100, Best RMSE: 1.9449979292369117\n",
      "Generation 25/100, Best RMSE: 1.9449979292369117\n",
      "Generation 26/100, Best RMSE: 1.9449979292369117\n",
      "Generation 27/100, Best RMSE: 1.944997605128008\n",
      "Generation 28/100, Best RMSE: 1.9449972111640383\n",
      "Generation 29/100, Best RMSE: 1.944996883241411\n",
      "Generation 30/100, Best RMSE: 1.9449956707476517\n",
      "Generation 31/100, Best RMSE: 1.9449946046733722\n",
      "Generation 32/100, Best RMSE: 1.9449946046733722\n",
      "Generation 33/100, Best RMSE: 1.9449943429060048\n",
      "Generation 34/100, Best RMSE: 1.944994275841314\n",
      "Generation 35/100, Best RMSE: 1.944994275841314\n",
      "Generation 36/100, Best RMSE: 1.944994275841314\n",
      "Generation 37/100, Best RMSE: 1.944994275841314\n",
      "Generation 38/100, Best RMSE: 1.9449941178706849\n",
      "Generation 39/100, Best RMSE: 1.9449941178706849\n",
      "Generation 40/100, Best RMSE: 1.9449941178706849\n",
      "Generation 41/100, Best RMSE: 1.9449941178706849\n",
      "Generation 42/100, Best RMSE: 1.9449941178706849\n",
      "Generation 43/100, Best RMSE: 1.9449940684908955\n",
      "Generation 44/100, Best RMSE: 1.944961436215707\n",
      "Generation 45/100, Best RMSE: 1.9449591505684267\n",
      "Generation 46/100, Best RMSE: 1.9449591505684267\n",
      "Generation 47/100, Best RMSE: 1.9449591505684267\n",
      "Generation 48/100, Best RMSE: 1.9449542153640136\n",
      "Generation 49/100, Best RMSE: 1.9449542153640136\n",
      "Generation 50/100, Best RMSE: 1.9449542153640136\n",
      "Generation 51/100, Best RMSE: 1.9449542153640136\n",
      "Generation 52/100, Best RMSE: 1.9449484285090515\n",
      "Generation 53/100, Best RMSE: 1.9449481948191467\n",
      "Generation 54/100, Best RMSE: 1.9449480863424067\n",
      "Generation 55/100, Best RMSE: 1.9449477177986678\n",
      "Generation 56/100, Best RMSE: 1.9449477177986678\n",
      "Generation 57/100, Best RMSE: 1.944947713253137\n",
      "Generation 58/100, Best RMSE: 1.944947713253137\n",
      "Generation 59/100, Best RMSE: 1.9449475877552977\n",
      "Generation 60/100, Best RMSE: 1.9449473400063961\n",
      "Generation 61/100, Best RMSE: 1.9449473400063961\n",
      "Generation 62/100, Best RMSE: 1.9449473400063961\n",
      "Generation 63/100, Best RMSE: 1.9449473400063961\n",
      "Generation 64/100, Best RMSE: 1.9449472864554396\n",
      "Generation 65/100, Best RMSE: 1.944912244891164\n",
      "Generation 66/100, Best RMSE: 1.944912244891164\n",
      "Generation 67/100, Best RMSE: 1.944907319866687\n",
      "Generation 68/100, Best RMSE: 1.9449063757801006\n",
      "Generation 69/100, Best RMSE: 1.9449063757801006\n",
      "Generation 70/100, Best RMSE: 1.9449063757801006\n",
      "Generation 71/100, Best RMSE: 1.9449063757801006\n",
      "Generation 72/100, Best RMSE: 1.9449063757801006\n",
      "Generation 73/100, Best RMSE: 1.9449063757801006\n",
      "Generation 74/100, Best RMSE: 1.9449063757801006\n",
      "Generation 75/100, Best RMSE: 1.9449063757801006\n",
      "Generation 76/100, Best RMSE: 1.9449063757801006\n",
      "Generation 77/100, Best RMSE: 1.9449063757801006\n",
      "Generation 78/100, Best RMSE: 1.9449063757801006\n",
      "Generation 79/100, Best RMSE: 1.9449063757801006\n",
      "Generation 80/100, Best RMSE: 1.9449063757801006\n",
      "Generation 81/100, Best RMSE: 1.9449063747409536\n",
      "Generation 82/100, Best RMSE: 1.9449063607103008\n",
      "Generation 83/100, Best RMSE: 1.9449063442355474\n",
      "Generation 84/100, Best RMSE: 1.9449063442355474\n",
      "Generation 85/100, Best RMSE: 1.9449063310201937\n",
      "Generation 86/100, Best RMSE: 1.944906327444451\n",
      "Generation 87/100, Best RMSE: 1.9449063220898024\n",
      "Generation 88/100, Best RMSE: 1.9449063095924288\n",
      "Generation 89/100, Best RMSE: 1.9449062917894688\n",
      "Generation 90/100, Best RMSE: 1.9449062784736149\n",
      "Generation 91/100, Best RMSE: 1.9449062742836594\n",
      "Generation 92/100, Best RMSE: 1.9449062625001383\n",
      "Generation 93/100, Best RMSE: 1.9449062572706672\n",
      "Generation 94/100, Best RMSE: 1.9449062503772885\n",
      "Generation 95/100, Best RMSE: 1.9449062358540203\n",
      "Generation 96/100, Best RMSE: 1.9449062215298294\n",
      "Generation 97/100, Best RMSE: 1.9449062130251176\n",
      "Generation 98/100, Best RMSE: 1.9449062002094182\n",
      "Generation 99/100, Best RMSE: 1.944906197706784\n",
      "Generation 100/100, Best RMSE: 1.9449061809689594\n",
      "Optimal Weights: [0.43205361 0.01455957 0.         0.         0.55338682]\n",
      "(18, 5, 48, 2) (18, 48, 2)\n",
      "Generation 1/100, Best RMSE: 1.9065924644390724\n",
      "Generation 2/100, Best RMSE: 1.9037467690842422\n",
      "Generation 3/100, Best RMSE: 1.9001450431790803\n",
      "Generation 4/100, Best RMSE: 1.893722300565456\n",
      "Generation 5/100, Best RMSE: 1.893722300565456\n",
      "Generation 6/100, Best RMSE: 1.8921646524709919\n",
      "Generation 7/100, Best RMSE: 1.8893674122207997\n",
      "Generation 8/100, Best RMSE: 1.8837841878557453\n",
      "Generation 9/100, Best RMSE: 1.8837841878557453\n",
      "Generation 10/100, Best RMSE: 1.8837841878557453\n",
      "Generation 11/100, Best RMSE: 1.8837841878557453\n",
      "Generation 12/100, Best RMSE: 1.8837841878557453\n",
      "Generation 13/100, Best RMSE: 1.8833563756212983\n",
      "Generation 14/100, Best RMSE: 1.8833563756212983\n",
      "Generation 15/100, Best RMSE: 1.8820951499584666\n",
      "Generation 16/100, Best RMSE: 1.8820951499584666\n",
      "Generation 17/100, Best RMSE: 1.8820951499584666\n",
      "Generation 18/100, Best RMSE: 1.8820951499584666\n",
      "Generation 19/100, Best RMSE: 1.8820951499584666\n",
      "Generation 20/100, Best RMSE: 1.8820951499584666\n",
      "Generation 21/100, Best RMSE: 1.8820951499584666\n",
      "Generation 22/100, Best RMSE: 1.8820951499584666\n",
      "Generation 23/100, Best RMSE: 1.8820951499584666\n",
      "Generation 24/100, Best RMSE: 1.8820951499584666\n",
      "Generation 25/100, Best RMSE: 1.8820951499584666\n",
      "Generation 26/100, Best RMSE: 1.8820951499584666\n",
      "Generation 27/100, Best RMSE: 1.8820951499584666\n",
      "Generation 28/100, Best RMSE: 1.8820951499584666\n",
      "Generation 29/100, Best RMSE: 1.8820951499584666\n",
      "Generation 30/100, Best RMSE: 1.8820951499584666\n",
      "Generation 31/100, Best RMSE: 1.8820951499584666\n",
      "Generation 32/100, Best RMSE: 1.8820951499584666\n",
      "Generation 33/100, Best RMSE: 1.8820951499584666\n",
      "Generation 34/100, Best RMSE: 1.8820951499584666\n",
      "Generation 35/100, Best RMSE: 1.8820951499584666\n",
      "Generation 36/100, Best RMSE: 1.8820951499584666\n",
      "Generation 37/100, Best RMSE: 1.8820951499584666\n",
      "Generation 38/100, Best RMSE: 1.8820951499584666\n",
      "Generation 39/100, Best RMSE: 1.8820951499584666\n",
      "Generation 40/100, Best RMSE: 1.8820951499584666\n",
      "Generation 41/100, Best RMSE: 1.8820951499584666\n",
      "Generation 42/100, Best RMSE: 1.8820951499584666\n",
      "Generation 43/100, Best RMSE: 1.8820951499584666\n",
      "Generation 44/100, Best RMSE: 1.8820951499584666\n",
      "Generation 45/100, Best RMSE: 1.8820951499584666\n",
      "Generation 46/100, Best RMSE: 1.8820951499584666\n",
      "Generation 47/100, Best RMSE: 1.8820951499584666\n",
      "Generation 48/100, Best RMSE: 1.8820951499584666\n",
      "Generation 49/100, Best RMSE: 1.8820951499584666\n",
      "Generation 50/100, Best RMSE: 1.8820951499584666\n",
      "Generation 51/100, Best RMSE: 1.8820951499584666\n",
      "Generation 52/100, Best RMSE: 1.8820951499584666\n",
      "Generation 53/100, Best RMSE: 1.8820951499584666\n",
      "Generation 54/100, Best RMSE: 1.8820951499584666\n",
      "Generation 55/100, Best RMSE: 1.8820951499584666\n",
      "Generation 56/100, Best RMSE: 1.8820951499584666\n",
      "Generation 57/100, Best RMSE: 1.8820951499584666\n",
      "Generation 58/100, Best RMSE: 1.8820951499584666\n",
      "Generation 59/100, Best RMSE: 1.8820951499584666\n",
      "Generation 60/100, Best RMSE: 1.8820951499584666\n",
      "Generation 61/100, Best RMSE: 1.8820951499584666\n",
      "Generation 62/100, Best RMSE: 1.8820951499584666\n",
      "Generation 63/100, Best RMSE: 1.8820951499584666\n",
      "Generation 64/100, Best RMSE: 1.8820951499584666\n",
      "Generation 65/100, Best RMSE: 1.8820951499584666\n",
      "Generation 66/100, Best RMSE: 1.8820951499584666\n",
      "Generation 67/100, Best RMSE: 1.8820951499584666\n",
      "Generation 68/100, Best RMSE: 1.8820951499584666\n",
      "Generation 69/100, Best RMSE: 1.8820951499584666\n",
      "Generation 70/100, Best RMSE: 1.8820951499584666\n",
      "Generation 71/100, Best RMSE: 1.8820674596131122\n",
      "Generation 72/100, Best RMSE: 1.8820674596131122\n",
      "Generation 73/100, Best RMSE: 1.8820674596131122\n",
      "Generation 74/100, Best RMSE: 1.8820674596131122\n",
      "Generation 75/100, Best RMSE: 1.8820674596131122\n",
      "Generation 76/100, Best RMSE: 1.8820674596131122\n",
      "Generation 77/100, Best RMSE: 1.8820674596131122\n",
      "Generation 78/100, Best RMSE: 1.8820674596131122\n",
      "Generation 79/100, Best RMSE: 1.8820674596131122\n",
      "Generation 80/100, Best RMSE: 1.8820674596131122\n",
      "Generation 81/100, Best RMSE: 1.8820674596131122\n",
      "Generation 82/100, Best RMSE: 1.8820674596131122\n",
      "Generation 83/100, Best RMSE: 1.8820674596131122\n",
      "Generation 84/100, Best RMSE: 1.8820674596131122\n",
      "Generation 85/100, Best RMSE: 1.8820674596131122\n",
      "Generation 86/100, Best RMSE: 1.8820674596131122\n",
      "Generation 87/100, Best RMSE: 1.8820674596131122\n",
      "Generation 88/100, Best RMSE: 1.8820674596131122\n",
      "Generation 89/100, Best RMSE: 1.8820674596131122\n",
      "Generation 90/100, Best RMSE: 1.8820674596131122\n",
      "Generation 91/100, Best RMSE: 1.8820674596131122\n",
      "Generation 92/100, Best RMSE: 1.8820674596131122\n",
      "Generation 93/100, Best RMSE: 1.8820674596131122\n",
      "Generation 94/100, Best RMSE: 1.8820330539748957\n",
      "Generation 95/100, Best RMSE: 1.8820165328442795\n",
      "Generation 96/100, Best RMSE: 1.8820165328442795\n",
      "Generation 97/100, Best RMSE: 1.8820165328442795\n",
      "Generation 98/100, Best RMSE: 1.8820165328442795\n",
      "Generation 99/100, Best RMSE: 1.8820165305655052\n",
      "Generation 100/100, Best RMSE: 1.8820165292326203\n",
      "Optimal Weights: [0.35697415 0.         0.         0.         0.64302585]\n",
      "(26, 5, 48, 2) (26, 48, 2)\n",
      "Generation 1/100, Best RMSE: 1.889672149194226\n",
      "Generation 2/100, Best RMSE: 1.889672149194226\n",
      "Generation 3/100, Best RMSE: 1.889672149194226\n",
      "Generation 4/100, Best RMSE: 1.889672149194226\n",
      "Generation 5/100, Best RMSE: 1.889672149194226\n",
      "Generation 6/100, Best RMSE: 1.889672149194226\n",
      "Generation 7/100, Best RMSE: 1.8840246768388351\n",
      "Generation 8/100, Best RMSE: 1.8829293856857159\n",
      "Generation 9/100, Best RMSE: 1.8829293856857159\n",
      "Generation 10/100, Best RMSE: 1.882880072853278\n",
      "Generation 11/100, Best RMSE: 1.8827022641742888\n",
      "Generation 12/100, Best RMSE: 1.8827022641742888\n",
      "Generation 13/100, Best RMSE: 1.8825593040974369\n",
      "Generation 14/100, Best RMSE: 1.8825593040974369\n",
      "Generation 15/100, Best RMSE: 1.8825593040974369\n",
      "Generation 16/100, Best RMSE: 1.8825227167809282\n",
      "Generation 17/100, Best RMSE: 1.882387025738542\n",
      "Generation 18/100, Best RMSE: 1.8823846548168521\n",
      "Generation 19/100, Best RMSE: 1.8823844077722376\n",
      "Generation 20/100, Best RMSE: 1.882382800363417\n",
      "Generation 21/100, Best RMSE: 1.8823826453473114\n",
      "Generation 22/100, Best RMSE: 1.882381843894989\n",
      "Generation 23/100, Best RMSE: 1.882381843894989\n",
      "Generation 24/100, Best RMSE: 1.882381843894989\n",
      "Generation 25/100, Best RMSE: 1.882381843894989\n",
      "Generation 26/100, Best RMSE: 1.882381841024156\n",
      "Generation 27/100, Best RMSE: 1.8823818241199568\n",
      "Generation 28/100, Best RMSE: 1.8823818206685152\n",
      "Generation 29/100, Best RMSE: 1.8823818164486301\n",
      "Generation 30/100, Best RMSE: 1.8823817979487307\n",
      "Generation 31/100, Best RMSE: 1.8823817890126526\n",
      "Generation 32/100, Best RMSE: 1.8823817820901105\n",
      "Generation 33/100, Best RMSE: 1.882381779095772\n",
      "Generation 34/100, Best RMSE: 1.8823817694768972\n",
      "Generation 35/100, Best RMSE: 1.8823817680855413\n",
      "Generation 36/100, Best RMSE: 1.8823817680855413\n",
      "Generation 37/100, Best RMSE: 1.8823817661653113\n",
      "Generation 38/100, Best RMSE: 1.8823817558571827\n",
      "Generation 39/100, Best RMSE: 1.8823817542085666\n",
      "Generation 40/100, Best RMSE: 1.8823817528042661\n",
      "Generation 41/100, Best RMSE: 1.8823817528042661\n",
      "Generation 42/100, Best RMSE: 1.882381752735073\n",
      "Generation 43/100, Best RMSE: 1.8823817512455827\n",
      "Generation 44/100, Best RMSE: 1.8823817512455827\n",
      "Generation 45/100, Best RMSE: 1.8823817498243753\n",
      "Generation 46/100, Best RMSE: 1.8823817498243753\n",
      "Generation 47/100, Best RMSE: 1.8823817498243753\n",
      "Generation 48/100, Best RMSE: 1.8823817498243753\n",
      "Generation 49/100, Best RMSE: 1.8823817498243753\n",
      "Generation 50/100, Best RMSE: 1.8823817497159177\n",
      "Generation 51/100, Best RMSE: 1.8823817496970927\n",
      "Generation 52/100, Best RMSE: 1.8823817495496753\n",
      "Generation 53/100, Best RMSE: 1.8823817494184982\n",
      "Generation 54/100, Best RMSE: 1.882381749301767\n",
      "Generation 55/100, Best RMSE: 1.8823817492060568\n",
      "Generation 56/100, Best RMSE: 1.8823817491929487\n",
      "Generation 57/100, Best RMSE: 1.882381749098656\n",
      "Generation 58/100, Best RMSE: 1.8823817490892325\n",
      "Generation 59/100, Best RMSE: 1.882381749086241\n",
      "Generation 60/100, Best RMSE: 1.882381749000061\n",
      "Generation 61/100, Best RMSE: 1.882381748923424\n",
      "Generation 62/100, Best RMSE: 1.8823817489134407\n",
      "Generation 63/100, Best RMSE: 1.8823817489134407\n",
      "Generation 64/100, Best RMSE: 1.8823817489030807\n",
      "Generation 65/100, Best RMSE: 1.8823817488290433\n",
      "Generation 66/100, Best RMSE: 1.8823817487739072\n",
      "Generation 67/100, Best RMSE: 1.8823817487236976\n",
      "Generation 68/100, Best RMSE: 1.8823817486602201\n",
      "Generation 69/100, Best RMSE: 1.8823817486367238\n",
      "Generation 70/100, Best RMSE: 1.8823817485755623\n",
      "Generation 71/100, Best RMSE: 1.8823817485755623\n",
      "Generation 72/100, Best RMSE: 1.8823817485755623\n",
      "Generation 73/100, Best RMSE: 1.882381748521782\n",
      "Generation 74/100, Best RMSE: 1.8823817484791936\n",
      "Generation 75/100, Best RMSE: 1.8823817484747747\n",
      "Generation 76/100, Best RMSE: 1.8823817484715029\n",
      "Generation 77/100, Best RMSE: 1.8823817484460368\n",
      "Generation 78/100, Best RMSE: 1.8823817484279628\n",
      "Generation 79/100, Best RMSE: 1.8823817484062344\n",
      "Generation 80/100, Best RMSE: 1.8823817483839316\n",
      "Generation 81/100, Best RMSE: 1.8823817483608896\n",
      "Generation 82/100, Best RMSE: 1.8823817483243175\n",
      "Generation 83/100, Best RMSE: 1.8823817483243175\n",
      "Generation 84/100, Best RMSE: 1.882381748320465\n",
      "Generation 85/100, Best RMSE: 1.8823817482877823\n",
      "Generation 86/100, Best RMSE: 1.882381748263557\n",
      "Generation 87/100, Best RMSE: 1.8823817482596807\n",
      "Generation 88/100, Best RMSE: 1.8823817482560354\n",
      "Generation 89/100, Best RMSE: 1.8823817482222123\n",
      "Generation 90/100, Best RMSE: 1.8823817482222123\n",
      "Generation 91/100, Best RMSE: 1.8823817481973775\n",
      "Generation 92/100, Best RMSE: 1.882381748193771\n",
      "Generation 93/100, Best RMSE: 1.8823817481667362\n",
      "Generation 94/100, Best RMSE: 1.882381748165949\n",
      "Generation 95/100, Best RMSE: 1.882381748141611\n",
      "Generation 96/100, Best RMSE: 1.8823817481406377\n",
      "Generation 97/100, Best RMSE: 1.8823817481406375\n",
      "Generation 98/100, Best RMSE: 1.8823817481160792\n",
      "Generation 99/100, Best RMSE: 1.8823817481143204\n",
      "Generation 100/100, Best RMSE: 1.882381748103877\n",
      "Optimal Weights: [0.8902205  0.         0.09566673 0.01411277 0.        ]\n"
     ]
    }
   ],
   "source": [
    "# 새로운 블록: GA 실행 및 최적 가중치 찾기\n",
    "input_directory = 'ga_s3'\n",
    "optimal_weights_list=[]\n",
    "for month in range(1, 13):\n",
    "    try:\n",
    "\n",
    "        model_predictions, true_values = load_and_process_validation_data(input_directory, month)\n",
    "        print(model_predictions.shape, true_values.shape)\n",
    "        if len(model_predictions) == 0 or len(true_values) == 0:\n",
    "            print(f\"{month}월: 데이터가 부족하여 건너뜁니다.\")\n",
    "            continue\n",
    "\n",
    "        # GA 실행하여 최적 가중치 찾기\n",
    "        optimal_weights = genetic_algorithm_with_elitism(\n",
    "            model_predictions, true_values, population_size=100, generations=100, mutation_rate=0.03\n",
    "        )\n",
    "        optimal_weights_list.append(optimal_weights)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"{month}월 처리 중 오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57055253 0.         0.01078756 0.16910843 0.24955148]\n",
      "[0.89326787 0.01718011 0.08480656 0.         0.00474546]\n",
      "[0.87158191 0.         0.01500284 0.         0.11341526]\n",
      "[0.48293436 0.         0.         0.01971699 0.49734865]\n",
      "[0.73229964 0.         0.         0.         0.26770036]\n",
      "[0.29015045 0.19695908 0.34140963 0.         0.17148084]\n",
      "[0.43500006 0.         0.         0.14708702 0.41791292]\n",
      "[0.83995537 0.         0.         0.12841461 0.03163001]\n",
      "[0.58545155 0.         0.27482755 0.         0.1397209 ]\n",
      "[0.43205361 0.01455957 0.         0.         0.55338682]\n",
      "[0.35697415 0.         0.         0.         0.64302585]\n",
      "[0.8902205  0.         0.09566673 0.01411277 0.        ]\n"
     ]
    }
   ],
   "source": [
    "for i in optimal_weights_list:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_and_process_test_data(input_directory, month, models=5, time_window=48):\n",
    "    \"\"\"\n",
    "    Test 데이터를 로드하고, 모델 예측값과 True 값을 추출해 시간 단위로 이어붙이기\n",
    "\n",
    "    Args:\n",
    "        input_directory (str): 모델별 test 데이터가 있는 디렉토리\n",
    "        month (int): 처리할 월\n",
    "        models (int): 모델 개수 (default=5)\n",
    "        time_window (int): 샘플당 시간 창 (default=48)\n",
    "\n",
    "    Returns:\n",
    "        model_predictions (np.ndarray): (n_samples, models, time_window, 2)\n",
    "        true_values (np.ndarray): (n_samples, time_window, 2)\n",
    "    \"\"\"\n",
    "    model_predictions = []  # 모델별 예측값 저장\n",
    "    true_values = None  # True U, True V 저장\n",
    "\n",
    "    for model_idx in range(1, models + 1):\n",
    "        model_dir = os.path.join(input_directory, f\"model{model_idx}\")\n",
    "        file_path = os.path.join(model_dir, f'test_month_{month}_model_{model_idx}_results.csv')\n",
    "\n",
    "        # 파일 존재 여부 확인\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"Warning: {file_path} not found. Skipping model {model_idx}.\")\n",
    "            continue\n",
    "\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # NaN 값 확인\n",
    "        if df.isnull().values.any():\n",
    "            print(f\"NaN found in Model {model_idx} test results for month {month}:\")\n",
    "            print(df.isnull().sum())\n",
    "\n",
    "        # 모델 예측값 추출\n",
    "        pred_u = df[f\"Model {model_idx} Test Pred U\"].values\n",
    "        pred_v = df[f\"Model {model_idx} Test Pred V\"].values\n",
    "\n",
    "        # 데이터 부족 시 예외 처리\n",
    "        n_samples = len(pred_u) // time_window\n",
    "        if n_samples == 0:\n",
    "            print(f\"Warning: Insufficient data for model {model_idx} in month {month}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        pred_u = pred_u[:n_samples * time_window].reshape(n_samples, time_window, 1)\n",
    "        pred_v = pred_v[:n_samples * time_window].reshape(n_samples, time_window, 1)\n",
    "        model_data = np.concatenate([pred_u, pred_v], axis=2)  # (n_samples, 48, 2)\n",
    "\n",
    "        # 모델별 예측값 저장\n",
    "        model_predictions.append(model_data)\n",
    "\n",
    "        # True U와 True V 추출 (첫 번째 모델 파일에서만 처리)\n",
    "        if model_idx == 1:\n",
    "            true_u = df[\"True U\"].values[:n_samples * time_window].reshape(n_samples, time_window, 1)\n",
    "            true_v = df[\"True V\"].values[:n_samples * time_window].reshape(n_samples, time_window, 1)\n",
    "            true_values = np.concatenate([true_u, true_v], axis=2)\n",
    "\n",
    "    # 모델 예측값 형태 변환: (n_samples, models, 48, 2)\n",
    "    if model_predictions:\n",
    "        model_predictions = np.stack(model_predictions, axis=1)\n",
    "    else:\n",
    "        raise ValueError(\"No valid data found for any model.\")\n",
    "\n",
    "    # True Values가 정상적으로 로드되었는지 확인\n",
    "    if true_values is None:\n",
    "        raise ValueError(\"True values could not be extracted.\")\n",
    "\n",
    "    print(f\"Processed Month {month} - Model Predictions Shape: {model_predictions.shape}\")\n",
    "    print(f\"Processed Month {month} - True Values Shape: {true_values.shape}\")\n",
    "\n",
    "    return model_predictions, true_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Month 1 - Model Predictions Shape: (26, 5, 48, 2)\n",
      "Processed Month 1 - True Values Shape: (26, 48, 2)\n",
      "\n",
      "Month 1 - Model Predictions Shape: (26, 5, 48, 2)\n",
      "Month 1 - True Values Shape: (26, 48, 2)\n",
      "Month 1 - RMSE: 2.0867\n",
      "Processed Month 2 - Model Predictions Shape: (25, 5, 48, 2)\n",
      "Processed Month 2 - True Values Shape: (25, 48, 2)\n",
      "\n",
      "Month 2 - Model Predictions Shape: (25, 5, 48, 2)\n",
      "Month 2 - True Values Shape: (25, 48, 2)\n",
      "Month 2 - RMSE: 2.2926\n",
      "Processed Month 3 - Model Predictions Shape: (28, 5, 48, 2)\n",
      "Processed Month 3 - True Values Shape: (28, 48, 2)\n",
      "\n",
      "Month 3 - Model Predictions Shape: (28, 5, 48, 2)\n",
      "Month 3 - True Values Shape: (28, 48, 2)\n",
      "Month 3 - RMSE: 2.3402\n",
      "Processed Month 4 - Model Predictions Shape: (20, 5, 48, 2)\n",
      "Processed Month 4 - True Values Shape: (20, 48, 2)\n",
      "\n",
      "Month 4 - Model Predictions Shape: (20, 5, 48, 2)\n",
      "Month 4 - True Values Shape: (20, 48, 2)\n",
      "Month 4 - RMSE: 2.5049\n",
      "Processed Month 5 - Model Predictions Shape: (18, 5, 48, 2)\n",
      "Processed Month 5 - True Values Shape: (18, 48, 2)\n",
      "\n",
      "Month 5 - Model Predictions Shape: (18, 5, 48, 2)\n",
      "Month 5 - True Values Shape: (18, 48, 2)\n",
      "Month 5 - RMSE: 1.7762\n",
      "Processed Month 6 - Model Predictions Shape: (18, 5, 48, 2)\n",
      "Processed Month 6 - True Values Shape: (18, 48, 2)\n",
      "\n",
      "Month 6 - Model Predictions Shape: (18, 5, 48, 2)\n",
      "Month 6 - True Values Shape: (18, 48, 2)\n",
      "Month 6 - RMSE: 2.3236\n",
      "Processed Month 7 - Model Predictions Shape: (15, 5, 48, 2)\n",
      "Processed Month 7 - True Values Shape: (15, 48, 2)\n",
      "\n",
      "Month 7 - Model Predictions Shape: (15, 5, 48, 2)\n",
      "Month 7 - True Values Shape: (15, 48, 2)\n",
      "Month 7 - RMSE: 2.2944\n",
      "Processed Month 8 - Model Predictions Shape: (24, 5, 48, 2)\n",
      "Processed Month 8 - True Values Shape: (24, 48, 2)\n",
      "\n",
      "Month 8 - Model Predictions Shape: (24, 5, 48, 2)\n",
      "Month 8 - True Values Shape: (24, 48, 2)\n",
      "Month 8 - RMSE: 2.1726\n",
      "Processed Month 9 - Model Predictions Shape: (21, 5, 48, 2)\n",
      "Processed Month 9 - True Values Shape: (21, 48, 2)\n",
      "\n",
      "Month 9 - Model Predictions Shape: (21, 5, 48, 2)\n",
      "Month 9 - True Values Shape: (21, 48, 2)\n",
      "Month 9 - RMSE: 3.0136\n",
      "Processed Month 10 - Model Predictions Shape: (14, 5, 48, 2)\n",
      "Processed Month 10 - True Values Shape: (14, 48, 2)\n",
      "\n",
      "Month 10 - Model Predictions Shape: (14, 5, 48, 2)\n",
      "Month 10 - True Values Shape: (14, 48, 2)\n",
      "Month 10 - RMSE: 2.3361\n",
      "Processed Month 11 - Model Predictions Shape: (23, 5, 48, 2)\n",
      "Processed Month 11 - True Values Shape: (23, 48, 2)\n",
      "\n",
      "Month 11 - Model Predictions Shape: (23, 5, 48, 2)\n",
      "Month 11 - True Values Shape: (23, 48, 2)\n",
      "Month 11 - RMSE: 2.0135\n",
      "Processed Month 12 - Model Predictions Shape: (18, 5, 48, 2)\n",
      "Processed Month 12 - True Values Shape: (18, 48, 2)\n",
      "\n",
      "Month 12 - Model Predictions Shape: (18, 5, 48, 2)\n",
      "Month 12 - True Values Shape: (18, 48, 2)\n",
      "Month 12 - RMSE: 2.1271\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    input_directory = \"./ga_s3\"\n",
    "    \n",
    "    # 1월부터 12월까지 데이터 로드 및 출력\n",
    "    for month in range(1, 13):\n",
    "        try:\n",
    "            model_predictions, true_values = load_and_process_test_data(input_directory, month)\n",
    "            print(f\"\\nMonth {month} - Model Predictions Shape: {model_predictions.shape}\")\n",
    "            print(f\"Month {month} - True Values Shape: {true_values.shape}\")\n",
    "            \n",
    "            # 추가적인 데이터 분석 또는 모델 평가 수행 가능\n",
    "            # 예시: 전체 RMSE 계산\n",
    "            mse = np.mean((model_predictions.mean(axis=1) - true_values) ** 2)\n",
    "            rmse = np.sqrt(mse)\n",
    "            print(f\"Month {month} - RMSE: {rmse:.4f}\")\n",
    "\n",
    "        except ValueError as e:\n",
    "            print(f\"Skipping month {month} due to error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def calculate_ensemble_rmse(model_predictions, true_values, weights, output_steps):\n",
    "    \"\"\"\n",
    "    최적 가중치를 사용하여 앙상블 예측값을 저장하고 나중에 RMSE를 계산\n",
    "\n",
    "    Args:\n",
    "        model_predictions (np.ndarray): 모델 예측값 (n_samples, models, time_window, 2)\n",
    "        true_values (np.ndarray): 실제 값 (n_samples, time_window, 2)\n",
    "        weights (np.ndarray): 최적 가중치 (models,)\n",
    "        output_steps (int): 예측 타임스텝 수\n",
    "\n",
    "    Returns:\n",
    "        results_dict (dict): 예측값과 실제값 저장 딕셔너리\n",
    "        overall_rmse (float): 전체 평균 RMSE\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"NaN in model_predictions: {np.isnan(model_predictions).any()}\")\n",
    "    print(f\"NaN in true_values: {np.isnan(true_values).any()}\")\n",
    "\n",
    "    # 입력 데이터 형태 검증\n",
    "    if model_predictions.ndim != 4 or true_values.ndim != 3:\n",
    "        raise ValueError(\"입력 데이터의 형태가 올바르지 않습니다. \"\n",
    "                         \"model_predictions는 (n_samples, models, time_window, 2) 형태여야 하고, \"\n",
    "                         \"true_values는 (n_samples, time_window, 2) 형태여야 합니다.\")\n",
    "\n",
    "    n_samples, n_models, time_window, _ = model_predictions.shape\n",
    "\n",
    "    # 디버깅 출력\n",
    "    print(f\"model_predictions.shape: {model_predictions.shape}\")\n",
    "    print(f\"true_values.shape: {true_values.shape}\")\n",
    "    print(f\"weights.shape: {weights.shape}\")\n",
    "    print(f\"weights: {weights}\")\n",
    "    print(f\"time_window: {time_window}, output_steps: {output_steps}\")\n",
    "\n",
    "    # weights 크기 검증\n",
    "    if len(weights) != n_models:\n",
    "        raise ValueError(f\"weights 길이({len(weights)})가 모델 개수({n_models})와 일치하지 않습니다.\")\n",
    "\n",
    "    # weights 합 검증\n",
    "    if not np.isclose(np.sum(weights), 1.0):\n",
    "        raise ValueError(f\"weights의 합({np.sum(weights)})이 1이 아닙니다. 앙상블 결과가 왜곡될 수 있습니다.\")\n",
    "\n",
    "    # 앙상블 예측값 계산 (가중치 적용)\n",
    "    ensemble_predictions = np.tensordot(model_predictions, weights, axes=(1, 0))  # (n_samples, time_window, 2)\n",
    "\n",
    "    # 예측값과 실제값을 저장할 딕셔너리 초기화\n",
    "    results_dict = {i: {'predictions': [], 'true_values': []} for i in range(time_window)}\n",
    "\n",
    "    # 예측값과 실제값 저장\n",
    "    for i in range(time_window):  # 전체 time_window만큼 반복\n",
    "        results_dict[i]['predictions'].extend(ensemble_predictions[:, i, :].tolist())\n",
    "        results_dict[i]['true_values'].extend(true_values[:, i, :].tolist())\n",
    "\n",
    "    # 전체 RMSE 계산\n",
    "    all_predictions = np.concatenate(\n",
    "        [np.array(results_dict[i]['predictions']) for i in range(time_window)], axis=0\n",
    "    )\n",
    "    all_true_values = np.concatenate(\n",
    "        [np.array(results_dict[i]['true_values']) for i in range(time_window)], axis=0\n",
    "    )\n",
    "    mse = mean_squared_error(all_true_values, all_predictions, multioutput=\"uniform_average\")\n",
    "    overall_rmse = np.sqrt(mse)\n",
    "\n",
    "\n",
    "    return results_dict, round(overall_rmse, 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Month 1 - Model Predictions Shape: (26, 5, 48, 2)\n",
      "Processed Month 1 - True Values Shape: (26, 48, 2)\n",
      "(26, 5, 48, 2)\n",
      "Ensemble Predictions Shape: (26, 48, 2)\n",
      "(1248, 2)\n",
      "Processed Month 2 - Model Predictions Shape: (25, 5, 48, 2)\n",
      "Processed Month 2 - True Values Shape: (25, 48, 2)\n",
      "(25, 5, 48, 2)\n",
      "Ensemble Predictions Shape: (25, 48, 2)\n",
      "(1200, 2)\n",
      "Processed Month 3 - Model Predictions Shape: (28, 5, 48, 2)\n",
      "Processed Month 3 - True Values Shape: (28, 48, 2)\n",
      "(28, 5, 48, 2)\n",
      "Ensemble Predictions Shape: (28, 48, 2)\n",
      "(1344, 2)\n",
      "Processed Month 4 - Model Predictions Shape: (20, 5, 48, 2)\n",
      "Processed Month 4 - True Values Shape: (20, 48, 2)\n",
      "(20, 5, 48, 2)\n",
      "Ensemble Predictions Shape: (20, 48, 2)\n",
      "(960, 2)\n",
      "Processed Month 5 - Model Predictions Shape: (18, 5, 48, 2)\n",
      "Processed Month 5 - True Values Shape: (18, 48, 2)\n",
      "(18, 5, 48, 2)\n",
      "Ensemble Predictions Shape: (18, 48, 2)\n",
      "(864, 2)\n",
      "Processed Month 6 - Model Predictions Shape: (18, 5, 48, 2)\n",
      "Processed Month 6 - True Values Shape: (18, 48, 2)\n",
      "(18, 5, 48, 2)\n",
      "Ensemble Predictions Shape: (18, 48, 2)\n",
      "(864, 2)\n",
      "Processed Month 7 - Model Predictions Shape: (15, 5, 48, 2)\n",
      "Processed Month 7 - True Values Shape: (15, 48, 2)\n",
      "(15, 5, 48, 2)\n",
      "Ensemble Predictions Shape: (15, 48, 2)\n",
      "(720, 2)\n",
      "Processed Month 8 - Model Predictions Shape: (24, 5, 48, 2)\n",
      "Processed Month 8 - True Values Shape: (24, 48, 2)\n",
      "(24, 5, 48, 2)\n",
      "Ensemble Predictions Shape: (24, 48, 2)\n",
      "(1152, 2)\n",
      "Processed Month 9 - Model Predictions Shape: (21, 5, 48, 2)\n",
      "Processed Month 9 - True Values Shape: (21, 48, 2)\n",
      "(21, 5, 48, 2)\n",
      "Ensemble Predictions Shape: (21, 48, 2)\n",
      "(1008, 2)\n",
      "Processed Month 10 - Model Predictions Shape: (14, 5, 48, 2)\n",
      "Processed Month 10 - True Values Shape: (14, 48, 2)\n",
      "(14, 5, 48, 2)\n",
      "Ensemble Predictions Shape: (14, 48, 2)\n",
      "(672, 2)\n",
      "Processed Month 11 - Model Predictions Shape: (23, 5, 48, 2)\n",
      "Processed Month 11 - True Values Shape: (23, 48, 2)\n",
      "(23, 5, 48, 2)\n",
      "Ensemble Predictions Shape: (23, 48, 2)\n",
      "(1104, 2)\n",
      "Processed Month 12 - Model Predictions Shape: (18, 5, 48, 2)\n",
      "Processed Month 12 - True Values Shape: (18, 48, 2)\n",
      "(18, 5, 48, 2)\n",
      "Ensemble Predictions Shape: (18, 48, 2)\n",
      "(864, 2)\n",
      "\n",
      "시간별 평균 RMSE:\n",
      "시간 0: 1.6605109459844953\n",
      "시간 1: 1.7454601993190557\n",
      "시간 2: 1.7742050197983623\n",
      "시간 3: 1.7969918098068203\n",
      "시간 4: 1.7513878186332628\n",
      "시간 5: 1.7779089975876028\n",
      "시간 6: 1.8157323180697802\n",
      "시간 7: 1.9356023868789605\n",
      "시간 8: 1.968110760908844\n",
      "시간 9: 1.994628735954662\n",
      "시간 10: 2.0870073612084714\n",
      "시간 11: 2.1714135795974765\n",
      "시간 12: 2.136494007617736\n",
      "시간 13: 2.154645988862589\n",
      "시간 14: 2.209534475584293\n",
      "시간 15: 2.166102649741361\n",
      "시간 16: 2.172343758348179\n",
      "시간 17: 2.235608361741674\n",
      "시간 18: 2.2899194830479495\n",
      "시간 19: 2.4914442420699774\n",
      "시간 20: 2.4733054173437004\n",
      "시간 21: 2.33543514719997\n",
      "시간 22: 2.1762465770580603\n",
      "시간 23: 2.1436757852376056\n",
      "시간 24: 2.1730652507483916\n",
      "시간 25: 2.217174257494778\n",
      "시간 26: 2.1210900158131722\n",
      "시간 27: 2.1175380892646154\n",
      "시간 28: 2.108108939993365\n",
      "시간 29: 2.0745390359272853\n",
      "시간 30: 2.0491446899641654\n",
      "시간 31: 2.1484280506661726\n",
      "시간 32: 2.2246691824418434\n",
      "시간 33: 2.30061569824777\n",
      "시간 34: 2.3540406431944927\n",
      "시간 35: 2.4039243200797444\n",
      "시간 36: 2.345671484186283\n",
      "시간 37: 2.314824085460223\n",
      "시간 38: 2.466550860469624\n",
      "시간 39: 2.529838524907492\n",
      "시간 40: 2.487204423355556\n",
      "시간 41: 2.51624702404314\n",
      "시간 42: 2.6669985474607425\n",
      "시간 43: 2.8549486304315512\n",
      "시간 44: 2.871431141436824\n",
      "시간 45: 2.785932325937553\n",
      "시간 46: 2.7335729509780027\n",
      "시간 47: 2.834079573980022\n",
      "\n",
      "전체 평균 RMSE:\n",
      "uniform 월별 전체 평균 RMSE: 2.27345857299111\n",
      "uniform 그룹별 전체 평균 RMSE: 2.232569866126744\n"
     ]
    }
   ],
   "source": [
    "def calculate_uniform_ensemble_rmse(model_predictions, true_values):\n",
    "    n_samples, n_models, time_window, n_features = model_predictions.shape\n",
    "\n",
    "    # 동일 가중치 설정\n",
    "    weights = np.array([1.0 / n_models] * n_models).reshape(1, -1, 1, 1)\n",
    "    ensemble_predictions = np.sum(model_predictions * weights, axis=1)\n",
    "\n",
    "\n",
    "    print(f\"Ensemble Predictions Shape: {ensemble_predictions.shape}\")\n",
    "\n",
    "    results_dict = {i: [] for i in range(time_window)}\n",
    "\n",
    "    for i in range(time_window):\n",
    "        predictions_sample = ensemble_predictions[:, i, :]\n",
    "        true_values_sample = true_values[:, i, :]\n",
    "\n",
    "        mse = mean_squared_error(true_values_sample, predictions_sample, multioutput='uniform_average')\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        results_dict[i].append(rmse)\n",
    "\n",
    "    all_predictions = ensemble_predictions.reshape(-1, n_features)\n",
    "    all_true_values = true_values.reshape(-1, n_features)\n",
    "    print(all_true_values.shape)\n",
    "    overall_mse = mean_squared_error(all_true_values, all_predictions, multioutput='uniform_average')\n",
    "    overall_rmse = np.sqrt(overall_mse)\n",
    "\n",
    "    return results_dict, overall_rmse\n",
    "\n",
    "\n",
    "def calculate_groupwise_rmse(all_results):\n",
    "    time_window = len(all_results[0])\n",
    "    average_rmse = {i: [] for i in range(time_window)}\n",
    "\n",
    "    for month_results in all_results:\n",
    "        for key, rmse_list in month_results.items():\n",
    "            average_rmse[key].extend(rmse_list)\n",
    "\n",
    "    groupwise_rmse = {key: np.mean(rmse_list) for key, rmse_list in average_rmse.items()}\n",
    "    overall_rmse = np.mean(list(groupwise_rmse.values()))\n",
    "\n",
    "    return groupwise_rmse, overall_rmse\n",
    "\n",
    "\n",
    "def main():\n",
    "    input_directory = \"./ga_s3\"\n",
    "    all_results = []\n",
    "    overall_rmse_list = []\n",
    "\n",
    "    for month in range(1, 13):\n",
    "        model_predictions, true_values = load_and_process_test_data(input_directory, month)\n",
    "        print(model_predictions.shape)\n",
    "        print\n",
    "        results_dict, overall_rmse = calculate_uniform_ensemble_rmse(model_predictions, true_values)\n",
    "\n",
    "        all_results.append(results_dict)\n",
    "        overall_rmse_list.append(overall_rmse)\n",
    "\n",
    "    groupwise_rmse, overall_rmse = calculate_groupwise_rmse(all_results)\n",
    "\n",
    "    print(\"\\n시간별 평균 RMSE:\")\n",
    "    for time, rmse in groupwise_rmse.items():\n",
    "        print(f\"시간 {time}: {rmse}\")\n",
    "\n",
    "    print(\"\\n전체 평균 RMSE:\")\n",
    "    print(f\"uniform 월별 전체 평균 RMSE: {np.mean(overall_rmse_list)}\")\n",
    "    print(f\"uniform 그룹별 전체 평균 RMSE: {overall_rmse}\")\n",
    "\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Month 1 - Model Predictions Shape: (26, 5, 48, 2)\n",
      "Processed Month 1 - True Values Shape: (26, 48, 2)\n",
      "Month 1 - Model Predictions Shape: (26, 5, 48, 2)\n",
      "Selected Model 4 Predictions Shape: (26, 48, 2)\n",
      "Processed Month 2 - Model Predictions Shape: (25, 5, 48, 2)\n",
      "Processed Month 2 - True Values Shape: (25, 48, 2)\n",
      "Month 2 - Model Predictions Shape: (25, 5, 48, 2)\n",
      "Selected Model 4 Predictions Shape: (25, 48, 2)\n",
      "Processed Month 3 - Model Predictions Shape: (28, 5, 48, 2)\n",
      "Processed Month 3 - True Values Shape: (28, 48, 2)\n",
      "Month 3 - Model Predictions Shape: (28, 5, 48, 2)\n",
      "Selected Model 4 Predictions Shape: (28, 48, 2)\n",
      "Processed Month 4 - Model Predictions Shape: (20, 5, 48, 2)\n",
      "Processed Month 4 - True Values Shape: (20, 48, 2)\n",
      "Month 4 - Model Predictions Shape: (20, 5, 48, 2)\n",
      "Selected Model 4 Predictions Shape: (20, 48, 2)\n",
      "Processed Month 5 - Model Predictions Shape: (18, 5, 48, 2)\n",
      "Processed Month 5 - True Values Shape: (18, 48, 2)\n",
      "Month 5 - Model Predictions Shape: (18, 5, 48, 2)\n",
      "Selected Model 4 Predictions Shape: (18, 48, 2)\n",
      "Processed Month 6 - Model Predictions Shape: (18, 5, 48, 2)\n",
      "Processed Month 6 - True Values Shape: (18, 48, 2)\n",
      "Month 6 - Model Predictions Shape: (18, 5, 48, 2)\n",
      "Selected Model 4 Predictions Shape: (18, 48, 2)\n",
      "Processed Month 7 - Model Predictions Shape: (15, 5, 48, 2)\n",
      "Processed Month 7 - True Values Shape: (15, 48, 2)\n",
      "Month 7 - Model Predictions Shape: (15, 5, 48, 2)\n",
      "Selected Model 4 Predictions Shape: (15, 48, 2)\n",
      "Processed Month 8 - Model Predictions Shape: (24, 5, 48, 2)\n",
      "Processed Month 8 - True Values Shape: (24, 48, 2)\n",
      "Month 8 - Model Predictions Shape: (24, 5, 48, 2)\n",
      "Selected Model 4 Predictions Shape: (24, 48, 2)\n",
      "Processed Month 9 - Model Predictions Shape: (21, 5, 48, 2)\n",
      "Processed Month 9 - True Values Shape: (21, 48, 2)\n",
      "Month 9 - Model Predictions Shape: (21, 5, 48, 2)\n",
      "Selected Model 4 Predictions Shape: (21, 48, 2)\n",
      "Processed Month 10 - Model Predictions Shape: (14, 5, 48, 2)\n",
      "Processed Month 10 - True Values Shape: (14, 48, 2)\n",
      "Month 10 - Model Predictions Shape: (14, 5, 48, 2)\n",
      "Selected Model 4 Predictions Shape: (14, 48, 2)\n",
      "Processed Month 11 - Model Predictions Shape: (23, 5, 48, 2)\n",
      "Processed Month 11 - True Values Shape: (23, 48, 2)\n",
      "Month 11 - Model Predictions Shape: (23, 5, 48, 2)\n",
      "Selected Model 4 Predictions Shape: (23, 48, 2)\n",
      "Processed Month 12 - Model Predictions Shape: (18, 5, 48, 2)\n",
      "Processed Month 12 - True Values Shape: (18, 48, 2)\n",
      "Month 12 - Model Predictions Shape: (18, 5, 48, 2)\n",
      "Selected Model 4 Predictions Shape: (18, 48, 2)\n",
      "\n",
      "시간별 평균 RMSE (Model 4):\n",
      "시간 0: 1.5995226478201126\n",
      "시간 1: 1.708068566765536\n",
      "시간 2: 1.7118568228469853\n",
      "시간 3: 1.7600171993338385\n",
      "시간 4: 1.7216434619754706\n",
      "시간 5: 1.715384686713781\n",
      "시간 6: 1.7563877755817183\n",
      "시간 7: 1.8915597050685842\n",
      "시간 8: 1.951675789411813\n",
      "시간 9: 2.0048377426740833\n",
      "시간 10: 2.0941493775523337\n",
      "시간 11: 2.1453440908755326\n",
      "시간 12: 2.0971232475287427\n",
      "시간 13: 2.0673934403761103\n",
      "시간 14: 2.1325513598515005\n",
      "시간 15: 2.070279322149554\n",
      "시간 16: 2.0884796090856366\n",
      "시간 17: 2.16180221515944\n",
      "시간 18: 2.239812487130673\n",
      "시간 19: 2.444640546781368\n",
      "시간 20: 2.4644153537892537\n",
      "시간 21: 2.3251959595504044\n",
      "시간 22: 2.1598577466906757\n",
      "시간 23: 2.10554579870578\n",
      "시간 24: 2.139733116878134\n",
      "시간 25: 2.1591107818656927\n",
      "시간 26: 2.0824045424941953\n",
      "시간 27: 2.091678660508805\n",
      "시간 28: 2.1117896596006154\n",
      "시간 29: 2.053868275119295\n",
      "시간 30: 2.0697655733065683\n",
      "시간 31: 2.1737321754299845\n",
      "시간 32: 2.2858235024222533\n",
      "시간 33: 2.376271679655696\n",
      "시간 34: 2.4215373892474115\n",
      "시간 35: 2.430533611000058\n",
      "시간 36: 2.3470850190332375\n",
      "시간 37: 2.271298864510977\n",
      "시간 38: 2.387036766606165\n",
      "시간 39: 2.3929033249578704\n",
      "시간 40: 2.302010710761966\n",
      "시간 41: 2.3547711669250817\n",
      "시간 42: 2.4965921770445347\n",
      "시간 43: 2.7591110294793477\n",
      "시간 44: 2.8060023249239925\n",
      "시간 45: 2.7464776777586017\n",
      "시간 46: 2.727332828470306\n",
      "시간 47: 2.8146927357005187\n",
      "\n",
      "전체 평균 RMSE (Model 4):\n",
      "Model 4 월별 전체 평균 RMSE: 2.2329600738898536\n",
      "Model 4 그룹별 전체 평균 RMSE: 2.1920647613983384\n"
     ]
    }
   ],
   "source": [
    "def calculate_single_model_rmse(model_predictions, true_values, model_index=4):\n",
    "    n_samples, n_models, time_window, n_features = model_predictions.shape\n",
    "\n",
    "    # 특정 모델의 예측값만 선택\n",
    "    selected_model_predictions = model_predictions[:, model_index, :, :]\n",
    "    print(f\"Selected Model {model_index} Predictions Shape: {selected_model_predictions.shape}\")\n",
    "\n",
    "    results_dict = {i: [] for i in range(time_window)}\n",
    "\n",
    "    for i in range(time_window):\n",
    "        predictions_sample = selected_model_predictions[:, i, :]\n",
    "        true_values_sample = true_values[:, i, :]\n",
    "\n",
    "        mse = mean_squared_error(true_values_sample, predictions_sample, multioutput='uniform_average')\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        results_dict[i].append(rmse)\n",
    "\n",
    "    all_predictions = selected_model_predictions.reshape(-1, n_features)\n",
    "    all_true_values = true_values.reshape(-1, n_features)\n",
    "    \n",
    "    overall_mse = mean_squared_error(all_true_values, all_predictions, multioutput='uniform_average')\n",
    "    overall_rmse = np.sqrt(overall_mse)\n",
    "\n",
    "    return results_dict, overall_rmse\n",
    "\n",
    "\n",
    "def main():\n",
    "    input_directory = \"./ga_s3\"\n",
    "    all_results = []\n",
    "    overall_rmse_list = []\n",
    "\n",
    "    for month in range(1, 13):\n",
    "        model_predictions, true_values = load_and_process_test_data(input_directory, month)\n",
    "        print(f\"Month {month} - Model Predictions Shape: {model_predictions.shape}\")\n",
    "\n",
    "        # 모델 인덱스 4의 RMSE 계산\n",
    "        results_dict, overall_rmse = calculate_single_model_rmse(model_predictions, true_values, 4)\n",
    "\n",
    "        all_results.append(results_dict)\n",
    "        overall_rmse_list.append(overall_rmse)\n",
    "\n",
    "    groupwise_rmse, overall_rmse = calculate_groupwise_rmse(all_results)\n",
    "\n",
    "    print(\"\\n시간별 평균 RMSE (Model 4):\")\n",
    "    for time, rmse in groupwise_rmse.items():\n",
    "        print(f\"시간 {time}: {rmse}\")\n",
    "\n",
    "    print(\"\\n전체 평균 RMSE (Model 4):\")\n",
    "    print(f\"Model 4 월별 전체 평균 RMSE: {np.mean(overall_rmse_list)}\")\n",
    "    print(f\"Model 4 그룹별 전체 평균 RMSE: {overall_rmse}\")\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing month 1 data...\n",
      "Processed Month 1 - Model Predictions Shape: (26, 5, 48, 2)\n",
      "Processed Month 1 - True Values Shape: (26, 48, 2)\n",
      "Applying weights for month 1: [0.57055253 0.         0.01078756 0.16910843 0.24955148]\n",
      "Input Model Predictions Shape: (26, 5, 48, 2)\n",
      "Ensemble Predictions Shape after applying weights: (26, 48, 2)\n",
      "\n",
      "Processing month 2 data...\n",
      "Processed Month 2 - Model Predictions Shape: (25, 5, 48, 2)\n",
      "Processed Month 2 - True Values Shape: (25, 48, 2)\n",
      "Applying weights for month 2: [0.89326787 0.01718011 0.08480656 0.         0.00474546]\n",
      "Input Model Predictions Shape: (25, 5, 48, 2)\n",
      "Ensemble Predictions Shape after applying weights: (25, 48, 2)\n",
      "\n",
      "Processing month 3 data...\n",
      "Processed Month 3 - Model Predictions Shape: (28, 5, 48, 2)\n",
      "Processed Month 3 - True Values Shape: (28, 48, 2)\n",
      "Applying weights for month 3: [0.87158191 0.         0.01500284 0.         0.11341526]\n",
      "Input Model Predictions Shape: (28, 5, 48, 2)\n",
      "Ensemble Predictions Shape after applying weights: (28, 48, 2)\n",
      "\n",
      "Processing month 4 data...\n",
      "Processed Month 4 - Model Predictions Shape: (20, 5, 48, 2)\n",
      "Processed Month 4 - True Values Shape: (20, 48, 2)\n",
      "Applying weights for month 4: [0.48293436 0.         0.         0.01971699 0.49734865]\n",
      "Input Model Predictions Shape: (20, 5, 48, 2)\n",
      "Ensemble Predictions Shape after applying weights: (20, 48, 2)\n",
      "\n",
      "Processing month 5 data...\n",
      "Processed Month 5 - Model Predictions Shape: (18, 5, 48, 2)\n",
      "Processed Month 5 - True Values Shape: (18, 48, 2)\n",
      "Applying weights for month 5: [0.73229964 0.         0.         0.         0.26770036]\n",
      "Input Model Predictions Shape: (18, 5, 48, 2)\n",
      "Ensemble Predictions Shape after applying weights: (18, 48, 2)\n",
      "\n",
      "Processing month 6 data...\n",
      "Processed Month 6 - Model Predictions Shape: (18, 5, 48, 2)\n",
      "Processed Month 6 - True Values Shape: (18, 48, 2)\n",
      "Applying weights for month 6: [0.29015045 0.19695908 0.34140963 0.         0.17148084]\n",
      "Input Model Predictions Shape: (18, 5, 48, 2)\n",
      "Ensemble Predictions Shape after applying weights: (18, 48, 2)\n",
      "\n",
      "Processing month 7 data...\n",
      "Processed Month 7 - Model Predictions Shape: (15, 5, 48, 2)\n",
      "Processed Month 7 - True Values Shape: (15, 48, 2)\n",
      "Applying weights for month 7: [0.43500006 0.         0.         0.14708702 0.41791292]\n",
      "Input Model Predictions Shape: (15, 5, 48, 2)\n",
      "Ensemble Predictions Shape after applying weights: (15, 48, 2)\n",
      "\n",
      "Processing month 8 data...\n",
      "Processed Month 8 - Model Predictions Shape: (24, 5, 48, 2)\n",
      "Processed Month 8 - True Values Shape: (24, 48, 2)\n",
      "Applying weights for month 8: [0.83995537 0.         0.         0.12841461 0.03163001]\n",
      "Input Model Predictions Shape: (24, 5, 48, 2)\n",
      "Ensemble Predictions Shape after applying weights: (24, 48, 2)\n",
      "\n",
      "Processing month 9 data...\n",
      "Processed Month 9 - Model Predictions Shape: (21, 5, 48, 2)\n",
      "Processed Month 9 - True Values Shape: (21, 48, 2)\n",
      "Applying weights for month 9: [0.58545155 0.         0.27482755 0.         0.1397209 ]\n",
      "Input Model Predictions Shape: (21, 5, 48, 2)\n",
      "Ensemble Predictions Shape after applying weights: (21, 48, 2)\n",
      "\n",
      "Processing month 10 data...\n",
      "Processed Month 10 - Model Predictions Shape: (14, 5, 48, 2)\n",
      "Processed Month 10 - True Values Shape: (14, 48, 2)\n",
      "Applying weights for month 10: [0.43205361 0.01455957 0.         0.         0.55338682]\n",
      "Input Model Predictions Shape: (14, 5, 48, 2)\n",
      "Ensemble Predictions Shape after applying weights: (14, 48, 2)\n",
      "\n",
      "Processing month 11 data...\n",
      "Processed Month 11 - Model Predictions Shape: (23, 5, 48, 2)\n",
      "Processed Month 11 - True Values Shape: (23, 48, 2)\n",
      "Applying weights for month 11: [0.35697415 0.         0.         0.         0.64302585]\n",
      "Input Model Predictions Shape: (23, 5, 48, 2)\n",
      "Ensemble Predictions Shape after applying weights: (23, 48, 2)\n",
      "\n",
      "Processing month 12 data...\n",
      "Processed Month 12 - Model Predictions Shape: (18, 5, 48, 2)\n",
      "Processed Month 12 - True Values Shape: (18, 48, 2)\n",
      "Applying weights for month 12: [0.8902205  0.         0.09566673 0.01411277 0.        ]\n",
      "Input Model Predictions Shape: (18, 5, 48, 2)\n",
      "Ensemble Predictions Shape after applying weights: (18, 48, 2)\n",
      "\n",
      "시간별 평균 RMSE:\n",
      "시간 0: 1.3759432965228688\n",
      "시간 1: 1.5731519569487356\n",
      "시간 2: 1.6369479234954742\n",
      "시간 3: 1.7121609781249194\n",
      "시간 4: 1.6678976829946797\n",
      "시간 5: 1.6687717427192494\n",
      "시간 6: 1.7084453498933077\n",
      "시간 7: 1.8465734722559433\n",
      "시간 8: 1.8172763841306938\n",
      "시간 9: 1.8642158714906938\n",
      "시간 10: 1.9669459147683117\n",
      "시간 11: 2.0383363126306024\n",
      "시간 12: 2.0045385092177574\n",
      "시간 13: 1.995207937253548\n",
      "시간 14: 2.04697007787045\n",
      "시간 15: 1.9910466831181834\n",
      "시간 16: 2.005007556194116\n",
      "시간 17: 2.087953193338738\n",
      "시간 18: 2.1805493618530343\n",
      "시간 19: 2.467944110707854\n",
      "시간 20: 2.436119587651692\n",
      "시간 21: 2.2485920557368533\n",
      "시간 22: 2.041863117013254\n",
      "시간 23: 2.0333561068362824\n",
      "시간 24: 2.0982310993223225\n",
      "시간 25: 2.1644320865062077\n",
      "시간 26: 2.0759463271881446\n",
      "시간 27: 2.0857578196004223\n",
      "시간 28: 2.107936898184622\n",
      "시간 29: 2.075988446187173\n",
      "시간 30: 2.0544847334481937\n",
      "시간 31: 2.160031154148859\n",
      "시간 32: 2.2388211651711094\n",
      "시간 33: 2.322544980328157\n",
      "시간 34: 2.4021026090726663\n",
      "시간 35: 2.4112234468858653\n",
      "시간 36: 2.336334613735002\n",
      "시간 37: 2.2911287026227956\n",
      "시간 38: 2.457166214657\n",
      "시간 39: 2.5282513166108207\n",
      "시간 40: 2.449313061318528\n",
      "시간 41: 2.473221916829523\n",
      "시간 42: 2.6403707445429565\n",
      "시간 43: 2.8358361029339068\n",
      "시간 44: 2.8284967068270217\n",
      "시간 45: 2.717251739512544\n",
      "시간 46: 2.6085273735380703\n",
      "시간 47: 2.703399729677832\n",
      "\n",
      "전체 평균 RMSE:\n",
      "GA 월별 전체 평균 RMSE: 2.202065270074302\n",
      "GA 그룹별 전체 평균 RMSE: 2.1558877952420206\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# 기존 optimal_weights_list 사용\n",
    "def calculate_ga_ensemble_rmse(model_predictions, true_values, weights):\n",
    "    n_samples, n_models, time_window, n_features = model_predictions.shape\n",
    "    print(f\"Input Model Predictions Shape: {model_predictions.shape}\")\n",
    "\n",
    "    # GA 기반 가중치를 적용한 앙상블 예측값 계산 (n_samples 적용)\n",
    "    weights = np.array(weights).reshape(1, -1, 1, 1)  # 모델 수 차원과 맞춤\n",
    "    ensemble_predictions = np.sum(model_predictions * weights, axis=1)\n",
    "\n",
    "    print(f\"Ensemble Predictions Shape after applying weights: {ensemble_predictions.shape}\")\n",
    "\n",
    "    results_dict = {i: [] for i in range(time_window)}\n",
    "\n",
    "    for i in range(time_window):\n",
    "        predictions_sample = ensemble_predictions[:, i, :]\n",
    "        true_values_sample = true_values[:, i, :]\n",
    "\n",
    "        # 예측값과 실제값의 차원 확인\n",
    "        if predictions_sample.shape != true_values_sample.shape:\n",
    "            raise ValueError(f\"Shape mismatch: {predictions_sample.shape} vs {true_values_sample.shape}\")\n",
    "\n",
    "        mse = mean_squared_error(true_values_sample, predictions_sample, multioutput='uniform_average')\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        results_dict[i].append(rmse)\n",
    "\n",
    "    all_predictions = ensemble_predictions.reshape(n_samples * time_window, n_features)\n",
    "    all_true_values = true_values.reshape(n_samples * time_window, n_features)\n",
    "\n",
    "    overall_mse = mean_squared_error(all_true_values, all_predictions, multioutput='uniform_average')\n",
    "    overall_rmse = np.sqrt(overall_mse)\n",
    "\n",
    "    return results_dict, overall_rmse\n",
    "\n",
    "\n",
    "def calculate_groupwise_rmse(all_results):\n",
    "    time_window = len(all_results[0])\n",
    "    average_rmse = {i: [] for i in range(time_window)}\n",
    "\n",
    "    for month_results in all_results:\n",
    "        for key, rmse_list in month_results.items():\n",
    "            average_rmse[key].extend(rmse_list)\n",
    "\n",
    "    groupwise_rmse = {key: np.mean(rmse_list) for key, rmse_list in average_rmse.items()}\n",
    "    overall_rmse = np.mean(list(groupwise_rmse.values()))\n",
    "\n",
    "    return groupwise_rmse, overall_rmse\n",
    "\n",
    "\n",
    "def main():\n",
    "    input_directory = \"./ga_s3\"\n",
    "    all_results = []\n",
    "    overall_rmse_list = []\n",
    "\n",
    "    for month in range(1, 13):\n",
    "        print(f\"\\nProcessing month {month} data...\")\n",
    "        model_predictions, true_values = load_and_process_test_data(input_directory, month)\n",
    "\n",
    "        # 월별 최적 가중치 적용\n",
    "        month_weights = optimal_weights_list[month - 1]\n",
    "        print(f\"Applying weights for month {month}: {month_weights}\")\n",
    "\n",
    "        results_dict, overall_rmse = calculate_ga_ensemble_rmse(model_predictions, true_values, month_weights)\n",
    "\n",
    "        all_results.append(results_dict)\n",
    "        overall_rmse_list.append(overall_rmse)\n",
    "\n",
    "    groupwise_rmse, overall_rmse = calculate_groupwise_rmse(all_results)\n",
    "\n",
    "    print(\"\\n시간별 평균 RMSE:\")\n",
    "    for time, rmse in groupwise_rmse.items():\n",
    "        print(f\"시간 {time}: {rmse}\")\n",
    "\n",
    "    print(\"\\n전체 평균 RMSE:\")\n",
    "    print(f\"GA 월별 전체 평균 RMSE: {np.mean(overall_rmse_list)}\")\n",
    "    print(f\"GA 그룹별 전체 평균 RMSE: {overall_rmse}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Month 1 - Model Predictions Shape: (26, 5, 48, 2)\n",
      "Processed Month 1 - True Values Shape: (26, 48, 2)\n",
      "1월 가중치: [0.57055253 0.         0.01078756 0.16910843 0.24955148]\n",
      "1월 개별 모델 RMSE: [2.102773022886727, 2.5728350521417958, 2.140547987162377, 2.8394349124644007, 2.1355950177896177]\n",
      "1월 개별 모델 0~24 시간 평균 RMSE: [1.9249162191020355, 2.3532967377659455, 2.011720749118762, 2.71549660640836, 1.9637904820177168]\n",
      "1월 개별 모델 25~47 시간 평균 RMSE: [2.261869064416568, 2.745342605296209, 2.249991653130403, 2.9500569506062173, 2.2850251502750125]\n",
      "NaN in model_predictions: False\n",
      "NaN in true_values: False\n",
      "model_predictions.shape: (26, 5, 48, 2)\n",
      "true_values.shape: (26, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.57055253 0.         0.01078756 0.16910843 0.24955148]\n",
      "time_window: 48, output_steps: 48\n",
      "1월 예측값: (26, 5, 48, 2), 실제값: (26, 48, 2), 가중치: [0.57055253 0.         0.01078756 0.16910843 0.24955148]\n",
      "1월 앙상블 0~24 시간 평균 RMSE: 1.8636253177638589\n",
      "1월 앙상블 25~47 시간 평균 RMSE: 2.1854852436043437\n",
      "Processed Month 2 - Model Predictions Shape: (25, 5, 48, 2)\n",
      "Processed Month 2 - True Values Shape: (25, 48, 2)\n",
      "2월 가중치: [0.89326787 0.01718011 0.08480656 0.         0.00474546]\n",
      "2월 개별 모델 RMSE: [2.35313426759237, 2.7063699657081317, 2.436167185909528, 2.635595252151555, 2.2933480108819886]\n",
      "2월 개별 모델 0~24 시간 평균 RMSE: [2.0589343673330185, 2.5468300537891344, 2.1891826368265264, 2.526289198973032, 2.1232098260655934]\n",
      "2월 개별 모델 25~47 시간 평균 RMSE: [2.554289484498308, 2.7768304016324654, 2.5772025187677903, 2.6706024166940683, 2.3519293277379574]\n",
      "NaN in model_predictions: False\n",
      "NaN in true_values: False\n",
      "model_predictions.shape: (25, 5, 48, 2)\n",
      "true_values.shape: (25, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.89326787 0.01718011 0.08480656 0.         0.00474546]\n",
      "time_window: 48, output_steps: 48\n",
      "2월 예측값: (25, 5, 48, 2), 실제값: (25, 48, 2), 가중치: [0.89326787 0.01718011 0.08480656 0.         0.00474546]\n",
      "2월 앙상블 0~24 시간 평균 RMSE: 2.0323156466383083\n",
      "2월 앙상블 25~47 시간 평균 RMSE: 2.5043092397199107\n",
      "Processed Month 3 - Model Predictions Shape: (28, 5, 48, 2)\n",
      "Processed Month 3 - True Values Shape: (28, 48, 2)\n",
      "3월 가중치: [0.87158191 0.         0.01500284 0.         0.11341526]\n",
      "3월 개별 모델 RMSE: [2.2724846560820637, 2.8249607487090103, 2.383602972895613, 2.8390193535661847, 2.4085803933548093]\n",
      "3월 개별 모델 0~24 시간 평균 RMSE: [1.9936752159293214, 2.739742194087773, 2.279086489118189, 2.7136850170392255, 2.2693857977479643]\n",
      "3월 개별 모델 25~47 시간 평균 RMSE: [2.5086839272166266, 2.8837829510859656, 2.4501158511148677, 2.9450319726970404, 2.528153748612361]\n",
      "NaN in model_predictions: False\n",
      "NaN in true_values: False\n",
      "model_predictions.shape: (28, 5, 48, 2)\n",
      "true_values.shape: (28, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.87158191 0.         0.01500284 0.         0.11341526]\n",
      "time_window: 48, output_steps: 48\n",
      "3월 예측값: (28, 5, 48, 2), 실제값: (28, 48, 2), 가중치: [0.87158191 0.         0.01500284 0.         0.11341526]\n",
      "3월 앙상블 0~24 시간 평균 RMSE: 1.9770875696467383\n",
      "3월 앙상블 25~47 시간 평균 RMSE: 2.4697014796348493\n",
      "Processed Month 4 - Model Predictions Shape: (20, 5, 48, 2)\n",
      "Processed Month 4 - True Values Shape: (20, 48, 2)\n",
      "4월 가중치: [0.48293436 0.         0.         0.01971699 0.49734865]\n",
      "4월 개별 모델 RMSE: [2.3438655301255817, 3.1671633939435253, 2.3942660483293396, 3.7351398260628055, 2.364346400996078]\n",
      "4월 개별 모델 0~24 시간 평균 RMSE: [2.0514419814459566, 2.929379661977052, 2.13409062825362, 3.611515445701, 2.2376442757615655]\n",
      "4월 개별 모델 25~47 시간 평균 RMSE: [2.5996747849673723, 3.3558595408873857, 2.6228490264977604, 3.837670358509265, 2.4599467221820754]\n",
      "NaN in model_predictions: False\n",
      "NaN in true_values: False\n",
      "model_predictions.shape: (20, 5, 48, 2)\n",
      "true_values.shape: (20, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.48293436 0.         0.         0.01971699 0.49734865]\n",
      "time_window: 48, output_steps: 48\n",
      "4월 예측값: (20, 5, 48, 2), 실제값: (20, 48, 2), 가중치: [0.48293436 0.         0.         0.01971699 0.49734865]\n",
      "4월 앙상블 0~24 시간 평균 RMSE: 2.03486720567289\n",
      "4월 앙상블 25~47 시간 평균 RMSE: 2.420441182861168\n",
      "Processed Month 5 - Model Predictions Shape: (18, 5, 48, 2)\n",
      "Processed Month 5 - True Values Shape: (18, 48, 2)\n",
      "5월 가중치: [0.73229964 0.         0.         0.         0.26770036]\n",
      "5월 개별 모델 RMSE: [1.9164067621744687, 2.3215062510828077, 1.8202235782263694, 2.3004515020994796, 1.7536624632697377]\n",
      "5월 개별 모델 0~24 시간 평균 RMSE: [1.6303429716957538, 2.0971913155397788, 1.6416765205551065, 2.0419429772992155, 1.5268107572568292]\n",
      "5월 개별 모델 25~47 시간 평균 RMSE: [2.1551327346029407, 2.482854478420743, 1.9503898889351206, 2.508129303877514, 1.9311363002704913]\n",
      "NaN in model_predictions: False\n",
      "NaN in true_values: False\n",
      "model_predictions.shape: (18, 5, 48, 2)\n",
      "true_values.shape: (18, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.73229964 0.         0.         0.         0.26770036]\n",
      "time_window: 48, output_steps: 48\n",
      "5월 예측값: (18, 5, 48, 2), 실제값: (18, 48, 2), 가중치: [0.73229964 0.         0.         0.         0.26770036]\n",
      "5월 앙상블 0~24 시간 평균 RMSE: 1.5282531819973193\n",
      "5월 앙상블 25~47 시간 평균 RMSE: 2.007944477916566\n",
      "Processed Month 6 - Model Predictions Shape: (18, 5, 48, 2)\n",
      "Processed Month 6 - True Values Shape: (18, 48, 2)\n",
      "6월 가중치: [0.29015045 0.19695908 0.34140963 0.         0.17148084]\n",
      "6월 개별 모델 RMSE: [2.4069489239767528, 2.8073148029569928, 2.3827441675132306, 3.251252937750725, 2.2589630285057156]\n",
      "6월 개별 모델 0~24 시간 평균 RMSE: [2.1201578811659405, 2.4653907873755276, 1.9677009898772473, 3.08208224012402, 1.9555339021842157]\n",
      "6월 개별 모델 25~47 시간 평균 RMSE: [2.596341758692513, 3.1004167242931495, 2.7207096653169627, 3.4030799233834053, 2.502679573521701]\n",
      "NaN in model_predictions: False\n",
      "NaN in true_values: False\n",
      "model_predictions.shape: (18, 5, 48, 2)\n",
      "true_values.shape: (18, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.29015045 0.19695908 0.34140963 0.         0.17148084]\n",
      "time_window: 48, output_steps: 48\n",
      "6월 예측값: (18, 5, 48, 2), 실제값: (18, 48, 2), 가중치: [0.29015045 0.19695908 0.34140963 0.         0.17148084]\n",
      "6월 앙상블 0~24 시간 평균 RMSE: 1.910242279249917\n",
      "6월 앙상블 25~47 시간 평균 RMSE: 2.548951579580741\n",
      "Processed Month 7 - Model Predictions Shape: (15, 5, 48, 2)\n",
      "Processed Month 7 - True Values Shape: (15, 48, 2)\n",
      "7월 가중치: [0.43500006 0.         0.         0.14708702 0.41791292]\n",
      "7월 개별 모델 RMSE: [2.433458848842132, 2.611852247875814, 2.406805177260867, 2.7774640252866565, 2.328890024673045]\n",
      "7월 개별 모델 0~24 시간 평균 RMSE: [2.187674791750004, 2.3200621001160986, 2.0413274339238465, 2.4055987821690135, 1.921768454775161]\n",
      "7월 개별 모델 25~47 시간 평균 RMSE: [2.5807948451025022, 2.8411605888960185, 2.6676800327411807, 3.074631553385075, 2.6108311436750706]\n",
      "NaN in model_predictions: False\n",
      "NaN in true_values: False\n",
      "model_predictions.shape: (15, 5, 48, 2)\n",
      "true_values.shape: (15, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.43500006 0.         0.         0.14708702 0.41791292]\n",
      "time_window: 48, output_steps: 48\n",
      "7월 예측값: (15, 5, 48, 2), 실제값: (15, 48, 2), 가중치: [0.43500006 0.         0.         0.14708702 0.41791292]\n",
      "7월 앙상블 0~24 시간 평균 RMSE: 1.9421168542254452\n",
      "7월 앙상블 25~47 시간 평균 RMSE: 2.5404970350003033\n",
      "Processed Month 8 - Model Predictions Shape: (24, 5, 48, 2)\n",
      "Processed Month 8 - True Values Shape: (24, 48, 2)\n",
      "8월 가중치: [0.83995537 0.         0.         0.12841461 0.03163001]\n",
      "8월 개별 모델 RMSE: [2.3137918713159618, 2.4123742644409876, 2.329214280355531, 2.5081609783815018, 2.1682291242505265]\n",
      "8월 개별 모델 0~24 시간 평균 RMSE: [2.145556521645079, 2.326639838660343, 2.220018587463402, 2.497374965534546, 2.052885893226093]\n",
      "8월 개별 모델 25~47 시간 평균 RMSE: [2.4343742793787926, 2.462450831987027, 2.3903240628688134, 2.4815034270449146, 2.2346990462541694]\n",
      "NaN in model_predictions: False\n",
      "NaN in true_values: False\n",
      "model_predictions.shape: (24, 5, 48, 2)\n",
      "true_values.shape: (24, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.83995537 0.         0.         0.12841461 0.03163001]\n",
      "time_window: 48, output_steps: 48\n",
      "8월 예측값: (24, 5, 48, 2), 실제값: (24, 48, 2), 가중치: [0.83995537 0.         0.         0.12841461 0.03163001]\n",
      "8월 앙상블 0~24 시간 평균 RMSE: 2.104293090500344\n",
      "8월 앙상블 25~47 시간 평균 RMSE: 2.329903881522164\n",
      "Processed Month 9 - Model Predictions Shape: (21, 5, 48, 2)\n",
      "Processed Month 9 - True Values Shape: (21, 48, 2)\n",
      "9월 가중치: [0.58545155 0.         0.27482755 0.         0.1397209 ]\n",
      "9월 개별 모델 RMSE: [2.9787194217449686, 3.518899947111407, 3.171644006450082, 4.33735602795472, 2.973715392110641]\n",
      "9월 개별 모델 0~24 시간 평균 RMSE: [2.2903394232095113, 3.2750744191789334, 2.6232030007398395, 4.275531608729262, 2.4555263391645]\n",
      "9월 개별 모델 25~47 시간 평균 RMSE: [3.3807991026817916, 3.628409096182815, 3.531060122771603, 4.25637239504781, 3.2981484455861447]\n",
      "NaN in model_predictions: False\n",
      "NaN in true_values: False\n",
      "model_predictions.shape: (21, 5, 48, 2)\n",
      "true_values.shape: (21, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.58545155 0.         0.27482755 0.         0.1397209 ]\n",
      "time_window: 48, output_steps: 48\n",
      "9월 예측값: (21, 5, 48, 2), 실제값: (21, 48, 2), 가중치: [0.58545155 0.         0.27482755 0.         0.1397209 ]\n",
      "9월 앙상블 0~24 시간 평균 RMSE: 2.3187668482329435\n",
      "9월 앙상블 25~47 시간 평균 RMSE: 3.3225431237988294\n",
      "Processed Month 10 - Model Predictions Shape: (14, 5, 48, 2)\n",
      "Processed Month 10 - True Values Shape: (14, 48, 2)\n",
      "10월 가중치: [0.43205361 0.01455957 0.         0.         0.55338682]\n",
      "10월 개별 모델 RMSE: [2.160937265066441, 2.9417662632213886, 2.157215055637158, 3.5156008156342513, 2.190643672821341]\n",
      "10월 개별 모델 0~24 시간 평균 RMSE: [1.8909025872167018, 2.814486146978047, 2.026558223756851, 3.3147702594634785, 2.088308378383059]\n",
      "10월 개별 모델 25~47 시간 평균 RMSE: [2.3539051708584613, 2.963018763621319, 2.2403216561668016, 3.6648365404570993, 2.2542588418807834]\n",
      "NaN in model_predictions: False\n",
      "NaN in true_values: False\n",
      "model_predictions.shape: (14, 5, 48, 2)\n",
      "true_values.shape: (14, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.43205361 0.01455957 0.         0.         0.55338682]\n",
      "time_window: 48, output_steps: 48\n",
      "10월 예측값: (14, 5, 48, 2), 실제값: (14, 48, 2), 가중치: [0.43205361 0.01455957 0.         0.         0.55338682]\n",
      "10월 앙상블 0~24 시간 평균 RMSE: 1.9255623044878853\n",
      "10월 앙상블 25~47 시간 평균 RMSE: 2.192147760709871\n",
      "Processed Month 11 - Model Predictions Shape: (23, 5, 48, 2)\n",
      "Processed Month 11 - True Values Shape: (23, 48, 2)\n",
      "11월 가중치: [0.35697415 0.         0.         0.         0.64302585]\n",
      "11월 개별 모델 RMSE: [2.021572390239006, 2.3637802822223732, 2.0324028880968683, 2.6330563717101967, 1.9832382978740801]\n",
      "11월 개별 모델 0~24 시간 평균 RMSE: [1.8455562840842887, 2.352669404407406, 1.9504727692432042, 2.56577199284142, 1.8719950473909677]\n",
      "11월 개별 모델 25~47 시간 평균 RMSE: [2.1370479202112955, 2.3601311334451474, 2.06216440610951, 2.660301856534135, 2.0405330103583386]\n",
      "NaN in model_predictions: False\n",
      "NaN in true_values: False\n",
      "model_predictions.shape: (23, 5, 48, 2)\n",
      "true_values.shape: (23, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.35697415 0.         0.         0.         0.64302585]\n",
      "time_window: 48, output_steps: 48\n",
      "11월 예측값: (23, 5, 48, 2), 실제값: (23, 48, 2), 가중치: [0.35697415 0.         0.         0.         0.64302585]\n",
      "11월 앙상블 0~24 시간 평균 RMSE: 1.8058018897694021\n",
      "11월 앙상블 25~47 시간 평균 RMSE: 1.9871969307110953\n",
      "Processed Month 12 - Model Predictions Shape: (18, 5, 48, 2)\n",
      "Processed Month 12 - True Values Shape: (18, 48, 2)\n",
      "12월 가중치: [0.8902205  0.         0.09566673 0.01411277 0.        ]\n",
      "12월 개별 모델 RMSE: [2.076858312359644, 2.6454385975725194, 2.046680389486683, 3.3827127572816456, 1.936309060150662]\n",
      "12월 개별 모델 0~24 시간 평균 RMSE: [1.8727737765587256, 2.6057550987206706, 1.9889214949732363, 3.483774476477765, 1.800634319768923]\n",
      "12월 개별 모델 25~47 시간 평균 RMSE: [2.21171334615729, 2.6427236685759636, 2.0784738404030496, 3.2207586185674644, 2.021874590597115]\n",
      "NaN in model_predictions: False\n",
      "NaN in true_values: False\n",
      "model_predictions.shape: (18, 5, 48, 2)\n",
      "true_values.shape: (18, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.8902205  0.         0.09566673 0.01411277 0.        ]\n",
      "time_window: 48, output_steps: 48\n",
      "12월 예측값: (18, 5, 48, 2), 실제값: (18, 48, 2), 가중치: [0.8902205  0.         0.09566673 0.01411277 0.        ]\n",
      "12월 앙상블 0~24 시간 평균 RMSE: 1.8438100272179405\n",
      "12월 앙상블 25~47 시간 평균 RMSE: 2.170130876867507\n",
      "\n",
      "전체 월 평균 앙상블 RMSE:  2.202083333333333\n",
      "\n",
      "구간별 평균 RMSE 비교 결과:\n",
      "1월:\n",
      "  모델 0~24 시간 평균 RMSE: [1.9249162191020355, 2.3532967377659455, 2.011720749118762, 2.71549660640836, 1.9637904820177168]\n",
      "  모델 25~47 시간 평균 RMSE: [2.261869064416568, 2.745342605296209, 2.249991653130403, 2.9500569506062173, 2.2850251502750125]\n",
      "  앙상블 0~24 시간 평균 RMSE: 1.8636\n",
      "  앙상블 25~47 시간 평균 RMSE: 2.1855\n",
      "2월:\n",
      "  모델 0~24 시간 평균 RMSE: [2.0589343673330185, 2.5468300537891344, 2.1891826368265264, 2.526289198973032, 2.1232098260655934]\n",
      "  모델 25~47 시간 평균 RMSE: [2.554289484498308, 2.7768304016324654, 2.5772025187677903, 2.6706024166940683, 2.3519293277379574]\n",
      "  앙상블 0~24 시간 평균 RMSE: 2.0323\n",
      "  앙상블 25~47 시간 평균 RMSE: 2.5043\n",
      "3월:\n",
      "  모델 0~24 시간 평균 RMSE: [1.9936752159293214, 2.739742194087773, 2.279086489118189, 2.7136850170392255, 2.2693857977479643]\n",
      "  모델 25~47 시간 평균 RMSE: [2.5086839272166266, 2.8837829510859656, 2.4501158511148677, 2.9450319726970404, 2.528153748612361]\n",
      "  앙상블 0~24 시간 평균 RMSE: 1.9771\n",
      "  앙상블 25~47 시간 평균 RMSE: 2.4697\n",
      "4월:\n",
      "  모델 0~24 시간 평균 RMSE: [2.0514419814459566, 2.929379661977052, 2.13409062825362, 3.611515445701, 2.2376442757615655]\n",
      "  모델 25~47 시간 평균 RMSE: [2.5996747849673723, 3.3558595408873857, 2.6228490264977604, 3.837670358509265, 2.4599467221820754]\n",
      "  앙상블 0~24 시간 평균 RMSE: 2.0349\n",
      "  앙상블 25~47 시간 평균 RMSE: 2.4204\n",
      "5월:\n",
      "  모델 0~24 시간 평균 RMSE: [1.6303429716957538, 2.0971913155397788, 1.6416765205551065, 2.0419429772992155, 1.5268107572568292]\n",
      "  모델 25~47 시간 평균 RMSE: [2.1551327346029407, 2.482854478420743, 1.9503898889351206, 2.508129303877514, 1.9311363002704913]\n",
      "  앙상블 0~24 시간 평균 RMSE: 1.5283\n",
      "  앙상블 25~47 시간 평균 RMSE: 2.0079\n",
      "6월:\n",
      "  모델 0~24 시간 평균 RMSE: [2.1201578811659405, 2.4653907873755276, 1.9677009898772473, 3.08208224012402, 1.9555339021842157]\n",
      "  모델 25~47 시간 평균 RMSE: [2.596341758692513, 3.1004167242931495, 2.7207096653169627, 3.4030799233834053, 2.502679573521701]\n",
      "  앙상블 0~24 시간 평균 RMSE: 1.9102\n",
      "  앙상블 25~47 시간 평균 RMSE: 2.5490\n",
      "7월:\n",
      "  모델 0~24 시간 평균 RMSE: [2.187674791750004, 2.3200621001160986, 2.0413274339238465, 2.4055987821690135, 1.921768454775161]\n",
      "  모델 25~47 시간 평균 RMSE: [2.5807948451025022, 2.8411605888960185, 2.6676800327411807, 3.074631553385075, 2.6108311436750706]\n",
      "  앙상블 0~24 시간 평균 RMSE: 1.9421\n",
      "  앙상블 25~47 시간 평균 RMSE: 2.5405\n",
      "8월:\n",
      "  모델 0~24 시간 평균 RMSE: [2.145556521645079, 2.326639838660343, 2.220018587463402, 2.497374965534546, 2.052885893226093]\n",
      "  모델 25~47 시간 평균 RMSE: [2.4343742793787926, 2.462450831987027, 2.3903240628688134, 2.4815034270449146, 2.2346990462541694]\n",
      "  앙상블 0~24 시간 평균 RMSE: 2.1043\n",
      "  앙상블 25~47 시간 평균 RMSE: 2.3299\n",
      "9월:\n",
      "  모델 0~24 시간 평균 RMSE: [2.2903394232095113, 3.2750744191789334, 2.6232030007398395, 4.275531608729262, 2.4555263391645]\n",
      "  모델 25~47 시간 평균 RMSE: [3.3807991026817916, 3.628409096182815, 3.531060122771603, 4.25637239504781, 3.2981484455861447]\n",
      "  앙상블 0~24 시간 평균 RMSE: 2.3188\n",
      "  앙상블 25~47 시간 평균 RMSE: 3.3225\n",
      "10월:\n",
      "  모델 0~24 시간 평균 RMSE: [1.8909025872167018, 2.814486146978047, 2.026558223756851, 3.3147702594634785, 2.088308378383059]\n",
      "  모델 25~47 시간 평균 RMSE: [2.3539051708584613, 2.963018763621319, 2.2403216561668016, 3.6648365404570993, 2.2542588418807834]\n",
      "  앙상블 0~24 시간 평균 RMSE: 1.9256\n",
      "  앙상블 25~47 시간 평균 RMSE: 2.1921\n",
      "11월:\n",
      "  모델 0~24 시간 평균 RMSE: [1.8455562840842887, 2.352669404407406, 1.9504727692432042, 2.56577199284142, 1.8719950473909677]\n",
      "  모델 25~47 시간 평균 RMSE: [2.1370479202112955, 2.3601311334451474, 2.06216440610951, 2.660301856534135, 2.0405330103583386]\n",
      "  앙상블 0~24 시간 평균 RMSE: 1.8058\n",
      "  앙상블 25~47 시간 평균 RMSE: 1.9872\n",
      "12월:\n",
      "  모델 0~24 시간 평균 RMSE: [1.8727737765587256, 2.6057550987206706, 1.9889214949732363, 3.483774476477765, 1.800634319768923]\n",
      "  모델 25~47 시간 평균 RMSE: [2.21171334615729, 2.6427236685759636, 2.0784738404030496, 3.2207586185674644, 2.021874590597115]\n",
      "  앙상블 0~24 시간 평균 RMSE: 1.8438\n",
      "  앙상블 25~47 시간 평균 RMSE: 2.1701\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "overall_rmse_list = []\n",
    "uniform_overall_rmse_list = []\n",
    "individual_model_rmse = []  # 월별 개별 모델 RMSE 저장 리스트\n",
    "timewise_model_rmse = []  # 시간별 개별 모델 RMSE 저장 리스트\n",
    "comparison_results = []  # 구간별 평균 RMSE 비교 결과 저장 리스트\n",
    "\n",
    "for month in range(1, 13):  # 1월부터 12월까지 반복\n",
    "    try:\n",
    "        # 테스트 데이터 로드 및 처리\n",
    "        model_predictions, true_values = load_and_process_test_data(input_directory, month)\n",
    "\n",
    "        # 월별 optimal_weights 확인\n",
    "        if isinstance(optimal_weights_list, list):\n",
    "            month_weights = optimal_weights_list[month - 1]\n",
    "        else:\n",
    "            raise ValueError(\"optimal_weights_list가 월별 가중치를 포함한 리스트가 아닙니다.\")\n",
    "\n",
    "        print(f\"{month}월 가중치: {month_weights}\")\n",
    "\n",
    "        # 월별 개별 모델 RMSE 계산\n",
    "        n_models = model_predictions.shape[1]\n",
    "        time_window = model_predictions.shape[2]\n",
    "        monthly_model_rmse = []  # 해당 월의 각 모델 RMSE 저장\n",
    "        monthly_timewise_rmse = {t: [] for t in range(time_window)}  # 시간별 RMSE 저장\n",
    "\n",
    "        for model_idx in range(n_models):\n",
    "            model_prediction = model_predictions[:, model_idx, :, :]  # 해당 모델의 예측값 (n_samples, time_window, 2)\n",
    "            \n",
    "            # 월별 RMSE\n",
    "            mse = mean_squared_error(true_values.reshape(-1, 2), model_prediction.reshape(-1, 2), multioutput=\"uniform_average\")\n",
    "            rmse = np.sqrt(mse)\n",
    "            monthly_model_rmse.append(rmse)\n",
    "\n",
    "            # 시간별 RMSE\n",
    "            for t in range(time_window):\n",
    "                time_mse = mean_squared_error(true_values[:, t, :], model_prediction[:, t, :], multioutput=\"uniform_average\")\n",
    "                time_rmse = np.sqrt(time_mse)\n",
    "                monthly_timewise_rmse[t].append(time_rmse)\n",
    "\n",
    "        individual_model_rmse.append(monthly_model_rmse)\n",
    "        timewise_model_rmse.append(monthly_timewise_rmse)\n",
    "\n",
    "        print(f\"{month}월 개별 모델 RMSE: {monthly_model_rmse}\")\n",
    "\n",
    "        # 0~24, 25~47 시간 구간별 개별 모델 평균 RMSE 계산\n",
    "        avg_rmse_0_24 = [np.mean([monthly_timewise_rmse[t][model_idx] for t in range(0, 25)]) for model_idx in range(n_models)]\n",
    "        avg_rmse_25_47 = [np.mean([monthly_timewise_rmse[t][model_idx] for t in range(25, 48)]) for model_idx in range(n_models)]\n",
    "\n",
    "        print(f\"{month}월 개별 모델 0~24 시간 평균 RMSE: {avg_rmse_0_24}\")\n",
    "        print(f\"{month}월 개별 모델 25~47 시간 평균 RMSE: {avg_rmse_25_47}\")\n",
    "\n",
    "        # 앙상블 RMSE 계산\n",
    "        ensemble_rmse, overall_rmse = calculate_ensemble_rmse(model_predictions, true_values, month_weights, 48)\n",
    "        print(f\"{month}월 예측값: {model_predictions.shape}, 실제값: {true_values.shape}, 가중치: {month_weights}\")\n",
    "\n",
    "        # 0~24, 25~47 시간 구간별 앙상블 평균 RMSE 계산\n",
    "        ensemble_predictions = np.tensordot(model_predictions, month_weights, axes=(1, 0))  # (n_samples, time_window, 2)\n",
    "        avg_ensemble_rmse_0_24 = np.mean([\n",
    "            np.sqrt(mean_squared_error(true_values[:, t, :], ensemble_predictions[:, t, :], multioutput=\"uniform_average\"))\n",
    "            for t in range(0, 25)\n",
    "        ])\n",
    "        avg_ensemble_rmse_25_47 = np.mean([\n",
    "            np.sqrt(mean_squared_error(true_values[:, t, :], ensemble_predictions[:, t, :], multioutput=\"uniform_average\"))\n",
    "            for t in range(25, 48)\n",
    "        ])\n",
    "\n",
    "        print(f\"{month}월 앙상블 0~24 시간 평균 RMSE: {avg_ensemble_rmse_0_24}\")\n",
    "        print(f\"{month}월 앙상블 25~47 시간 평균 RMSE: {avg_ensemble_rmse_25_47}\")\n",
    "\n",
    "        # 결과 비교 저장\n",
    "        comparison_results.append({\n",
    "            \"month\": month,\n",
    "            \"model_avg_rmse_0_24\": avg_rmse_0_24,\n",
    "            \"model_avg_rmse_25_47\": avg_rmse_25_47,\n",
    "            \"ensemble_avg_rmse_0_24\": avg_ensemble_rmse_0_24,\n",
    "            \"ensemble_avg_rmse_25_47\": avg_ensemble_rmse_25_47\n",
    "        })\n",
    "\n",
    "        overall_rmse_list.append(overall_rmse)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"{month}월 처리 중 오류 발생: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# 최종 평균 RMSE 출력\n",
    "if overall_rmse_list:\n",
    "    print(\"\\n전체 월 평균 앙상블 RMSE: \", np.mean(overall_rmse_list))\n",
    "else:\n",
    "    print(\"\\n앙상블 RMSE 결과가 없습니다.\")\n",
    "\n",
    "# 구간별 결과 출력\n",
    "print(\"\\n구간별 평균 RMSE 비교 결과:\")\n",
    "for result in comparison_results:\n",
    "    print(f\"{result['month']}월:\")\n",
    "    print(f\"  모델 0~24 시간 평균 RMSE: {result['model_avg_rmse_0_24']}\")\n",
    "    print(f\"  모델 25~47 시간 평균 RMSE: {result['model_avg_rmse_25_47']}\")\n",
    "    print(f\"  앙상블 0~24 시간 평균 RMSE: {result['ensemble_avg_rmse_0_24']:.4f}\")\n",
    "    print(f\"  앙상블 25~47 시간 평균 RMSE: {result['ensemble_avg_rmse_25_47']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GA 검증 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmse(model_predictions, true_values, individual):\n",
    "    \"\"\" 주어진 개체에 대해 앙상블 예측값을 계산하고 RMSE를 반환 \"\"\"\n",
    "    ensemble_prediction = np.sum([weight * model_predictions[:, i, :, :] for i, weight in enumerate(individual)], axis=0)\n",
    "    rmse = np.sqrt(np.mean((true_values - ensemble_prediction) ** 2))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genetic_algorithm_with_elitism(model_predictions, true_values, population_size=100, generations=100, mutation_rate=0.03, seed=None):\n",
    "    \"\"\"\n",
    "    GA를 사용하여 최적의 가중치 찾기\n",
    "    Args:\n",
    "        model_predictions: (n_samples, models, time_window, 2) 형태의 모델 예측값\n",
    "        true_values: (n_samples, time_window, 2) 형태의 실제값\n",
    "        population_size: 초기 개체군 크기\n",
    "        generations: 세대 수\n",
    "        mutation_rate: 돌연변이 확률\n",
    "        seed: 난수 시드를 고정하기 위한 값\n",
    "    Returns:\n",
    "        최적 가중치 배열\n",
    "    \"\"\"\n",
    "    num_models = model_predictions.shape[1]  # 모델 수\n",
    "    time_window = model_predictions.shape[2]  # 시간 단위\n",
    "    \n",
    "    # 초기 population 생성\n",
    "    population = np.random.dirichlet(np.ones(num_models), size=population_size)  # 초기 가중치 개체군\n",
    "\n",
    "    for generation in range(generations):\n",
    "        fitness_scores = []\n",
    "\n",
    "        # 현재 population의 fitness (RMSE) 계산\n",
    "        for individual in population:\n",
    "            ensemble_prediction = np.sum(\n",
    "                [weight * model_predictions[:, i, :, :] for i, weight in enumerate(individual)],\n",
    "                axis=0\n",
    "            )\n",
    "            rmse = np.sqrt(np.mean((true_values - ensemble_prediction) ** 2))\n",
    "            fitness_scores.append(rmse)\n",
    "        \n",
    "        fitness_scores = np.array(fitness_scores)\n",
    "\n",
    "        # 새로운 population 생성\n",
    "        new_population = []\n",
    "        while len(new_population) < population_size:\n",
    "            # 부모 선택\n",
    "            np.random.seed(seed + generation)  # 세대마다 다른 시드 적용\n",
    "            parent1 = roulette_wheel_selection(population, fitness_scores)\n",
    "            parent2 = roulette_wheel_selection(population, fitness_scores)\n",
    "\n",
    "            # 교차 연산\n",
    "            np.random.seed(seed + generation + 1)  # 세대마다 다른 시드 적용\n",
    "            crossover_point = np.random.randint(1, num_models)\n",
    "            child = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))\n",
    "\n",
    "            # 돌연변이\n",
    "            if np.random.rand() < mutation_rate:\n",
    "                np.random.seed(seed + generation + 2)  # 세대마다 다른 시드 적용\n",
    "                mutation_vector = np.random.normal(0, 0.1, size=num_models)\n",
    "                child = np.clip(child + mutation_vector, 0, 1)\n",
    "\n",
    "            # 정규화\n",
    "            child = child / np.sum(child)\n",
    "            new_population.append(child)\n",
    "        \n",
    "        new_population = np.array(new_population)\n",
    "\n",
    "        # 엘리티즘 적용: 상위 50% 개체 선택\n",
    "        combined_population = np.vstack((population, new_population))\n",
    "        combined_fitness = np.concatenate((fitness_scores, np.zeros(len(new_population))))\n",
    "\n",
    "        for idx, individual in enumerate(new_population):\n",
    "            ensemble_prediction = np.sum(\n",
    "                [weight * model_predictions[:, i, :, :] for i, weight in enumerate(individual)],\n",
    "                axis=0\n",
    "            )\n",
    "            combined_fitness[len(fitness_scores) + idx] = np.sqrt(np.mean((true_values - ensemble_prediction) ** 2))\n",
    "\n",
    "        sorted_indices = np.argsort(combined_fitness)\n",
    "        population = combined_population[sorted_indices][:population_size]\n",
    "\n",
    "        print(f\"Generation {generation + 1}/{generations}, Best RMSE: {combined_fitness[sorted_indices][0]}\")\n",
    "\n",
    "    # 최적 개체 반환\n",
    "    best_weights = population[0]\n",
    "    print(f\"Optimal Weights: {best_weights}\")\n",
    "    return best_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def run_ga_experiment(model_predictions, true_values, population_size=100, generations=100, mutation_rate=0.03, seed=None):\n",
    "    \"\"\"\n",
    "    유전 알고리즘 실험을 한 번 실행하고, GA 계산 시간을 측정하여 최적 가중치를 반환합니다.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)  # seed 설정\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    optimal_weights = genetic_algorithm_with_elitism(model_predictions, true_values, \n",
    "                                                     population_size=population_size, \n",
    "                                                     generations=generations, mutation_rate=mutation_rate, seed=seed)\n",
    "\n",
    "    ga_time = time.time() - start_time\n",
    "    \n",
    "    # 앙상블 예측\n",
    "    ensemble_prediction = np.sum([weight * model_predictions[:, i, :, :] for i, weight in enumerate(optimal_weights)], axis=0)\n",
    "    \n",
    "    # 3D 배열을 2D 배열로 변환 (n_samples, time_window * 2)\n",
    "    ensemble_prediction_2d = ensemble_prediction.reshape(-1, ensemble_prediction.shape[1] * ensemble_prediction.shape[2])\n",
    "    true_values_2d = true_values.reshape(-1, true_values.shape[1] * true_values.shape[2])\n",
    "\n",
    "    # RMSE 계산\n",
    "    rmse = np.sqrt(mean_squared_error(true_values_2d, ensemble_prediction_2d))\n",
    "\n",
    "    return optimal_weights, ga_time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def calculate_ensemble_rmse2(model_predictions, true_values, weights):\n",
    "    \"\"\"\n",
    "    최적 가중치를 사용하여 앙상블 RMSE를 계산\n",
    "\n",
    "    Args:\n",
    "        model_predictions (np.ndarray): 모델 예측값 (n_samples, models, time_window, 2)\n",
    "        true_values (np.ndarray): 실제 값 (n_samples, time_window, 2)\n",
    "        weights (np.ndarray): 최적 가중치 (models,)\n",
    "\n",
    "    Returns:\n",
    "        ensemble_rmse_dict (dict): 시간별 RMSE 딕셔너리\n",
    "        overall_rmse (float): 전체 평균 RMSE\n",
    "    \"\"\"\n",
    "    n_samples, n_models, time_window, _ = model_predictions.shape\n",
    "    \n",
    "    # 앙상블 예측값 계산 (가중치 적용)\n",
    "    ensemble_predictions = np.tensordot(model_predictions, weights, axes=(1, 0))  # (n_samples, time_window, 2)\n",
    "\n",
    "    # 시간별 RMSE를 저장할 딕셔너리\n",
    "    ensemble_rmse_dict = {}\n",
    "    \n",
    "    for time_step in range(time_window):\n",
    "        # 시간별 예측값과 실제값 추출\n",
    "        preds = ensemble_predictions[:, time_step, :]\n",
    "        trues = true_values[:, time_step, :]\n",
    "        \n",
    "        # RMSE 계산\n",
    "        mse = mean_squared_error(trues, preds, multioutput='uniform_average')\n",
    "        rmse = np.sqrt(mse)\n",
    "        ensemble_rmse_dict[time_step] = round(rmse, 4)\n",
    "\n",
    "    # 전체 평균 RMSE 계산\n",
    "    overall_rmse = np.mean(list(ensemble_rmse_dict.values()))\n",
    "\n",
    "    return round(overall_rmse, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def save_to_csv_for_seed(seed, monthly_rmse_list, monthly_ga_time_list, output_dir=\"./ga_검증\"):\n",
    "    \"\"\"각 seed별로 CSV 파일로 저장하는 함수\"\"\"\n",
    "    \n",
    "    valid_months = [i for i in range(1, 12)]\n",
    "    \n",
    "    # 월별 RMSE와 GA 계산 시간을 DataFrame으로 변환\n",
    "    monthly_df_rmse = pd.DataFrame({\n",
    "        'Seed': [seed],\n",
    "        **{f'Month {month} RMSE': [monthly_rmse_list[idx]] for idx, month in enumerate(valid_months)}\n",
    "    })\n",
    "    \n",
    "    monthly_df_ga_time = pd.DataFrame({\n",
    "        'Seed': [seed],\n",
    "        **{f'Month {month} GA Time': [monthly_ga_time_list[idx]] for idx, month in enumerate(valid_months)}\n",
    "    })\n",
    "    \n",
    "    # 저장할 디렉토리 생성 (없는 경우 생성)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # 각 seed에 대해 결과 저장\n",
    "    monthly_df_rmse.to_csv(f'{output_dir}/seed_{seed}_monthly_rmse.csv', index=False)\n",
    "    monthly_df_ga_time.to_csv(f'{output_dir}/seed_{seed}_monthly_ga_time.csv', index=False)\n",
    "\n",
    "    print(f\"Seed {seed}의 CSV 파일들이 성공적으로 저장되었습니다.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def calculate_seed_statistics(output_dir=\"./ga_검증\"):\n",
    "    \"\"\"30개의 seed에 대한 전체 통계 (평균, 표준편차)를 계산하여 저장하는 함수\"\"\"\n",
    "    all_rmse_list = []\n",
    "    all_ga_time_list = []\n",
    "    \n",
    "    # 각 seed별 통계 계산을 위한 리스트\n",
    "    seed_statistics = []\n",
    "\n",
    "    for seed in range(31):  # 0부터 30까지 31번 반복 실험\n",
    "        # seed별로 저장된 CSV 파일 불러오기\n",
    "        monthly_df_rmse = pd.read_csv(f'{output_dir}/seed_{seed}_monthly_rmse.csv')\n",
    "        monthly_df_ga_time = pd.read_csv(f'{output_dir}/seed_{seed}_monthly_ga_time.csv')\n",
    "        \n",
    "        # 전체 RMSE와 GA 시간의 값만 저장 (모든 월을 합친 통계)\n",
    "        rmse_values = monthly_df_rmse.iloc[0, 1:].values  # 월별 RMSE\n",
    "        ga_time_values = monthly_df_ga_time.iloc[0, 1:].values  # 월별 GA Time\n",
    "        \n",
    "        all_rmse_list.append(rmse_values)\n",
    "        all_ga_time_list.append(ga_time_values)\n",
    "        \n",
    "        # 각 seed에 대한 전체 평균과 표준편차 계산\n",
    "        seed_rmse_mean = np.mean(rmse_values)\n",
    "        seed_ga_time_mean = np.mean(ga_time_values)\n",
    "        \n",
    "        # 각 seed별 통계를 저장\n",
    "        seed_statistics.append({\n",
    "            'Seed': seed,\n",
    "            'Mean RMSE': seed_rmse_mean,\n",
    "            'Mean GA Time': seed_ga_time_mean\n",
    "        })\n",
    "    \n",
    "    # 전체 RMSE와 GA 시간에 대한 평균과 표준편차 계산\n",
    "    total_rmse_mean = np.mean(all_rmse_list)\n",
    "    total_ga_time_mean = np.mean(all_ga_time_list)\n",
    "\n",
    "    # 최종 통계 DataFrame 생성 (전체 통계 + 각 seed별 통계)\n",
    "    final_df = pd.DataFrame({\n",
    "        'Total Mean RMSE': [total_rmse_mean],\n",
    "        'Total Mean GA Time': [total_ga_time_mean],\n",
    "    })\n",
    "\n",
    "    # 각 seed별 통계를 DataFrame으로 변환\n",
    "    seed_statistics_df = pd.DataFrame(seed_statistics)\n",
    "\n",
    "    # 저장할 디렉토리 생성 (없는 경우 생성)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # 전체 통계 결과를 CSV로 저장\n",
    "    final_df.to_csv(f'{output_dir}/final_statistics.csv', index=False)\n",
    "    # 각 seed별 통계 결과를 CSV로 저장\n",
    "    seed_statistics_df.to_csv(f'{output_dir}/seed_statistics.csv', index=False)\n",
    "\n",
    "    print(f\"30개의 seed에 대한 통계 파일이 성공적으로 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_ga(input_directory, population_size=100, generations=100, mutation_rate=0.03, output_dir=\"./ga_검증\"):\n",
    "    \"\"\"GA 가중치를 구하고, 테스트 데이터로 RMSE 계산\"\"\"\n",
    "    overall_rmse_list = []\n",
    "    ga_time_list = []\n",
    "\n",
    "    for seed in range(31):  # 0부터 30까지 31번 반복 실험\n",
    "        print(f\"\\nSeed {seed}로 실험 시작\")\n",
    "        \n",
    "        np.random.seed(seed)  # 각 seed마다 난수 초기화\n",
    "        \n",
    "        monthly_rmse_list = []  # 매 `seed`마다 월별 RMSE 리스트 초기화\n",
    "        monthly_ga_time_list = []  # 매 `seed`마다 월별 GA 계산 시간 리스트 초기화\n",
    "\n",
    "        # 1월부터 12월까지 월별로 처리\n",
    "        for month in range(1, 12):\n",
    "\n",
    "            # 검증 데이터를 통해 GA 가중치 구하기\n",
    "            model_predictions, true_values = load_and_process_validation_data(input_directory, month)  # 월별로 검증 데이터 로드\n",
    "            optimal_weights, ga_time = run_ga_experiment(model_predictions, true_values, population_size, generations, mutation_rate, seed)\n",
    "            \n",
    "            # 테스트 데이터를 로드하여 최적 가중치로 예측 및 RMSE 계산\n",
    "            test_predictions, test_true_values = load_and_process_test_data(input_directory, month)  # 월별로 테스트 데이터 로드\n",
    "            test_rmse = calculate_ensemble_rmse2(test_predictions, test_true_values, optimal_weights)\n",
    "\n",
    "            monthly_rmse_list.append(test_rmse)  # 월별 RMSE 추가\n",
    "            monthly_ga_time_list.append(ga_time)  # GA 계산 시간도 리스트에 추가\n",
    "\n",
    "        # 전체 실험 결과 (해당 seed에 대한 결과)\n",
    "        overall_rmse_list.append(np.mean(monthly_rmse_list))  # 월별 RMSE 평균값을 overall에 추가\n",
    "        ga_time_list.append(np.mean(monthly_ga_time_list))  # 월별 GA 계산 시간 평균값을 ga_time_list에 추가\n",
    "\n",
    "        # 해당 seed에 대한 결과를 CSV로 저장\n",
    "        save_to_csv_for_seed(seed, monthly_rmse_list.copy(), monthly_ga_time_list.copy(), output_dir)  # 복사된 리스트 전달\n",
    "\n",
    "    # 모든 seed에 대해 통계 계산 후 CSV로 저장\n",
    "    calculate_seed_statistics(output_dir)\n",
    "\n",
    "    return overall_rmse_list, ga_time_list  # 결과 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Seed 0로 실험 시작\n",
      "Generation 1/100, Best RMSE: 4.761268416323186\n",
      "Generation 2/100, Best RMSE: 4.761268416323186\n",
      "Generation 3/100, Best RMSE: 4.761268416323186\n",
      "Generation 4/100, Best RMSE: 4.761268416323186\n",
      "Generation 5/100, Best RMSE: 4.761268416323186\n",
      "Generation 6/100, Best RMSE: 4.761268416323186\n",
      "Generation 7/100, Best RMSE: 4.761268416323186\n",
      "Generation 8/100, Best RMSE: 4.761268416323186\n",
      "Generation 9/100, Best RMSE: 4.761268416323186\n",
      "Generation 10/100, Best RMSE: 4.761268416323186\n",
      "Generation 11/100, Best RMSE: 4.759915358486413\n",
      "Generation 12/100, Best RMSE: 4.759915358486413\n",
      "Generation 13/100, Best RMSE: 4.759915358486413\n",
      "Generation 14/100, Best RMSE: 4.759915358486413\n",
      "Generation 15/100, Best RMSE: 4.759915358486413\n",
      "Generation 16/100, Best RMSE: 4.759915358486413\n",
      "Generation 17/100, Best RMSE: 4.759915358486413\n",
      "Generation 18/100, Best RMSE: 4.759915358486413\n",
      "Generation 19/100, Best RMSE: 4.759915358486413\n",
      "Generation 20/100, Best RMSE: 4.759915358486413\n",
      "Generation 21/100, Best RMSE: 4.759915358486413\n",
      "Generation 22/100, Best RMSE: 4.759915358486413\n",
      "Generation 23/100, Best RMSE: 4.759915358486413\n",
      "Generation 24/100, Best RMSE: 4.759915358486413\n",
      "Generation 25/100, Best RMSE: 4.759915358486413\n",
      "Generation 26/100, Best RMSE: 4.759915358486413\n",
      "Generation 27/100, Best RMSE: 4.759915358486413\n",
      "Generation 28/100, Best RMSE: 4.759915358486413\n",
      "Generation 29/100, Best RMSE: 4.759915358486413\n",
      "Generation 30/100, Best RMSE: 4.759915358486413\n",
      "Generation 31/100, Best RMSE: 4.759915358486413\n",
      "Generation 32/100, Best RMSE: 4.759915358486413\n",
      "Generation 33/100, Best RMSE: 4.759915358486413\n",
      "Generation 34/100, Best RMSE: 4.759915358486413\n",
      "Generation 35/100, Best RMSE: 4.759915358486413\n",
      "Generation 36/100, Best RMSE: 4.759915358486413\n",
      "Generation 37/100, Best RMSE: 4.759915358486413\n",
      "Generation 38/100, Best RMSE: 4.759915358486413\n",
      "Generation 39/100, Best RMSE: 4.746740253879932\n",
      "Generation 40/100, Best RMSE: 4.746740253879932\n",
      "Generation 41/100, Best RMSE: 4.746740253879932\n",
      "Generation 42/100, Best RMSE: 4.746740253879932\n",
      "Generation 43/100, Best RMSE: 4.746740253879932\n",
      "Generation 44/100, Best RMSE: 4.746740253879932\n",
      "Generation 45/100, Best RMSE: 4.746740253879932\n",
      "Generation 46/100, Best RMSE: 4.746740253879932\n",
      "Generation 47/100, Best RMSE: 4.746740253879932\n",
      "Generation 48/100, Best RMSE: 4.746740253879932\n",
      "Generation 49/100, Best RMSE: 4.746740253879932\n",
      "Generation 50/100, Best RMSE: 4.746740253879932\n",
      "Generation 51/100, Best RMSE: 4.746740253879932\n",
      "Generation 52/100, Best RMSE: 4.746740253879932\n",
      "Generation 53/100, Best RMSE: 4.746740253879932\n",
      "Generation 54/100, Best RMSE: 4.746740253879932\n",
      "Generation 55/100, Best RMSE: 4.746740253879932\n",
      "Generation 56/100, Best RMSE: 4.746740253879932\n",
      "Generation 57/100, Best RMSE: 4.746740253879932\n",
      "Generation 58/100, Best RMSE: 4.746740253879932\n",
      "Generation 59/100, Best RMSE: 4.746740253879932\n",
      "Generation 60/100, Best RMSE: 4.746740253879932\n",
      "Generation 61/100, Best RMSE: 4.746740253879932\n",
      "Generation 62/100, Best RMSE: 4.746740253879932\n",
      "Generation 63/100, Best RMSE: 4.746740253879932\n",
      "Generation 64/100, Best RMSE: 4.746740253879932\n",
      "Generation 65/100, Best RMSE: 4.746740253879932\n",
      "Generation 66/100, Best RMSE: 4.746740253879932\n",
      "Generation 67/100, Best RMSE: 4.746740253879932\n",
      "Generation 68/100, Best RMSE: 4.746740253879932\n",
      "Generation 69/100, Best RMSE: 4.746740253879932\n",
      "Generation 70/100, Best RMSE: 4.746740253879932\n",
      "Generation 71/100, Best RMSE: 4.746740253879932\n",
      "Generation 72/100, Best RMSE: 4.746740253879932\n",
      "Generation 73/100, Best RMSE: 4.746740253879932\n",
      "Generation 74/100, Best RMSE: 4.746740253879932\n",
      "Generation 75/100, Best RMSE: 4.746740253879932\n",
      "Generation 76/100, Best RMSE: 4.746740253879932\n",
      "Generation 77/100, Best RMSE: 4.746740253879932\n",
      "Generation 78/100, Best RMSE: 4.746740253879932\n",
      "Generation 79/100, Best RMSE: 4.746740253879932\n",
      "Generation 80/100, Best RMSE: 4.746740253879932\n",
      "Generation 81/100, Best RMSE: 4.746740253879932\n",
      "Generation 82/100, Best RMSE: 4.746740253879932\n",
      "Generation 83/100, Best RMSE: 4.746740253879932\n",
      "Generation 84/100, Best RMSE: 4.746740253879932\n",
      "Generation 85/100, Best RMSE: 4.746740253879932\n",
      "Generation 86/100, Best RMSE: 4.746740253879932\n",
      "Generation 87/100, Best RMSE: 4.746740253879932\n",
      "Generation 88/100, Best RMSE: 4.746740253879932\n",
      "Generation 89/100, Best RMSE: 4.746740253879932\n",
      "Generation 90/100, Best RMSE: 4.746740253879932\n",
      "Generation 91/100, Best RMSE: 4.746740253879932\n",
      "Generation 92/100, Best RMSE: 4.746740253879932\n",
      "Generation 93/100, Best RMSE: 4.746740253879932\n",
      "Generation 94/100, Best RMSE: 4.746740253879932\n",
      "Generation 95/100, Best RMSE: 4.746740253879932\n",
      "Generation 96/100, Best RMSE: 4.746740253879932\n",
      "Generation 97/100, Best RMSE: 4.746740253879932\n",
      "Generation 98/100, Best RMSE: 4.746740253879932\n",
      "Generation 99/100, Best RMSE: 4.746740253879932\n",
      "Generation 100/100, Best RMSE: 4.746740253879932\n",
      "Optimal Weights: [0.13730062 0.0167808  0.57050898 0.27540961 0.        ]\n",
      "Generation 1/100, Best RMSE: 4.552369981929663\n",
      "Generation 2/100, Best RMSE: 4.552369981929663\n",
      "Generation 3/100, Best RMSE: 4.552369981929663\n",
      "Generation 4/100, Best RMSE: 4.552369981929663\n",
      "Generation 5/100, Best RMSE: 4.552369981929663\n",
      "Generation 6/100, Best RMSE: 4.552369981929663\n",
      "Generation 7/100, Best RMSE: 4.552369981929663\n",
      "Generation 8/100, Best RMSE: 4.547885377580273\n",
      "Generation 9/100, Best RMSE: 4.547885377580273\n",
      "Generation 10/100, Best RMSE: 4.547885377580273\n",
      "Generation 11/100, Best RMSE: 4.547885377580273\n",
      "Generation 12/100, Best RMSE: 4.547885377580273\n",
      "Generation 13/100, Best RMSE: 4.547885377580273\n",
      "Generation 14/100, Best RMSE: 4.547885377580273\n",
      "Generation 15/100, Best RMSE: 4.547885377580273\n",
      "Generation 16/100, Best RMSE: 4.547885377580273\n",
      "Generation 17/100, Best RMSE: 4.547885377580273\n",
      "Generation 18/100, Best RMSE: 4.547885377580273\n",
      "Generation 19/100, Best RMSE: 4.547885377580273\n",
      "Generation 20/100, Best RMSE: 4.547885377580273\n",
      "Generation 21/100, Best RMSE: 4.547885377580273\n",
      "Generation 22/100, Best RMSE: 4.547885377580273\n",
      "Generation 23/100, Best RMSE: 4.547885377580273\n",
      "Generation 24/100, Best RMSE: 4.547885377580273\n",
      "Generation 25/100, Best RMSE: 4.547885377580273\n",
      "Generation 26/100, Best RMSE: 4.547885377580273\n",
      "Generation 27/100, Best RMSE: 4.547885377580273\n",
      "Generation 28/100, Best RMSE: 4.547885377580273\n",
      "Generation 29/100, Best RMSE: 4.547885377580273\n",
      "Generation 30/100, Best RMSE: 4.547885377580273\n",
      "Generation 31/100, Best RMSE: 4.547885377580273\n",
      "Generation 32/100, Best RMSE: 4.547885377580273\n",
      "Generation 33/100, Best RMSE: 4.547885377580273\n",
      "Generation 34/100, Best RMSE: 4.547885377580273\n",
      "Generation 35/100, Best RMSE: 4.547885377580273\n",
      "Generation 36/100, Best RMSE: 4.547885377580273\n",
      "Generation 37/100, Best RMSE: 4.547885377580273\n",
      "Generation 38/100, Best RMSE: 4.547885377580273\n",
      "Generation 39/100, Best RMSE: 4.547885377580273\n",
      "Generation 40/100, Best RMSE: 4.547885377580273\n",
      "Generation 41/100, Best RMSE: 4.547885377580273\n",
      "Generation 42/100, Best RMSE: 4.547885377580273\n",
      "Generation 43/100, Best RMSE: 4.547885377580273\n",
      "Generation 44/100, Best RMSE: 4.547885377580273\n",
      "Generation 45/100, Best RMSE: 4.547885377580273\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./ga_검증_w2_2\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# 저장할 경로를 지정\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# validate_ga 함수 실행하여 결과 가져오기\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m overall_rmse_list, ga_time_list, \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_ga\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpopulation_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmutation_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.03\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[31], line 19\u001b[0m, in \u001b[0;36mvalidate_ga\u001b[1;34m(input_directory, population_size, generations, mutation_rate, output_dir)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m month \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m12\u001b[39m):\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# 검증 데이터를 통해 GA 가중치 구하기\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     model_predictions, true_values \u001b[38;5;241m=\u001b[39m load_and_process_validation_data(input_directory, month)  \u001b[38;5;66;03m# 월별로 검증 데이터 로드\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m     optimal_weights, ga_time \u001b[38;5;241m=\u001b[39m \u001b[43mrun_ga_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpopulation_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmutation_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# 테스트 데이터를 로드하여 최적 가중치로 예측 및 RMSE 계산\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     test_predictions, test_true_values \u001b[38;5;241m=\u001b[39m load_and_process_test_data(input_directory, month)  \u001b[38;5;66;03m# 월별로 테스트 데이터 로드\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[27], line 10\u001b[0m, in \u001b[0;36mrun_ga_experiment\u001b[1;34m(model_predictions, true_values, population_size, generations, mutation_rate, seed)\u001b[0m\n\u001b[0;32m      6\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(seed)  \u001b[38;5;66;03m# seed 설정\u001b[39;00m\n\u001b[0;32m      8\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 10\u001b[0m optimal_weights \u001b[38;5;241m=\u001b[39m \u001b[43mgenetic_algorithm_with_elitism\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mpopulation_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpopulation_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mgenerations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmutation_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmutation_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m ga_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# 앙상블 예측\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[26], line 45\u001b[0m, in \u001b[0;36mgenetic_algorithm_with_elitism\u001b[1;34m(model_predictions, true_values, population_size, generations, mutation_rate, seed)\u001b[0m\n\u001b[0;32m     43\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(seed \u001b[38;5;241m+\u001b[39m generation \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# 세대마다 다른 시드 적용\u001b[39;00m\n\u001b[0;32m     44\u001b[0m crossover_point \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1\u001b[39m, num_models)\n\u001b[1;32m---> 45\u001b[0m child \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent1\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mcrossover_point\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent2\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcrossover_point\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# 돌연변이\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand() \u001b[38;5;241m<\u001b[39m mutation_rate:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 실험에 사용할 입력 데이터 디렉토리 경로를 지정\n",
    "input_directory = \"./ga_w2\"  # 데이터가 저장된 디렉토리 경로로 수정해주세요.\n",
    "# validate_ga 함수 호출\n",
    "# 실행 후 파일을 저장할 디렉토리 지정\n",
    "output_dir = \"./ga_검증_w2_2\"  # 저장할 경로를 지정\n",
    "\n",
    "# validate_ga 함수 실행하여 결과 가져오기\n",
    "overall_rmse_list, ga_time_list, = validate_ga(input_directory, population_size=100, generations=100, mutation_rate=0.03, output_dir=output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "최종 평균 RMSE\n",
      "전체 앙상블 평균 RMSE: 3.142510850439882\n",
      "GA 평균 계산 시간: 1.362541737095002\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n최종 평균 RMSE\")\n",
    "print(f\"전체 앙상블 평균 RMSE: {np.mean(overall_rmse_list)}\")\n",
    "print(f\"GA 평균 계산 시간: {np.mean(ga_time_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
