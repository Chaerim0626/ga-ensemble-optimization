{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GA RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def roulette_wheel_selection(population, fitness_scores):\n",
    "    \"\"\"\n",
    "    룰렛 휠 선택 방식으로 부모 개체를 선택\n",
    "    Args:\n",
    "        population: 현재 개체군 (가중치 배열)\n",
    "        fitness_scores: 각 개체의 RMSE (낮을수록 좋음)\n",
    "    Returns:\n",
    "        선택된 부모 개체\n",
    "    \"\"\"\n",
    "    fitness_list = []\n",
    "    max_fitness = max(fitness_scores)\n",
    "    min_fitness = min(fitness_scores)\n",
    "    adjustment = (max_fitness - min_fitness) / 2 if max_fitness != min_fitness else 1  # 조정 값\n",
    "\n",
    "    for m in range(len(fitness_scores)):\n",
    "        # fitness 계산\n",
    "        fitness = max_fitness - fitness_scores[m] + adjustment\n",
    "        fitness_list.append(fitness)\n",
    "\n",
    "    fitness_list = np.array(fitness_list)\n",
    "    total_fitness = np.sum(fitness_list)\n",
    "\n",
    "    # total_fitness가 0인 경우 예외 처리\n",
    "    if total_fitness == 0:\n",
    "        raise ValueError(\"Total fitness is 0, cannot calculate probabilities.\")\n",
    "\n",
    "    probabilities = fitness_list / total_fitness\n",
    "\n",
    "    # 룰렛 휠 방식으로 부모 선택\n",
    "    selected_index = np.random.choice(len(population), p=probabilities)\n",
    "    return population[selected_index]\n",
    "\n",
    "\n",
    "def genetic_algorithm_with_elitism(model_predictions, true_values, population_size=100, generations=100, mutation_rate=0.03):\n",
    "    \"\"\"\n",
    "    GA를 사용하여 최적의 가중치 찾기\n",
    "    Args:\n",
    "        model_predictions: (n_samples, models, time_window, 2) 형태의 모델 예측값\n",
    "        true_values: (n_samples, time_window, 2) 형태의 실제값\n",
    "        population_size: 초기 개체군 크기\n",
    "        generations: 세대 수\n",
    "        mutation_rate: 돌연변이 확률\n",
    "    Returns:\n",
    "        최적 가중치 배열\n",
    "    \"\"\"\n",
    "    num_models = model_predictions.shape[1]  # 모델 수\n",
    "    population = np.random.dirichlet(np.ones(num_models), size=population_size)  # 초기 가중치 개체군\n",
    "\n",
    "    for generation in range(generations):\n",
    "        fitness_scores = []\n",
    "\n",
    "        # 현재 population의 fitness (RMSE) 계산\n",
    "        for individual in population:\n",
    "            ensemble_prediction = np.sum(\n",
    "                [weight * model_predictions[:, i, :, :] for i, weight in enumerate(individual)],\n",
    "                axis=0\n",
    "            )\n",
    "            rmse = np.sqrt(np.mean((true_values - ensemble_prediction) ** 2))\n",
    "            fitness_scores.append(rmse)\n",
    "        \n",
    "        fitness_scores = np.array(fitness_scores)\n",
    "\n",
    "        # 새로운 population 생성\n",
    "        new_population = []\n",
    "        while len(new_population) < population_size:\n",
    "            # 부모 선택\n",
    "            parent1 = roulette_wheel_selection(population, fitness_scores)\n",
    "            parent2 = roulette_wheel_selection(population, fitness_scores)\n",
    "\n",
    "            # 교차 연산\n",
    "            crossover_point = np.random.randint(1, num_models)\n",
    "            child = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))\n",
    "\n",
    "            # 돌연변이\n",
    "            if np.random.rand() < mutation_rate:\n",
    "                mutation_vector = np.random.normal(0, 0.1, size=num_models)\n",
    "                child = np.clip(child + mutation_vector, 0, 1)\n",
    "\n",
    "            # 정규화\n",
    "            child = child / np.sum(child)\n",
    "            new_population.append(child)\n",
    "        \n",
    "        new_population = np.array(new_population)\n",
    "\n",
    "        # 엘리티즘 적용\n",
    "        combined_population = np.vstack((population, new_population))\n",
    "        combined_fitness = np.concatenate((fitness_scores, np.zeros(len(new_population))))\n",
    "\n",
    "        for idx, individual in enumerate(new_population):\n",
    "            ensemble_prediction = np.sum(\n",
    "                [weight * model_predictions[:, i, :, :] for i, weight in enumerate(individual)],\n",
    "                axis=0\n",
    "            )\n",
    "            combined_fitness[len(fitness_scores) + idx] = np.sqrt(np.mean((true_values - ensemble_prediction) ** 2))\n",
    "\n",
    "        sorted_indices = np.argsort(combined_fitness)\n",
    "        population = combined_population[sorted_indices][:population_size]\n",
    "\n",
    "        print(f\"Generation {generation + 1}/{generations}, Best RMSE: {combined_fitness[sorted_indices][0]}\")\n",
    "\n",
    "    # 최적 개체 반환\n",
    "    best_weights = population[0]\n",
    "    print(f\"Optimal Weights: {best_weights}\")\n",
    "    return best_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def load_and_process_validation_data(input_directory, month, models=5, time_window=48):\n",
    "    model_predictions = []  # 각 모델의 예측값 저장\n",
    "\n",
    "    for model_idx in range(1, models + 1):\n",
    "        model_dir = os.path.join(input_directory, f\"model{model_idx}\")\n",
    "        file_path = os.path.join(model_dir, f'val_month_{month}_model_{model_idx}_results.csv')\n",
    "\n",
    "        # 🔍 파일 존재 여부 확인\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"파일이 존재하지 않습니다: {file_path}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"CSV 파일을 읽는 중 오류 발생: {file_path}, 오류: {e}\")\n",
    "            continue\n",
    "\n",
    "        # 🔍 컬럼 존재 여부 확인\n",
    "        pred_u_col = f\"Model {model_idx} Val Pred U\"\n",
    "        pred_v_col = f\"Model {model_idx} Val Pred V\"\n",
    "\n",
    "        if pred_u_col not in df.columns or pred_v_col not in df.columns:\n",
    "            print(f\"예측 컬럼이 존재하지 않습니다: {pred_u_col}, {pred_v_col}\")\n",
    "            continue\n",
    "\n",
    "        pred_u = df[pred_u_col].values\n",
    "        pred_v = df[pred_v_col].values\n",
    "\n",
    "        # True 값은 모델 1에서만 추출\n",
    "        if model_idx == 1:\n",
    "            if \"True U\" not in df.columns or \"True V\" not in df.columns:\n",
    "                print(f\"True 값 컬럼이 존재하지 않습니다.\")\n",
    "                continue\n",
    "\n",
    "            true_u = df[\"True U\"].values\n",
    "            true_v = df[\"True V\"].values\n",
    "\n",
    "        # 🔍 데이터 길이 확인 및 예외 처리\n",
    "        n_samples = len(pred_u) // time_window\n",
    "        if n_samples == 0:\n",
    "            print(f\"{file_path}: 데이터가 부족합니다. (데이터 길이: {len(pred_u)})\")\n",
    "            continue\n",
    "\n",
    "        pred_u = np.array(pred_u[:n_samples * time_window]).reshape(n_samples, time_window, 1)\n",
    "        pred_v = np.array(pred_v[:n_samples * time_window]).reshape(n_samples, time_window, 1)\n",
    "        model_predictions.append(np.concatenate([pred_u, pred_v], axis=2))  # (n_samples, 48, 2)\n",
    "\n",
    "        # True 값 병합 (한 번만 실행)\n",
    "        if model_idx == 1:\n",
    "            true_u = np.array(true_u[:n_samples * time_window]).reshape(n_samples, time_window, 1)\n",
    "            true_v = np.array(true_v[:n_samples * time_window]).reshape(n_samples, time_window, 1)\n",
    "            true_values = np.concatenate([true_u, true_v], axis=2)  # (n_samples, 48, 2)\n",
    "\n",
    "    # 🔍 예측값이 없는 경우 예외 처리\n",
    "    if not model_predictions:\n",
    "        print(f\"{month}월: 모델 예측값이 없습니다.\")\n",
    "        return np.array([]), np.array([])\n",
    "\n",
    "    # 🔍 모델 예측값 형태 변환: (n_samples, models, 48, 2)\n",
    "    try:\n",
    "        model_predictions = np.stack(model_predictions, axis=1)\n",
    "    except ValueError as e:\n",
    "        print(f\"모델 예측값 병합 중 오류 발생: {e}\")\n",
    "        return np.array([]), np.array([])\n",
    "\n",
    "    return model_predictions, true_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 5, 48, 2) (28, 48, 2)\n",
      "Generation 1/100, Best RMSE: 2.4892451847932526\n",
      "Generation 2/100, Best RMSE: 2.4892451847932526\n",
      "Generation 3/100, Best RMSE: 2.4840025743603382\n",
      "Generation 4/100, Best RMSE: 2.477932539573514\n",
      "Generation 5/100, Best RMSE: 2.477932539573514\n",
      "Generation 6/100, Best RMSE: 2.4769732789217427\n",
      "Generation 7/100, Best RMSE: 2.476595650542298\n",
      "Generation 8/100, Best RMSE: 2.476223955025573\n",
      "Generation 9/100, Best RMSE: 2.4760774585222434\n",
      "Generation 10/100, Best RMSE: 2.4759646732103877\n",
      "Generation 11/100, Best RMSE: 2.4759512277440296\n",
      "Generation 12/100, Best RMSE: 2.475949648856288\n",
      "Generation 13/100, Best RMSE: 2.4759248460555208\n",
      "Generation 14/100, Best RMSE: 2.4759248460555208\n",
      "Generation 15/100, Best RMSE: 2.475903775145306\n",
      "Generation 16/100, Best RMSE: 2.475902058888825\n",
      "Generation 17/100, Best RMSE: 2.475902058888825\n",
      "Generation 18/100, Best RMSE: 2.475902058888825\n",
      "Generation 19/100, Best RMSE: 2.475902058888825\n",
      "Generation 20/100, Best RMSE: 2.475902058888825\n",
      "Generation 21/100, Best RMSE: 2.475902058888825\n",
      "Generation 22/100, Best RMSE: 2.475902055355553\n",
      "Generation 23/100, Best RMSE: 2.4759020092137667\n",
      "Generation 24/100, Best RMSE: 2.4759020092137667\n",
      "Generation 25/100, Best RMSE: 2.475902005516422\n",
      "Generation 26/100, Best RMSE: 2.475901994495269\n",
      "Generation 27/100, Best RMSE: 2.475901990402292\n",
      "Generation 28/100, Best RMSE: 2.47590198169704\n",
      "Generation 29/100, Best RMSE: 2.475901976175956\n",
      "Generation 30/100, Best RMSE: 2.4759019746655664\n",
      "Generation 31/100, Best RMSE: 2.4759019746655664\n",
      "Generation 32/100, Best RMSE: 2.4759019741893034\n",
      "Generation 33/100, Best RMSE: 2.4759019735935652\n",
      "Generation 34/100, Best RMSE: 2.4759019735935652\n",
      "Generation 35/100, Best RMSE: 2.475901973369689\n",
      "Generation 36/100, Best RMSE: 2.4759019732068817\n",
      "Generation 37/100, Best RMSE: 2.4759019715230663\n",
      "Generation 38/100, Best RMSE: 2.475901970855492\n",
      "Generation 39/100, Best RMSE: 2.475901970855492\n",
      "Generation 40/100, Best RMSE: 2.475901970855492\n",
      "Generation 41/100, Best RMSE: 2.4759019708477092\n",
      "Generation 42/100, Best RMSE: 2.4759019707232928\n",
      "Generation 43/100, Best RMSE: 2.4759019706921572\n",
      "Generation 44/100, Best RMSE: 2.4759019706616994\n",
      "Generation 45/100, Best RMSE: 2.47590197061471\n",
      "Generation 46/100, Best RMSE: 2.47590197059182\n",
      "Generation 47/100, Best RMSE: 2.4759019705826333\n",
      "Generation 48/100, Best RMSE: 2.475901970541247\n",
      "Generation 49/100, Best RMSE: 2.4759019705009204\n",
      "Generation 50/100, Best RMSE: 2.475901970467246\n",
      "Generation 51/100, Best RMSE: 2.475901970438436\n",
      "Generation 52/100, Best RMSE: 2.4759019704374876\n",
      "Generation 53/100, Best RMSE: 2.475901970403064\n",
      "Generation 54/100, Best RMSE: 2.475901970403064\n",
      "Generation 55/100, Best RMSE: 2.475901970403064\n",
      "Generation 56/100, Best RMSE: 2.4759019704008045\n",
      "Generation 57/100, Best RMSE: 2.475901970387341\n",
      "Generation 58/100, Best RMSE: 2.475901970387341\n",
      "Generation 59/100, Best RMSE: 2.475901970387341\n",
      "Generation 60/100, Best RMSE: 2.475901970382844\n",
      "Generation 61/100, Best RMSE: 2.475901970381812\n",
      "Generation 62/100, Best RMSE: 2.4759019703784646\n",
      "Generation 63/100, Best RMSE: 2.4759019703784646\n",
      "Generation 64/100, Best RMSE: 2.4759019703770067\n",
      "Generation 65/100, Best RMSE: 2.4759019703752614\n",
      "Generation 66/100, Best RMSE: 2.475901970374736\n",
      "Generation 67/100, Best RMSE: 2.475901970374736\n",
      "Generation 68/100, Best RMSE: 2.4759019703729352\n",
      "Generation 69/100, Best RMSE: 2.4759019703729352\n",
      "Generation 70/100, Best RMSE: 2.4759019703720644\n",
      "Generation 71/100, Best RMSE: 2.4759019703718415\n",
      "Generation 72/100, Best RMSE: 2.4759019703717398\n",
      "Generation 73/100, Best RMSE: 2.475901970371328\n",
      "Generation 74/100, Best RMSE: 2.475901970371066\n",
      "Generation 75/100, Best RMSE: 2.475901970371054\n",
      "Generation 76/100, Best RMSE: 2.475901970370668\n",
      "Generation 77/100, Best RMSE: 2.475901970370614\n",
      "Generation 78/100, Best RMSE: 2.475901970370466\n",
      "Generation 79/100, Best RMSE: 2.4759019703704084\n",
      "Generation 80/100, Best RMSE: 2.4759019703703147\n",
      "Generation 81/100, Best RMSE: 2.4759019703702982\n",
      "Generation 82/100, Best RMSE: 2.4759019703702707\n",
      "Generation 83/100, Best RMSE: 2.475901970370208\n",
      "Generation 84/100, Best RMSE: 2.4759019703701894\n",
      "Generation 85/100, Best RMSE: 2.4759019703701894\n",
      "Generation 86/100, Best RMSE: 2.475901970370184\n",
      "Generation 87/100, Best RMSE: 2.4759019703701792\n",
      "Generation 88/100, Best RMSE: 2.4759019703701792\n",
      "Generation 89/100, Best RMSE: 2.4759019703701766\n",
      "Generation 90/100, Best RMSE: 2.47590197037016\n",
      "Generation 91/100, Best RMSE: 2.47590197037016\n",
      "Generation 92/100, Best RMSE: 2.4759019703701464\n",
      "Generation 93/100, Best RMSE: 2.4759019703701464\n",
      "Generation 94/100, Best RMSE: 2.4759019703701464\n",
      "Generation 95/100, Best RMSE: 2.4759019703701464\n",
      "Generation 96/100, Best RMSE: 2.475901970370146\n",
      "Generation 97/100, Best RMSE: 2.475901970370145\n",
      "Generation 98/100, Best RMSE: 2.4759019703701446\n",
      "Generation 99/100, Best RMSE: 2.475901970370144\n",
      "Generation 100/100, Best RMSE: 2.4759019703701433\n",
      "Optimal Weights: [0.51842763 0.03934001 0.37414119 0.         0.06809118]\n",
      "(31, 5, 48, 2) (31, 48, 2)\n",
      "Generation 1/100, Best RMSE: 2.5701735151522405\n",
      "Generation 2/100, Best RMSE: 2.5653790846142934\n",
      "Generation 3/100, Best RMSE: 2.5653790846142934\n",
      "Generation 4/100, Best RMSE: 2.5651457020151742\n",
      "Generation 5/100, Best RMSE: 2.565069716783168\n",
      "Generation 6/100, Best RMSE: 2.565022734633937\n",
      "Generation 7/100, Best RMSE: 2.5644669278694354\n",
      "Generation 8/100, Best RMSE: 2.564410347344593\n",
      "Generation 9/100, Best RMSE: 2.564346396994637\n",
      "Generation 10/100, Best RMSE: 2.564346396994637\n",
      "Generation 11/100, Best RMSE: 2.564346396994637\n",
      "Generation 12/100, Best RMSE: 2.5643437873592623\n",
      "Generation 13/100, Best RMSE: 2.564343044811643\n",
      "Generation 14/100, Best RMSE: 2.564343044811643\n",
      "Generation 15/100, Best RMSE: 2.56434293706841\n",
      "Generation 16/100, Best RMSE: 2.5643420597729456\n",
      "Generation 17/100, Best RMSE: 2.564341900680357\n",
      "Generation 18/100, Best RMSE: 2.5643412908621666\n",
      "Generation 19/100, Best RMSE: 2.5643410544586\n",
      "Generation 20/100, Best RMSE: 2.564340957308297\n",
      "Generation 21/100, Best RMSE: 2.5643407493272057\n",
      "Generation 22/100, Best RMSE: 2.5643405610016945\n",
      "Generation 23/100, Best RMSE: 2.5643405610016945\n",
      "Generation 24/100, Best RMSE: 2.564340450366108\n",
      "Generation 25/100, Best RMSE: 2.564340450366108\n",
      "Generation 26/100, Best RMSE: 2.564340442402464\n",
      "Generation 27/100, Best RMSE: 2.564340400960759\n",
      "Generation 28/100, Best RMSE: 2.564340400960759\n",
      "Generation 29/100, Best RMSE: 2.5643403700014153\n",
      "Generation 30/100, Best RMSE: 2.5643403700014153\n",
      "Generation 31/100, Best RMSE: 2.5643403651681376\n",
      "Generation 32/100, Best RMSE: 2.5643403572930494\n",
      "Generation 33/100, Best RMSE: 2.5643403539544978\n",
      "Generation 34/100, Best RMSE: 2.5643403517848204\n",
      "Generation 35/100, Best RMSE: 2.5643403517848204\n",
      "Generation 36/100, Best RMSE: 2.5643403514053014\n",
      "Generation 37/100, Best RMSE: 2.5643403503058972\n",
      "Generation 38/100, Best RMSE: 2.5643403461805505\n",
      "Generation 39/100, Best RMSE: 2.5643403461805505\n",
      "Generation 40/100, Best RMSE: 2.5643403450383913\n",
      "Generation 41/100, Best RMSE: 2.5643403440428876\n",
      "Generation 42/100, Best RMSE: 2.564340343383314\n",
      "Generation 43/100, Best RMSE: 2.5643403428561595\n",
      "Generation 44/100, Best RMSE: 2.5643403413111128\n",
      "Generation 45/100, Best RMSE: 2.564340340646838\n",
      "Generation 46/100, Best RMSE: 2.564340340646838\n",
      "Generation 47/100, Best RMSE: 2.564340340646838\n",
      "Generation 48/100, Best RMSE: 2.564340340517225\n",
      "Generation 49/100, Best RMSE: 2.564340340194854\n",
      "Generation 50/100, Best RMSE: 2.5643403399239157\n",
      "Generation 51/100, Best RMSE: 2.564340339850568\n",
      "Generation 52/100, Best RMSE: 2.5643403398347804\n",
      "Generation 53/100, Best RMSE: 2.5643403398347804\n",
      "Generation 54/100, Best RMSE: 2.5643403398347804\n",
      "Generation 55/100, Best RMSE: 2.5643403397967823\n",
      "Generation 56/100, Best RMSE: 2.5643403397205398\n",
      "Generation 57/100, Best RMSE: 2.5643403397205398\n",
      "Generation 58/100, Best RMSE: 2.5643403397203004\n",
      "Generation 59/100, Best RMSE: 2.564340339684286\n",
      "Generation 60/100, Best RMSE: 2.564340339663282\n",
      "Generation 61/100, Best RMSE: 2.5643403396555007\n",
      "Generation 62/100, Best RMSE: 2.564340339633327\n",
      "Generation 63/100, Best RMSE: 2.564340339615375\n",
      "Generation 64/100, Best RMSE: 2.5643403395892084\n",
      "Generation 65/100, Best RMSE: 2.5643403395892084\n",
      "Generation 66/100, Best RMSE: 2.564340339586796\n",
      "Generation 67/100, Best RMSE: 2.56434033956399\n",
      "Generation 68/100, Best RMSE: 2.56434033956399\n",
      "Generation 69/100, Best RMSE: 2.5643403395581745\n",
      "Generation 70/100, Best RMSE: 2.564340339555946\n",
      "Generation 71/100, Best RMSE: 2.5643403395429982\n",
      "Generation 72/100, Best RMSE: 2.564340339541952\n",
      "Generation 73/100, Best RMSE: 2.564340339532831\n",
      "Generation 74/100, Best RMSE: 2.5643403395322553\n",
      "Generation 75/100, Best RMSE: 2.5643403395316584\n",
      "Generation 76/100, Best RMSE: 2.564340339528253\n",
      "Generation 77/100, Best RMSE: 2.5643403395281457\n",
      "Generation 78/100, Best RMSE: 2.564340339524451\n",
      "Generation 79/100, Best RMSE: 2.5643403395234503\n",
      "Generation 80/100, Best RMSE: 2.56434033952217\n",
      "Generation 81/100, Best RMSE: 2.5643403395209337\n",
      "Generation 82/100, Best RMSE: 2.5643403395206184\n",
      "Generation 83/100, Best RMSE: 2.5643403395206184\n",
      "Generation 84/100, Best RMSE: 2.564340339520054\n",
      "Generation 85/100, Best RMSE: 2.5643403395188047\n",
      "Generation 86/100, Best RMSE: 2.5643403395186453\n",
      "Generation 87/100, Best RMSE: 2.564340339517907\n",
      "Generation 88/100, Best RMSE: 2.5643403395172624\n",
      "Generation 89/100, Best RMSE: 2.5643403395170954\n",
      "Generation 90/100, Best RMSE: 2.564340339516633\n",
      "Generation 91/100, Best RMSE: 2.5643403395159416\n",
      "Generation 92/100, Best RMSE: 2.5643403395159416\n",
      "Generation 93/100, Best RMSE: 2.5643403395159416\n",
      "Generation 94/100, Best RMSE: 2.5643403395157165\n",
      "Generation 95/100, Best RMSE: 2.564340339515379\n",
      "Generation 96/100, Best RMSE: 2.5643403395152733\n",
      "Generation 97/100, Best RMSE: 2.5643403395149127\n",
      "Generation 98/100, Best RMSE: 2.5643403395147617\n",
      "Generation 99/100, Best RMSE: 2.564340339514627\n",
      "Generation 100/100, Best RMSE: 2.5643403395143216\n",
      "Optimal Weights: [0.38389873 0.13705036 0.08239942 0.         0.39665149]\n",
      "(30, 5, 48, 2) (30, 48, 2)\n",
      "Generation 1/100, Best RMSE: 3.853196478886592\n",
      "Generation 2/100, Best RMSE: 3.85229724004458\n",
      "Generation 3/100, Best RMSE: 3.850282635540399\n",
      "Generation 4/100, Best RMSE: 3.850282635540399\n",
      "Generation 5/100, Best RMSE: 3.850282635540399\n",
      "Generation 6/100, Best RMSE: 3.8491346974892036\n",
      "Generation 7/100, Best RMSE: 3.848735199131522\n",
      "Generation 8/100, Best RMSE: 3.848735199131522\n",
      "Generation 9/100, Best RMSE: 3.8487043863536408\n",
      "Generation 10/100, Best RMSE: 3.8483599823415235\n",
      "Generation 11/100, Best RMSE: 3.8483006923985403\n",
      "Generation 12/100, Best RMSE: 3.848178878075974\n",
      "Generation 13/100, Best RMSE: 3.8481643249420423\n",
      "Generation 14/100, Best RMSE: 3.8481583303052473\n",
      "Generation 15/100, Best RMSE: 3.8481583303052473\n",
      "Generation 16/100, Best RMSE: 3.8479773938957975\n",
      "Generation 17/100, Best RMSE: 3.847970983284408\n",
      "Generation 18/100, Best RMSE: 3.847969664973389\n",
      "Generation 19/100, Best RMSE: 3.847969664973389\n",
      "Generation 20/100, Best RMSE: 3.8479684694269576\n",
      "Generation 21/100, Best RMSE: 3.8479682602851497\n",
      "Generation 22/100, Best RMSE: 3.8479681839107944\n",
      "Generation 23/100, Best RMSE: 3.8479681750290142\n",
      "Generation 24/100, Best RMSE: 3.8479681750290142\n",
      "Generation 25/100, Best RMSE: 3.8479680140546737\n",
      "Generation 26/100, Best RMSE: 3.8479680140546737\n",
      "Generation 27/100, Best RMSE: 3.8479680140546737\n",
      "Generation 28/100, Best RMSE: 3.8479680140546737\n",
      "Generation 29/100, Best RMSE: 3.847967977615031\n",
      "Generation 30/100, Best RMSE: 3.8479679409577554\n",
      "Generation 31/100, Best RMSE: 3.8479679400231404\n",
      "Generation 32/100, Best RMSE: 3.84796793907125\n",
      "Generation 33/100, Best RMSE: 3.84796793907125\n",
      "Generation 34/100, Best RMSE: 3.847967938431262\n",
      "Generation 35/100, Best RMSE: 3.847967938431262\n",
      "Generation 36/100, Best RMSE: 3.847967938431262\n",
      "Generation 37/100, Best RMSE: 3.8479679383919665\n",
      "Generation 38/100, Best RMSE: 3.8479679383919665\n",
      "Generation 39/100, Best RMSE: 3.84796793822492\n",
      "Generation 40/100, Best RMSE: 3.84796793822492\n",
      "Generation 41/100, Best RMSE: 3.84796793822492\n",
      "Generation 42/100, Best RMSE: 3.84796793822492\n",
      "Generation 43/100, Best RMSE: 3.8479679382025136\n",
      "Generation 44/100, Best RMSE: 3.8479679381920193\n",
      "Generation 45/100, Best RMSE: 3.8479679381920193\n",
      "Generation 46/100, Best RMSE: 3.847967938188484\n",
      "Generation 47/100, Best RMSE: 3.847967938173165\n",
      "Generation 48/100, Best RMSE: 3.847967938167872\n",
      "Generation 49/100, Best RMSE: 3.8479679381577143\n",
      "Generation 50/100, Best RMSE: 3.8479679381572263\n",
      "Generation 51/100, Best RMSE: 3.847967938154312\n",
      "Generation 52/100, Best RMSE: 3.847967938145133\n",
      "Generation 53/100, Best RMSE: 3.8479679381367653\n",
      "Generation 54/100, Best RMSE: 3.8479679381325496\n",
      "Generation 55/100, Best RMSE: 3.847967938127478\n",
      "Generation 56/100, Best RMSE: 3.847967938127478\n",
      "Generation 57/100, Best RMSE: 3.8479679381273435\n",
      "Generation 58/100, Best RMSE: 3.8479679381260024\n",
      "Generation 59/100, Best RMSE: 3.8479679381253695\n",
      "Generation 60/100, Best RMSE: 3.8479679381233525\n",
      "Generation 61/100, Best RMSE: 3.8479679381224785\n",
      "Generation 62/100, Best RMSE: 3.847967938121566\n",
      "Generation 63/100, Best RMSE: 3.8479679381212915\n",
      "Generation 64/100, Best RMSE: 3.8479679381208967\n",
      "Generation 65/100, Best RMSE: 3.847967938119794\n",
      "Generation 66/100, Best RMSE: 3.847967938119794\n",
      "Generation 67/100, Best RMSE: 3.8479679381195617\n",
      "Generation 68/100, Best RMSE: 3.847967938118896\n",
      "Generation 69/100, Best RMSE: 3.847967938118879\n",
      "Generation 70/100, Best RMSE: 3.8479679381180882\n",
      "Generation 71/100, Best RMSE: 3.8479679381180882\n",
      "Generation 72/100, Best RMSE: 3.8479679381178142\n",
      "Generation 73/100, Best RMSE: 3.847967938117596\n",
      "Generation 74/100, Best RMSE: 3.8479679381173097\n",
      "Generation 75/100, Best RMSE: 3.8479679381173097\n",
      "Generation 76/100, Best RMSE: 3.8479679381171117\n",
      "Generation 77/100, Best RMSE: 3.847967938117004\n",
      "Generation 78/100, Best RMSE: 3.847967938116905\n",
      "Generation 79/100, Best RMSE: 3.847967938116836\n",
      "Generation 80/100, Best RMSE: 3.847967938116826\n",
      "Generation 81/100, Best RMSE: 3.847967938116754\n",
      "Generation 82/100, Best RMSE: 3.8479679381165757\n",
      "Generation 83/100, Best RMSE: 3.8479679381165757\n",
      "Generation 84/100, Best RMSE: 3.8479679381165623\n",
      "Generation 85/100, Best RMSE: 3.8479679381165237\n",
      "Generation 86/100, Best RMSE: 3.8479679381165015\n",
      "Generation 87/100, Best RMSE: 3.8479679381164384\n",
      "Generation 88/100, Best RMSE: 3.8479679381164384\n",
      "Generation 89/100, Best RMSE: 3.847967938116396\n",
      "Generation 90/100, Best RMSE: 3.847967938116364\n",
      "Generation 91/100, Best RMSE: 3.847967938116332\n",
      "Generation 92/100, Best RMSE: 3.847967938116332\n",
      "Generation 93/100, Best RMSE: 3.847967938116323\n",
      "Generation 94/100, Best RMSE: 3.8479679381163083\n",
      "Generation 95/100, Best RMSE: 3.8479679381163083\n",
      "Generation 96/100, Best RMSE: 3.8479679381162923\n",
      "Generation 97/100, Best RMSE: 3.8479679381162777\n",
      "Generation 98/100, Best RMSE: 3.8479679381162546\n",
      "Generation 99/100, Best RMSE: 3.847967938116245\n",
      "Generation 100/100, Best RMSE: 3.847967938116222\n",
      "Optimal Weights: [0.         0.02975621 0.31423977 0.39087923 0.26512478]\n",
      "(27, 5, 48, 2) (27, 48, 2)\n",
      "Generation 1/100, Best RMSE: 5.3931221690795725\n",
      "Generation 2/100, Best RMSE: 5.3931221690795725\n",
      "Generation 3/100, Best RMSE: 5.354405587047089\n",
      "Generation 4/100, Best RMSE: 5.329595124785625\n",
      "Generation 5/100, Best RMSE: 5.314455216144154\n",
      "Generation 6/100, Best RMSE: 5.290837775468357\n",
      "Generation 7/100, Best RMSE: 5.290837775468357\n",
      "Generation 8/100, Best RMSE: 5.269254002892545\n",
      "Generation 9/100, Best RMSE: 5.268146188109213\n",
      "Generation 10/100, Best RMSE: 5.256327653671634\n",
      "Generation 11/100, Best RMSE: 5.256327653671634\n",
      "Generation 12/100, Best RMSE: 5.249452300218392\n",
      "Generation 13/100, Best RMSE: 5.2459949666275\n",
      "Generation 14/100, Best RMSE: 5.2393353013855\n",
      "Generation 15/100, Best RMSE: 5.2393353013855\n",
      "Generation 16/100, Best RMSE: 5.2393353013855\n",
      "Generation 17/100, Best RMSE: 5.2393353013855\n",
      "Generation 18/100, Best RMSE: 5.2393353013855\n",
      "Generation 19/100, Best RMSE: 5.2393353013855\n",
      "Generation 20/100, Best RMSE: 5.2393353013855\n",
      "Generation 21/100, Best RMSE: 5.2393353013855\n",
      "Generation 22/100, Best RMSE: 5.2393353013855\n",
      "Generation 23/100, Best RMSE: 5.2393353013855\n",
      "Generation 24/100, Best RMSE: 5.2393353013855\n",
      "Generation 25/100, Best RMSE: 5.2393353013855\n",
      "Generation 26/100, Best RMSE: 5.2393353013855\n",
      "Generation 27/100, Best RMSE: 5.2393353013855\n",
      "Generation 28/100, Best RMSE: 5.2393353013855\n",
      "Generation 29/100, Best RMSE: 5.2393353013855\n",
      "Generation 30/100, Best RMSE: 5.2393353013855\n",
      "Generation 31/100, Best RMSE: 5.2393353013855\n",
      "Generation 32/100, Best RMSE: 5.2393353013855\n",
      "Generation 33/100, Best RMSE: 5.2393353013855\n",
      "Generation 34/100, Best RMSE: 5.2393353013855\n",
      "Generation 35/100, Best RMSE: 5.2393353013855\n",
      "Generation 36/100, Best RMSE: 5.2393353013855\n",
      "Generation 37/100, Best RMSE: 5.2393353013855\n",
      "Generation 38/100, Best RMSE: 5.2393353013855\n",
      "Generation 39/100, Best RMSE: 5.2393353013855\n",
      "Generation 40/100, Best RMSE: 5.2393353013855\n",
      "Generation 41/100, Best RMSE: 5.2393353013855\n",
      "Generation 42/100, Best RMSE: 5.2393353013855\n",
      "Generation 43/100, Best RMSE: 5.2393353013855\n",
      "Generation 44/100, Best RMSE: 5.2393353013855\n",
      "Generation 45/100, Best RMSE: 5.2393353013855\n",
      "Generation 46/100, Best RMSE: 5.2393353013855\n",
      "Generation 47/100, Best RMSE: 5.2393353013855\n",
      "Generation 48/100, Best RMSE: 5.2393353013855\n",
      "Generation 49/100, Best RMSE: 5.2393353013855\n",
      "Generation 50/100, Best RMSE: 5.2393353013855\n",
      "Generation 51/100, Best RMSE: 5.2393353013855\n",
      "Generation 52/100, Best RMSE: 5.2393353013855\n",
      "Generation 53/100, Best RMSE: 5.2393353013855\n",
      "Generation 54/100, Best RMSE: 5.2393353013855\n",
      "Generation 55/100, Best RMSE: 5.2393353013855\n",
      "Generation 56/100, Best RMSE: 5.2393353013855\n",
      "Generation 57/100, Best RMSE: 5.2393353013855\n",
      "Generation 58/100, Best RMSE: 5.2393353013855\n",
      "Generation 59/100, Best RMSE: 5.2393353013855\n",
      "Generation 60/100, Best RMSE: 5.2393353013855\n",
      "Generation 61/100, Best RMSE: 5.2393353013855\n",
      "Generation 62/100, Best RMSE: 5.2393353013855\n",
      "Generation 63/100, Best RMSE: 5.2393353013855\n",
      "Generation 64/100, Best RMSE: 5.2393353013855\n",
      "Generation 65/100, Best RMSE: 5.2393353013855\n",
      "Generation 66/100, Best RMSE: 5.2393353013855\n",
      "Generation 67/100, Best RMSE: 5.2393353013855\n",
      "Generation 68/100, Best RMSE: 5.2393353013855\n",
      "Generation 69/100, Best RMSE: 5.2393353013855\n",
      "Generation 70/100, Best RMSE: 5.2393353013855\n",
      "Generation 71/100, Best RMSE: 5.2393353013855\n",
      "Generation 72/100, Best RMSE: 5.2393353013855\n",
      "Generation 73/100, Best RMSE: 5.2393353013855\n",
      "Generation 74/100, Best RMSE: 5.2393353013855\n",
      "Generation 75/100, Best RMSE: 5.2393353013855\n",
      "Generation 76/100, Best RMSE: 5.2393353013855\n",
      "Generation 77/100, Best RMSE: 5.2393353013855\n",
      "Generation 78/100, Best RMSE: 5.2393353013855\n",
      "Generation 79/100, Best RMSE: 5.2393353013855\n",
      "Generation 80/100, Best RMSE: 5.2393353013855\n",
      "Generation 81/100, Best RMSE: 5.2393353013855\n",
      "Generation 82/100, Best RMSE: 5.2393353013855\n",
      "Generation 83/100, Best RMSE: 5.2393353013855\n",
      "Generation 84/100, Best RMSE: 5.2393353013855\n",
      "Generation 85/100, Best RMSE: 5.2393353013855\n",
      "Generation 86/100, Best RMSE: 5.2393353013855\n",
      "Generation 87/100, Best RMSE: 5.2393353013855\n",
      "Generation 88/100, Best RMSE: 5.2393353013855\n",
      "Generation 89/100, Best RMSE: 5.2393353013855\n",
      "Generation 90/100, Best RMSE: 5.2393353013855\n",
      "Generation 91/100, Best RMSE: 5.2393353013855\n",
      "Generation 92/100, Best RMSE: 5.2393353013855\n",
      "Generation 93/100, Best RMSE: 5.2393353013855\n",
      "Generation 94/100, Best RMSE: 5.2393353013855\n",
      "Generation 95/100, Best RMSE: 5.2393353013855\n",
      "Generation 96/100, Best RMSE: 5.2393353013855\n",
      "Generation 97/100, Best RMSE: 5.2393353013855\n",
      "Generation 98/100, Best RMSE: 5.2393353013855\n",
      "Generation 99/100, Best RMSE: 5.2393353013855\n",
      "Generation 100/100, Best RMSE: 5.2393353013855\n",
      "Optimal Weights: [0. 0. 0. 1. 0.]\n",
      "(24, 5, 48, 2) (24, 48, 2)\n",
      "Generation 1/100, Best RMSE: 1.9963199562328116\n",
      "Generation 2/100, Best RMSE: 1.9929366075644368\n",
      "Generation 3/100, Best RMSE: 1.9921688408385632\n",
      "Generation 4/100, Best RMSE: 1.9920414777773234\n",
      "Generation 5/100, Best RMSE: 1.9917465471049725\n",
      "Generation 6/100, Best RMSE: 1.9915627594611054\n",
      "Generation 7/100, Best RMSE: 1.9915273838886633\n",
      "Generation 8/100, Best RMSE: 1.99137008068581\n",
      "Generation 9/100, Best RMSE: 1.9913483029541272\n",
      "Generation 10/100, Best RMSE: 1.9913061729484924\n",
      "Generation 11/100, Best RMSE: 1.9913061729484924\n",
      "Generation 12/100, Best RMSE: 1.9913061729484924\n",
      "Generation 13/100, Best RMSE: 1.9913056304568935\n",
      "Generation 14/100, Best RMSE: 1.9913045492208445\n",
      "Generation 15/100, Best RMSE: 1.9913042706344912\n",
      "Generation 16/100, Best RMSE: 1.9913035189058788\n",
      "Generation 17/100, Best RMSE: 1.9913032731429192\n",
      "Generation 18/100, Best RMSE: 1.9913030049229736\n",
      "Generation 19/100, Best RMSE: 1.9913029037400094\n",
      "Generation 20/100, Best RMSE: 1.9913029023660271\n",
      "Generation 21/100, Best RMSE: 1.9913028905391736\n",
      "Generation 22/100, Best RMSE: 1.9913028794705434\n",
      "Generation 23/100, Best RMSE: 1.9913028770878642\n",
      "Generation 24/100, Best RMSE: 1.9913028770878642\n",
      "Generation 25/100, Best RMSE: 1.9913028770878642\n",
      "Generation 26/100, Best RMSE: 1.9913028767275112\n",
      "Generation 27/100, Best RMSE: 1.9913028764487095\n",
      "Generation 28/100, Best RMSE: 1.991302876419549\n",
      "Generation 29/100, Best RMSE: 1.9913028763408585\n",
      "Generation 30/100, Best RMSE: 1.9913028763294813\n",
      "Generation 31/100, Best RMSE: 1.9913028763212923\n",
      "Generation 32/100, Best RMSE: 1.9913028763103706\n",
      "Generation 33/100, Best RMSE: 1.99130287629013\n",
      "Generation 34/100, Best RMSE: 1.9913028762867007\n",
      "Generation 35/100, Best RMSE: 1.9913028762830876\n",
      "Generation 36/100, Best RMSE: 1.9913028762751497\n",
      "Generation 37/100, Best RMSE: 1.9913028762725367\n",
      "Generation 38/100, Best RMSE: 1.9913028762705818\n",
      "Generation 39/100, Best RMSE: 1.9913028762705818\n",
      "Generation 40/100, Best RMSE: 1.991302876269941\n",
      "Generation 41/100, Best RMSE: 1.991302876269941\n",
      "Generation 42/100, Best RMSE: 1.9913028762679394\n",
      "Generation 43/100, Best RMSE: 1.9913028762679394\n",
      "Generation 44/100, Best RMSE: 1.991302876267938\n",
      "Generation 45/100, Best RMSE: 1.9913028762671716\n",
      "Generation 46/100, Best RMSE: 1.9913028762670928\n",
      "Generation 47/100, Best RMSE: 1.9913028762670928\n",
      "Generation 48/100, Best RMSE: 1.9913028762670915\n",
      "Generation 49/100, Best RMSE: 1.9913028762669072\n",
      "Generation 50/100, Best RMSE: 1.9913028762668536\n",
      "Generation 51/100, Best RMSE: 1.9913028762668359\n",
      "Generation 52/100, Best RMSE: 1.9913028762667513\n",
      "Generation 53/100, Best RMSE: 1.9913028762666234\n",
      "Generation 54/100, Best RMSE: 1.991302876266535\n",
      "Generation 55/100, Best RMSE: 1.991302876266532\n",
      "Generation 56/100, Best RMSE: 1.9913028762664395\n",
      "Generation 57/100, Best RMSE: 1.9913028762664167\n",
      "Generation 58/100, Best RMSE: 1.9913028762664156\n",
      "Generation 59/100, Best RMSE: 1.9913028762664016\n",
      "Generation 60/100, Best RMSE: 1.9913028762663334\n",
      "Generation 61/100, Best RMSE: 1.9913028762663256\n",
      "Generation 62/100, Best RMSE: 1.991302876266317\n",
      "Generation 63/100, Best RMSE: 1.9913028762663076\n",
      "Generation 64/100, Best RMSE: 1.9913028762662928\n",
      "Generation 65/100, Best RMSE: 1.991302876266281\n",
      "Generation 66/100, Best RMSE: 1.9913028762662472\n",
      "Generation 67/100, Best RMSE: 1.9913028762662457\n",
      "Generation 68/100, Best RMSE: 1.9913028762662388\n",
      "Generation 69/100, Best RMSE: 1.9913028762662357\n",
      "Generation 70/100, Best RMSE: 1.9913028762662248\n",
      "Generation 71/100, Best RMSE: 1.991302876266215\n",
      "Generation 72/100, Best RMSE: 1.9913028762662066\n",
      "Generation 73/100, Best RMSE: 1.9913028762662066\n",
      "Generation 74/100, Best RMSE: 1.991302876266192\n",
      "Generation 75/100, Best RMSE: 1.9913028762661904\n",
      "Generation 76/100, Best RMSE: 1.9913028762661886\n",
      "Generation 77/100, Best RMSE: 1.9913028762661833\n",
      "Generation 78/100, Best RMSE: 1.9913028762661822\n",
      "Generation 79/100, Best RMSE: 1.9913028762661813\n",
      "Generation 80/100, Best RMSE: 1.9913028762661673\n",
      "Generation 81/100, Best RMSE: 1.9913028762661669\n",
      "Generation 82/100, Best RMSE: 1.991302876266164\n",
      "Generation 83/100, Best RMSE: 1.9913028762661624\n",
      "Generation 84/100, Best RMSE: 1.9913028762661615\n",
      "Generation 85/100, Best RMSE: 1.9913028762661584\n",
      "Generation 86/100, Best RMSE: 1.9913028762661569\n",
      "Generation 87/100, Best RMSE: 1.991302876266154\n",
      "Generation 88/100, Best RMSE: 1.9913028762661527\n",
      "Generation 89/100, Best RMSE: 1.9913028762661524\n",
      "Generation 90/100, Best RMSE: 1.9913028762661489\n",
      "Generation 91/100, Best RMSE: 1.9913028762661469\n",
      "Generation 92/100, Best RMSE: 1.991302876266146\n",
      "Generation 93/100, Best RMSE: 1.991302876266146\n",
      "Generation 94/100, Best RMSE: 1.9913028762661449\n",
      "Generation 95/100, Best RMSE: 1.9913028762661424\n",
      "Generation 96/100, Best RMSE: 1.991302876266142\n",
      "Generation 97/100, Best RMSE: 1.9913028762661389\n",
      "Generation 98/100, Best RMSE: 1.9913028762661389\n",
      "Generation 99/100, Best RMSE: 1.9913028762661376\n",
      "Generation 100/100, Best RMSE: 1.9913028762661376\n",
      "Optimal Weights: [0.45259968 0.02216514 0.30682226 0.         0.21841293]\n",
      "(16, 5, 48, 2) (16, 48, 2)\n",
      "Generation 1/100, Best RMSE: 2.5577290712802476\n",
      "Generation 2/100, Best RMSE: 2.5495803760326226\n",
      "Generation 3/100, Best RMSE: 2.5495803760326226\n",
      "Generation 4/100, Best RMSE: 2.5495803760326226\n",
      "Generation 5/100, Best RMSE: 2.548832017883402\n",
      "Generation 6/100, Best RMSE: 2.548832017883402\n",
      "Generation 7/100, Best RMSE: 2.548720386728976\n",
      "Generation 8/100, Best RMSE: 2.548720386728976\n",
      "Generation 9/100, Best RMSE: 2.548720386728976\n",
      "Generation 10/100, Best RMSE: 2.548667654549595\n",
      "Generation 11/100, Best RMSE: 2.54863527937241\n",
      "Generation 12/100, Best RMSE: 2.54863527937241\n",
      "Generation 13/100, Best RMSE: 2.54862350340711\n",
      "Generation 14/100, Best RMSE: 2.548616370015721\n",
      "Generation 15/100, Best RMSE: 2.548616370015721\n",
      "Generation 16/100, Best RMSE: 2.548610954110315\n",
      "Generation 17/100, Best RMSE: 2.548610954110315\n",
      "Generation 18/100, Best RMSE: 2.5486102661747116\n",
      "Generation 19/100, Best RMSE: 2.5486102491167237\n",
      "Generation 20/100, Best RMSE: 2.548609960380535\n",
      "Generation 21/100, Best RMSE: 2.5486095486278084\n",
      "Generation 22/100, Best RMSE: 2.5486093399009158\n",
      "Generation 23/100, Best RMSE: 2.548609070054669\n",
      "Generation 24/100, Best RMSE: 2.5486089313995297\n",
      "Generation 25/100, Best RMSE: 2.5486085582792994\n",
      "Generation 26/100, Best RMSE: 2.5486084797175614\n",
      "Generation 27/100, Best RMSE: 2.5486084797175614\n",
      "Generation 28/100, Best RMSE: 2.5486084458157827\n",
      "Generation 29/100, Best RMSE: 2.5486083049704344\n",
      "Generation 30/100, Best RMSE: 2.5486083049704344\n",
      "Generation 31/100, Best RMSE: 2.548608277653652\n",
      "Generation 32/100, Best RMSE: 2.5486082581252476\n",
      "Generation 33/100, Best RMSE: 2.5486081953756368\n",
      "Generation 34/100, Best RMSE: 2.5486081704391865\n",
      "Generation 35/100, Best RMSE: 2.54860814651417\n",
      "Generation 36/100, Best RMSE: 2.54860814651417\n",
      "Generation 37/100, Best RMSE: 2.5486081287553417\n",
      "Generation 38/100, Best RMSE: 2.54860811325857\n",
      "Generation 39/100, Best RMSE: 2.54860807510417\n",
      "Generation 40/100, Best RMSE: 2.5486080684252843\n",
      "Generation 41/100, Best RMSE: 2.548608047456944\n",
      "Generation 42/100, Best RMSE: 2.5486080319194966\n",
      "Generation 43/100, Best RMSE: 2.5486080319194966\n",
      "Generation 44/100, Best RMSE: 2.5486080319194966\n",
      "Generation 45/100, Best RMSE: 2.548608029875313\n",
      "Generation 46/100, Best RMSE: 2.5486080176457033\n",
      "Generation 47/100, Best RMSE: 2.5486080176457033\n",
      "Generation 48/100, Best RMSE: 2.548608014956989\n",
      "Generation 49/100, Best RMSE: 2.5486080144677614\n",
      "Generation 50/100, Best RMSE: 2.548608008431634\n",
      "Generation 51/100, Best RMSE: 2.548608007935756\n",
      "Generation 52/100, Best RMSE: 2.548608007740267\n",
      "Generation 53/100, Best RMSE: 2.5486080015826373\n",
      "Generation 54/100, Best RMSE: 2.5486079984144214\n",
      "Generation 55/100, Best RMSE: 2.5486079982128684\n",
      "Generation 56/100, Best RMSE: 2.5486079973102695\n",
      "Generation 57/100, Best RMSE: 2.5486079952154865\n",
      "Generation 58/100, Best RMSE: 2.5486079949864764\n",
      "Generation 59/100, Best RMSE: 2.548607993893309\n",
      "Generation 60/100, Best RMSE: 2.5486079915227684\n",
      "Generation 61/100, Best RMSE: 2.5486079887905153\n",
      "Generation 62/100, Best RMSE: 2.548607987993313\n",
      "Generation 63/100, Best RMSE: 2.5486079879783525\n",
      "Generation 64/100, Best RMSE: 2.548607987324025\n",
      "Generation 65/100, Best RMSE: 2.5486079830291706\n",
      "Generation 66/100, Best RMSE: 2.5486079830291706\n",
      "Generation 67/100, Best RMSE: 2.5486079830291706\n",
      "Generation 68/100, Best RMSE: 2.5486079823347807\n",
      "Generation 69/100, Best RMSE: 2.5486079823347807\n",
      "Generation 70/100, Best RMSE: 2.5486079821375953\n",
      "Generation 71/100, Best RMSE: 2.5486079805425597\n",
      "Generation 72/100, Best RMSE: 2.548607980097995\n",
      "Generation 73/100, Best RMSE: 2.5486079798094208\n",
      "Generation 74/100, Best RMSE: 2.54860797875229\n",
      "Generation 75/100, Best RMSE: 2.548607978725632\n",
      "Generation 76/100, Best RMSE: 2.548607978725632\n",
      "Generation 77/100, Best RMSE: 2.548607977830498\n",
      "Generation 78/100, Best RMSE: 2.548607977432158\n",
      "Generation 79/100, Best RMSE: 2.548607977432158\n",
      "Generation 80/100, Best RMSE: 2.548607977043111\n",
      "Generation 81/100, Best RMSE: 2.5486079768260055\n",
      "Generation 82/100, Best RMSE: 2.5486079768260055\n",
      "Generation 83/100, Best RMSE: 2.548607976506524\n",
      "Generation 84/100, Best RMSE: 2.548607976358784\n",
      "Generation 85/100, Best RMSE: 2.5486079761343206\n",
      "Generation 86/100, Best RMSE: 2.5486079761343206\n",
      "Generation 87/100, Best RMSE: 2.5486079758285856\n",
      "Generation 88/100, Best RMSE: 2.5486079757594755\n",
      "Generation 89/100, Best RMSE: 2.548607975686093\n",
      "Generation 90/100, Best RMSE: 2.548607975583178\n",
      "Generation 91/100, Best RMSE: 2.5486079753181237\n",
      "Generation 92/100, Best RMSE: 2.5486079753181237\n",
      "Generation 93/100, Best RMSE: 2.5486079752714517\n",
      "Generation 94/100, Best RMSE: 2.5486079751064583\n",
      "Generation 95/100, Best RMSE: 2.548607975106339\n",
      "Generation 96/100, Best RMSE: 2.5486079749817483\n",
      "Generation 97/100, Best RMSE: 2.548607974902853\n",
      "Generation 98/100, Best RMSE: 2.548607974865035\n",
      "Generation 99/100, Best RMSE: 2.548607974817235\n",
      "Generation 100/100, Best RMSE: 2.548607974791514\n",
      "Optimal Weights: [0.02991626 0.         0.50781986 0.         0.46226387]\n",
      "(16, 5, 48, 2) (16, 48, 2)\n",
      "Generation 1/100, Best RMSE: 2.4801269622695146\n",
      "Generation 2/100, Best RMSE: 2.4770763154592994\n",
      "Generation 3/100, Best RMSE: 2.4749435495617718\n",
      "Generation 4/100, Best RMSE: 2.471836515290301\n",
      "Generation 5/100, Best RMSE: 2.46988417098049\n",
      "Generation 6/100, Best RMSE: 2.4697523778573407\n",
      "Generation 7/100, Best RMSE: 2.467879010749939\n",
      "Generation 8/100, Best RMSE: 2.4671846077115154\n",
      "Generation 9/100, Best RMSE: 2.4666999398721\n",
      "Generation 10/100, Best RMSE: 2.4666999398721\n",
      "Generation 11/100, Best RMSE: 2.466622304621899\n",
      "Generation 12/100, Best RMSE: 2.466622304621899\n",
      "Generation 13/100, Best RMSE: 2.4662582072914745\n",
      "Generation 14/100, Best RMSE: 2.4662489938355234\n",
      "Generation 15/100, Best RMSE: 2.4662052836871866\n",
      "Generation 16/100, Best RMSE: 2.4662052836871866\n",
      "Generation 17/100, Best RMSE: 2.4661952451523153\n",
      "Generation 18/100, Best RMSE: 2.466193615930922\n",
      "Generation 19/100, Best RMSE: 2.4661929472603434\n",
      "Generation 20/100, Best RMSE: 2.4661924716496473\n",
      "Generation 21/100, Best RMSE: 2.4661924713769965\n",
      "Generation 22/100, Best RMSE: 2.4661924713769965\n",
      "Generation 23/100, Best RMSE: 2.4661924710767384\n",
      "Generation 24/100, Best RMSE: 2.466192316749873\n",
      "Generation 25/100, Best RMSE: 2.466192138913186\n",
      "Generation 26/100, Best RMSE: 2.466192127993994\n",
      "Generation 27/100, Best RMSE: 2.466192101453938\n",
      "Generation 28/100, Best RMSE: 2.466192093473832\n",
      "Generation 29/100, Best RMSE: 2.4661920912777218\n",
      "Generation 30/100, Best RMSE: 2.4661920905575174\n",
      "Generation 31/100, Best RMSE: 2.4661920559316544\n",
      "Generation 32/100, Best RMSE: 2.4661920553085994\n",
      "Generation 33/100, Best RMSE: 2.4661920553085994\n",
      "Generation 34/100, Best RMSE: 2.4661920385585034\n",
      "Generation 35/100, Best RMSE: 2.4661920324415236\n",
      "Generation 36/100, Best RMSE: 2.4661920248937648\n",
      "Generation 37/100, Best RMSE: 2.4661920202332857\n",
      "Generation 38/100, Best RMSE: 2.4661920091267917\n",
      "Generation 39/100, Best RMSE: 2.4661920070195973\n",
      "Generation 40/100, Best RMSE: 2.4661920005285007\n",
      "Generation 41/100, Best RMSE: 2.4661919901992113\n",
      "Generation 42/100, Best RMSE: 2.4661919823019933\n",
      "Generation 43/100, Best RMSE: 2.4661919823019933\n",
      "Generation 44/100, Best RMSE: 2.466191979272495\n",
      "Generation 45/100, Best RMSE: 2.4661919749943872\n",
      "Generation 46/100, Best RMSE: 2.4661919713520897\n",
      "Generation 47/100, Best RMSE: 2.4661919654278575\n",
      "Generation 48/100, Best RMSE: 2.4661919643173174\n",
      "Generation 49/100, Best RMSE: 2.466191959966457\n",
      "Generation 50/100, Best RMSE: 2.466191954814386\n",
      "Generation 51/100, Best RMSE: 2.466191954234377\n",
      "Generation 52/100, Best RMSE: 2.466191952497839\n",
      "Generation 53/100, Best RMSE: 2.466191949725551\n",
      "Generation 54/100, Best RMSE: 2.466191943673308\n",
      "Generation 55/100, Best RMSE: 2.4661919398886822\n",
      "Generation 56/100, Best RMSE: 2.466191938104981\n",
      "Generation 57/100, Best RMSE: 2.4661919340013734\n",
      "Generation 58/100, Best RMSE: 2.4661919269603123\n",
      "Generation 59/100, Best RMSE: 2.4661919266587065\n",
      "Generation 60/100, Best RMSE: 2.4661919266587065\n",
      "Generation 61/100, Best RMSE: 2.4661919226894677\n",
      "Generation 62/100, Best RMSE: 2.4661919223456237\n",
      "Generation 63/100, Best RMSE: 2.4661919219376056\n",
      "Generation 64/100, Best RMSE: 2.466191921211072\n",
      "Generation 65/100, Best RMSE: 2.4661919205923755\n",
      "Generation 66/100, Best RMSE: 2.466191920115385\n",
      "Generation 67/100, Best RMSE: 2.4661919193993773\n",
      "Generation 68/100, Best RMSE: 2.466191919103147\n",
      "Generation 69/100, Best RMSE: 2.466191918974536\n",
      "Generation 70/100, Best RMSE: 2.466191918392551\n",
      "Generation 71/100, Best RMSE: 2.466191918220307\n",
      "Generation 72/100, Best RMSE: 2.466191917416206\n",
      "Generation 73/100, Best RMSE: 2.4661919167520585\n",
      "Generation 74/100, Best RMSE: 2.4661919165239605\n",
      "Generation 75/100, Best RMSE: 2.466191916029766\n",
      "Generation 76/100, Best RMSE: 2.466191915902874\n",
      "Generation 77/100, Best RMSE: 2.4661919153529337\n",
      "Generation 78/100, Best RMSE: 2.466191914883942\n",
      "Generation 79/100, Best RMSE: 2.4661919146318505\n",
      "Generation 80/100, Best RMSE: 2.4661919145259183\n",
      "Generation 81/100, Best RMSE: 2.466191914271916\n",
      "Generation 82/100, Best RMSE: 2.466191913853812\n",
      "Generation 83/100, Best RMSE: 2.4661919135729633\n",
      "Generation 84/100, Best RMSE: 2.4661919130886285\n",
      "Generation 85/100, Best RMSE: 2.466191912786159\n",
      "Generation 86/100, Best RMSE: 2.4661919127437546\n",
      "Generation 87/100, Best RMSE: 2.466191912735989\n",
      "Generation 88/100, Best RMSE: 2.4661919124156686\n",
      "Generation 89/100, Best RMSE: 2.466191912339401\n",
      "Generation 90/100, Best RMSE: 2.4661919119543243\n",
      "Generation 91/100, Best RMSE: 2.466191911694548\n",
      "Generation 92/100, Best RMSE: 2.466191911458736\n",
      "Generation 93/100, Best RMSE: 2.466191911295089\n",
      "Generation 94/100, Best RMSE: 2.466191911252744\n",
      "Generation 95/100, Best RMSE: 2.4661919111432047\n",
      "Generation 96/100, Best RMSE: 2.466191910942038\n",
      "Generation 97/100, Best RMSE: 2.4661919109279222\n",
      "Generation 98/100, Best RMSE: 2.46619191077991\n",
      "Generation 99/100, Best RMSE: 2.466191910676428\n",
      "Generation 100/100, Best RMSE: 2.4661919105190506\n",
      "Optimal Weights: [0.11257954 0.         0.         0.30544933 0.58197113]\n",
      "(27, 5, 48, 2) (27, 48, 2)\n",
      "Generation 1/100, Best RMSE: 2.6639561885931715\n",
      "Generation 2/100, Best RMSE: 2.6617258325924733\n",
      "Generation 3/100, Best RMSE: 2.656579823050835\n",
      "Generation 4/100, Best RMSE: 2.6536528643871438\n",
      "Generation 5/100, Best RMSE: 2.6531292119875363\n",
      "Generation 6/100, Best RMSE: 2.652757268771032\n",
      "Generation 7/100, Best RMSE: 2.652757268771032\n",
      "Generation 8/100, Best RMSE: 2.6512863683768058\n",
      "Generation 9/100, Best RMSE: 2.6512863683768058\n",
      "Generation 10/100, Best RMSE: 2.6512863683768058\n",
      "Generation 11/100, Best RMSE: 2.6512190880302984\n",
      "Generation 12/100, Best RMSE: 2.651067480074951\n",
      "Generation 13/100, Best RMSE: 2.6510667857715444\n",
      "Generation 14/100, Best RMSE: 2.6510030208899185\n",
      "Generation 15/100, Best RMSE: 2.6510014430028077\n",
      "Generation 16/100, Best RMSE: 2.6509936582359748\n",
      "Generation 17/100, Best RMSE: 2.6509760192090503\n",
      "Generation 18/100, Best RMSE: 2.6509687368390615\n",
      "Generation 19/100, Best RMSE: 2.65096577539653\n",
      "Generation 20/100, Best RMSE: 2.650956709667063\n",
      "Generation 21/100, Best RMSE: 2.6509537138377164\n",
      "Generation 22/100, Best RMSE: 2.650950400143772\n",
      "Generation 23/100, Best RMSE: 2.6509494011803345\n",
      "Generation 24/100, Best RMSE: 2.6509494011803345\n",
      "Generation 25/100, Best RMSE: 2.6509494011803345\n",
      "Generation 26/100, Best RMSE: 2.650949315597581\n",
      "Generation 27/100, Best RMSE: 2.650949315597581\n",
      "Generation 28/100, Best RMSE: 2.650949315597581\n",
      "Generation 29/100, Best RMSE: 2.6509490616945244\n",
      "Generation 30/100, Best RMSE: 2.650948699612491\n",
      "Generation 31/100, Best RMSE: 2.650948699612491\n",
      "Generation 32/100, Best RMSE: 2.6509486854090674\n",
      "Generation 33/100, Best RMSE: 2.6509486328535625\n",
      "Generation 34/100, Best RMSE: 2.6509485892054574\n",
      "Generation 35/100, Best RMSE: 2.6509485892054574\n",
      "Generation 36/100, Best RMSE: 2.6509485853544055\n",
      "Generation 37/100, Best RMSE: 2.6509485333953586\n",
      "Generation 38/100, Best RMSE: 2.6509485333953586\n",
      "Generation 39/100, Best RMSE: 2.6509485313450503\n",
      "Generation 40/100, Best RMSE: 2.6509485241839728\n",
      "Generation 41/100, Best RMSE: 2.650948519506804\n",
      "Generation 42/100, Best RMSE: 2.650948519506804\n",
      "Generation 43/100, Best RMSE: 2.6509484901486426\n",
      "Generation 44/100, Best RMSE: 2.6509484901486426\n",
      "Generation 45/100, Best RMSE: 2.6509484901486426\n",
      "Generation 46/100, Best RMSE: 2.6509484901486426\n",
      "Generation 47/100, Best RMSE: 2.650948481205658\n",
      "Generation 48/100, Best RMSE: 2.650948481205658\n",
      "Generation 49/100, Best RMSE: 2.65094848104169\n",
      "Generation 50/100, Best RMSE: 2.6509484769531313\n",
      "Generation 51/100, Best RMSE: 2.650948472930289\n",
      "Generation 52/100, Best RMSE: 2.6509484689197653\n",
      "Generation 53/100, Best RMSE: 2.650948468147836\n",
      "Generation 54/100, Best RMSE: 2.6509484653859943\n",
      "Generation 55/100, Best RMSE: 2.6509484642073944\n",
      "Generation 56/100, Best RMSE: 2.650948460942945\n",
      "Generation 57/100, Best RMSE: 2.650948459403629\n",
      "Generation 58/100, Best RMSE: 2.6509484551268723\n",
      "Generation 59/100, Best RMSE: 2.6509484503004708\n",
      "Generation 60/100, Best RMSE: 2.650948449951029\n",
      "Generation 61/100, Best RMSE: 2.650948449951029\n",
      "Generation 62/100, Best RMSE: 2.6509484482227563\n",
      "Generation 63/100, Best RMSE: 2.650948447534252\n",
      "Generation 64/100, Best RMSE: 2.650948447534252\n",
      "Generation 65/100, Best RMSE: 2.6509484442364175\n",
      "Generation 66/100, Best RMSE: 2.650948444134526\n",
      "Generation 67/100, Best RMSE: 2.6509484434891446\n",
      "Generation 68/100, Best RMSE: 2.6509484434891446\n",
      "Generation 69/100, Best RMSE: 2.6509484434891446\n",
      "Generation 70/100, Best RMSE: 2.6509484429077084\n",
      "Generation 71/100, Best RMSE: 2.6509484429077084\n",
      "Generation 72/100, Best RMSE: 2.6509484427546104\n",
      "Generation 73/100, Best RMSE: 2.650948442145658\n",
      "Generation 74/100, Best RMSE: 2.6509484417237\n",
      "Generation 75/100, Best RMSE: 2.6509484417237\n",
      "Generation 76/100, Best RMSE: 2.6509484417237\n",
      "Generation 77/100, Best RMSE: 2.6509484415746782\n",
      "Generation 78/100, Best RMSE: 2.6509484413008075\n",
      "Generation 79/100, Best RMSE: 2.650948440992276\n",
      "Generation 80/100, Best RMSE: 2.6509484405848984\n",
      "Generation 81/100, Best RMSE: 2.650948440124131\n",
      "Generation 82/100, Best RMSE: 2.650948440066633\n",
      "Generation 83/100, Best RMSE: 2.6509484399105028\n",
      "Generation 84/100, Best RMSE: 2.6509484398363155\n",
      "Generation 85/100, Best RMSE: 2.6509484397681695\n",
      "Generation 86/100, Best RMSE: 2.650948439511138\n",
      "Generation 87/100, Best RMSE: 2.650948439511138\n",
      "Generation 88/100, Best RMSE: 2.650948439511138\n",
      "Generation 89/100, Best RMSE: 2.6509484392811675\n",
      "Generation 90/100, Best RMSE: 2.6509484392811675\n",
      "Generation 91/100, Best RMSE: 2.6509484392811675\n",
      "Generation 92/100, Best RMSE: 2.650948439214319\n",
      "Generation 93/100, Best RMSE: 2.650948439214319\n",
      "Generation 94/100, Best RMSE: 2.650948439214319\n",
      "Generation 95/100, Best RMSE: 2.6509484392068914\n",
      "Generation 96/100, Best RMSE: 2.6509484391092113\n",
      "Generation 97/100, Best RMSE: 2.6509484391092113\n",
      "Generation 98/100, Best RMSE: 2.6509484391092113\n",
      "Generation 99/100, Best RMSE: 2.6509484390532663\n",
      "Generation 100/100, Best RMSE: 2.6509484390405733\n",
      "Optimal Weights: [0.         0.19879487 0.05556217 0.21745841 0.52818455]\n",
      "(31, 5, 48, 2) (31, 48, 2)\n",
      "Generation 1/100, Best RMSE: 2.538221097389674\n",
      "Generation 2/100, Best RMSE: 2.538221097389674\n",
      "Generation 3/100, Best RMSE: 2.533866427798325\n",
      "Generation 4/100, Best RMSE: 2.533866427798325\n",
      "Generation 5/100, Best RMSE: 2.5334072417871534\n",
      "Generation 6/100, Best RMSE: 2.53325621164058\n",
      "Generation 7/100, Best RMSE: 2.5325417573081053\n",
      "Generation 8/100, Best RMSE: 2.5324015121750563\n",
      "Generation 9/100, Best RMSE: 2.5320621394458342\n",
      "Generation 10/100, Best RMSE: 2.5320621394458342\n",
      "Generation 11/100, Best RMSE: 2.531842628805149\n",
      "Generation 12/100, Best RMSE: 2.5316589153357\n",
      "Generation 13/100, Best RMSE: 2.531606901676391\n",
      "Generation 14/100, Best RMSE: 2.531323830158278\n",
      "Generation 15/100, Best RMSE: 2.531319770025233\n",
      "Generation 16/100, Best RMSE: 2.5313189932794544\n",
      "Generation 17/100, Best RMSE: 2.5313177958410065\n",
      "Generation 18/100, Best RMSE: 2.5313177958410065\n",
      "Generation 19/100, Best RMSE: 2.5313177808793834\n",
      "Generation 20/100, Best RMSE: 2.5313174358858666\n",
      "Generation 21/100, Best RMSE: 2.5313173825194313\n",
      "Generation 22/100, Best RMSE: 2.5313173594229896\n",
      "Generation 23/100, Best RMSE: 2.5313173594229896\n",
      "Generation 24/100, Best RMSE: 2.5313173534043436\n",
      "Generation 25/100, Best RMSE: 2.5313173532485824\n",
      "Generation 26/100, Best RMSE: 2.5313173532485824\n",
      "Generation 27/100, Best RMSE: 2.5313173531975024\n",
      "Generation 28/100, Best RMSE: 2.5313173529415716\n",
      "Generation 29/100, Best RMSE: 2.5313173529324815\n",
      "Generation 30/100, Best RMSE: 2.531317352924039\n",
      "Generation 31/100, Best RMSE: 2.531317352924039\n",
      "Generation 32/100, Best RMSE: 2.531317352924039\n",
      "Generation 33/100, Best RMSE: 2.531317352923252\n",
      "Generation 34/100, Best RMSE: 2.531317352923252\n",
      "Generation 35/100, Best RMSE: 2.5313173529230335\n",
      "Generation 36/100, Best RMSE: 2.5313173529230175\n",
      "Generation 37/100, Best RMSE: 2.531317352923009\n",
      "Generation 38/100, Best RMSE: 2.531317352923009\n",
      "Generation 39/100, Best RMSE: 2.531317352923009\n",
      "Generation 40/100, Best RMSE: 2.531317352923009\n",
      "Generation 41/100, Best RMSE: 2.531317352923008\n",
      "Generation 42/100, Best RMSE: 2.531317352923008\n",
      "Generation 43/100, Best RMSE: 2.531317352923008\n",
      "Generation 44/100, Best RMSE: 2.531317352923008\n",
      "Generation 45/100, Best RMSE: 2.531317352923008\n",
      "Generation 46/100, Best RMSE: 2.531317352923008\n",
      "Generation 47/100, Best RMSE: 2.531317352923008\n",
      "Generation 48/100, Best RMSE: 2.531317352923008\n",
      "Generation 49/100, Best RMSE: 2.531317352923008\n",
      "Generation 50/100, Best RMSE: 2.531317352923008\n",
      "Generation 51/100, Best RMSE: 2.531317352923008\n",
      "Generation 52/100, Best RMSE: 2.531317352923008\n",
      "Generation 53/100, Best RMSE: 2.531317352923008\n",
      "Generation 54/100, Best RMSE: 2.5313173529230077\n",
      "Generation 55/100, Best RMSE: 2.5313173529230077\n",
      "Generation 56/100, Best RMSE: 2.5313173529230077\n",
      "Generation 57/100, Best RMSE: 2.5313173529230077\n",
      "Generation 58/100, Best RMSE: 2.5313173529230077\n",
      "Generation 59/100, Best RMSE: 2.5313173529230077\n",
      "Generation 60/100, Best RMSE: 2.5313173529230077\n",
      "Generation 61/100, Best RMSE: 2.5313173529230077\n",
      "Generation 62/100, Best RMSE: 2.5313173529230077\n",
      "Generation 63/100, Best RMSE: 2.5313173529230077\n",
      "Generation 64/100, Best RMSE: 2.5313173529230077\n",
      "Generation 65/100, Best RMSE: 2.5313173529230077\n",
      "Generation 66/100, Best RMSE: 2.5313173529230077\n",
      "Generation 67/100, Best RMSE: 2.5313173529230077\n",
      "Generation 68/100, Best RMSE: 2.5313173529230077\n",
      "Generation 69/100, Best RMSE: 2.5313173529230077\n",
      "Generation 70/100, Best RMSE: 2.5313173529230077\n",
      "Generation 71/100, Best RMSE: 2.5313173529230077\n",
      "Generation 72/100, Best RMSE: 2.5313173529230077\n",
      "Generation 73/100, Best RMSE: 2.5313173529230077\n",
      "Generation 74/100, Best RMSE: 2.5313173529230077\n",
      "Generation 75/100, Best RMSE: 2.5313173529230077\n",
      "Generation 76/100, Best RMSE: 2.5313173529230077\n",
      "Generation 77/100, Best RMSE: 2.5313173529230077\n",
      "Generation 78/100, Best RMSE: 2.5313173529230077\n",
      "Generation 79/100, Best RMSE: 2.5313173529230077\n",
      "Generation 80/100, Best RMSE: 2.5313173529230077\n",
      "Generation 81/100, Best RMSE: 2.5313173529230077\n",
      "Generation 82/100, Best RMSE: 2.5313173529230077\n",
      "Generation 83/100, Best RMSE: 2.5313173529230077\n",
      "Generation 84/100, Best RMSE: 2.5313173529230077\n",
      "Generation 85/100, Best RMSE: 2.5313173529230077\n",
      "Generation 86/100, Best RMSE: 2.5313173529230077\n",
      "Generation 87/100, Best RMSE: 2.5313173529230077\n",
      "Generation 88/100, Best RMSE: 2.5313173529230077\n",
      "Generation 89/100, Best RMSE: 2.5313173529230077\n",
      "Generation 90/100, Best RMSE: 2.5313173529230077\n",
      "Generation 91/100, Best RMSE: 2.5313173529230077\n",
      "Generation 92/100, Best RMSE: 2.5313173529230077\n",
      "Generation 93/100, Best RMSE: 2.5313173529230077\n",
      "Generation 94/100, Best RMSE: 2.5313173529230077\n",
      "Generation 95/100, Best RMSE: 2.5313173529230077\n",
      "Generation 96/100, Best RMSE: 2.5313173529230077\n",
      "Generation 97/100, Best RMSE: 2.5313173529230077\n",
      "Generation 98/100, Best RMSE: 2.5313173529230077\n",
      "Generation 99/100, Best RMSE: 2.5313173529230077\n",
      "Generation 100/100, Best RMSE: 2.5313173529230077\n",
      "Optimal Weights: [0.3674709  0.         0.10396985 0.         0.52855925]\n",
      "(24, 5, 48, 2) (24, 48, 2)\n",
      "Generation 1/100, Best RMSE: 2.692405804689651\n",
      "Generation 2/100, Best RMSE: 2.692405804689651\n",
      "Generation 3/100, Best RMSE: 2.6808044006940097\n",
      "Generation 4/100, Best RMSE: 2.6808044006940097\n",
      "Generation 5/100, Best RMSE: 2.677754842861866\n",
      "Generation 6/100, Best RMSE: 2.6774259485872522\n",
      "Generation 7/100, Best RMSE: 2.6773869936732275\n",
      "Generation 8/100, Best RMSE: 2.6773869936732275\n",
      "Generation 9/100, Best RMSE: 2.6773869936732275\n",
      "Generation 10/100, Best RMSE: 2.6773755328686253\n",
      "Generation 11/100, Best RMSE: 2.6773686167021475\n",
      "Generation 12/100, Best RMSE: 2.6773664473302254\n",
      "Generation 13/100, Best RMSE: 2.677366194227811\n",
      "Generation 14/100, Best RMSE: 2.677366194227811\n",
      "Generation 15/100, Best RMSE: 2.677365941809802\n",
      "Generation 16/100, Best RMSE: 2.677365924358064\n",
      "Generation 17/100, Best RMSE: 2.6773659019776677\n",
      "Generation 18/100, Best RMSE: 2.6773659019776677\n",
      "Generation 19/100, Best RMSE: 2.677365870032346\n",
      "Generation 20/100, Best RMSE: 2.677365870032346\n",
      "Generation 21/100, Best RMSE: 2.677365870032346\n",
      "Generation 22/100, Best RMSE: 2.677365870032346\n",
      "Generation 23/100, Best RMSE: 2.677365856427572\n",
      "Generation 24/100, Best RMSE: 2.677365856427572\n",
      "Generation 25/100, Best RMSE: 2.677365856427572\n",
      "Generation 26/100, Best RMSE: 2.677365850460105\n",
      "Generation 27/100, Best RMSE: 2.677365850460105\n",
      "Generation 28/100, Best RMSE: 2.6773658493786616\n",
      "Generation 29/100, Best RMSE: 2.677365849151822\n",
      "Generation 30/100, Best RMSE: 2.677365848426432\n",
      "Generation 31/100, Best RMSE: 2.677365847959551\n",
      "Generation 32/100, Best RMSE: 2.6773658479253877\n",
      "Generation 33/100, Best RMSE: 2.6773658479253877\n",
      "Generation 34/100, Best RMSE: 2.6773658472544777\n",
      "Generation 35/100, Best RMSE: 2.6773658472528084\n",
      "Generation 36/100, Best RMSE: 2.677365847244919\n",
      "Generation 37/100, Best RMSE: 2.677365846925927\n",
      "Generation 38/100, Best RMSE: 2.677365846847724\n",
      "Generation 39/100, Best RMSE: 2.6773658468300234\n",
      "Generation 40/100, Best RMSE: 2.6773658467159143\n",
      "Generation 41/100, Best RMSE: 2.6773658466649066\n",
      "Generation 42/100, Best RMSE: 2.6773658465927457\n",
      "Generation 43/100, Best RMSE: 2.677365846499198\n",
      "Generation 44/100, Best RMSE: 2.6773658464982466\n",
      "Generation 45/100, Best RMSE: 2.677365846425543\n",
      "Generation 46/100, Best RMSE: 2.677365846425543\n",
      "Generation 47/100, Best RMSE: 2.6773658463659182\n",
      "Generation 48/100, Best RMSE: 2.6773658463659182\n",
      "Generation 49/100, Best RMSE: 2.6773658463260332\n",
      "Generation 50/100, Best RMSE: 2.6773658463253023\n",
      "Generation 51/100, Best RMSE: 2.677365846295771\n",
      "Generation 52/100, Best RMSE: 2.677365846295771\n",
      "Generation 53/100, Best RMSE: 2.677365846290179\n",
      "Generation 54/100, Best RMSE: 2.6773658462891605\n",
      "Generation 55/100, Best RMSE: 2.677365846282625\n",
      "Generation 56/100, Best RMSE: 2.6773658462707575\n",
      "Generation 57/100, Best RMSE: 2.6773658462679775\n",
      "Generation 58/100, Best RMSE: 2.6773658462623513\n",
      "Generation 59/100, Best RMSE: 2.6773658462504613\n",
      "Generation 60/100, Best RMSE: 2.6773658462493923\n",
      "Generation 61/100, Best RMSE: 2.6773658462416323\n",
      "Generation 62/100, Best RMSE: 2.6773658462415586\n",
      "Generation 63/100, Best RMSE: 2.677365846241474\n",
      "Generation 64/100, Best RMSE: 2.677365846238413\n",
      "Generation 65/100, Best RMSE: 2.6773658462378815\n",
      "Generation 66/100, Best RMSE: 2.6773658462372154\n",
      "Generation 67/100, Best RMSE: 2.6773658462364622\n",
      "Generation 68/100, Best RMSE: 2.6773658462352636\n",
      "Generation 69/100, Best RMSE: 2.67736584623339\n",
      "Generation 70/100, Best RMSE: 2.67736584623255\n",
      "Generation 71/100, Best RMSE: 2.6773658462325307\n",
      "Generation 72/100, Best RMSE: 2.677365846232023\n",
      "Generation 73/100, Best RMSE: 2.6773658462314276\n",
      "Generation 74/100, Best RMSE: 2.677365846231033\n",
      "Generation 75/100, Best RMSE: 2.6773658462302676\n",
      "Generation 76/100, Best RMSE: 2.6773658462302676\n",
      "Generation 77/100, Best RMSE: 2.6773658462302676\n",
      "Generation 78/100, Best RMSE: 2.6773658462302676\n",
      "Generation 79/100, Best RMSE: 2.6773658462300087\n",
      "Generation 80/100, Best RMSE: 2.677365846229989\n",
      "Generation 81/100, Best RMSE: 2.6773658462298537\n",
      "Generation 82/100, Best RMSE: 2.6773658462298537\n",
      "Generation 83/100, Best RMSE: 2.6773658462296925\n",
      "Generation 84/100, Best RMSE: 2.6773658462296925\n",
      "Generation 85/100, Best RMSE: 2.677365846229688\n",
      "Generation 86/100, Best RMSE: 2.677365846229637\n",
      "Generation 87/100, Best RMSE: 2.6773658462294243\n",
      "Generation 88/100, Best RMSE: 2.6773658462294225\n",
      "Generation 89/100, Best RMSE: 2.677365846229412\n",
      "Generation 90/100, Best RMSE: 2.67736584622935\n",
      "Generation 91/100, Best RMSE: 2.67736584622935\n",
      "Generation 92/100, Best RMSE: 2.6773658462293413\n",
      "Generation 93/100, Best RMSE: 2.6773658462293306\n",
      "Generation 94/100, Best RMSE: 2.6773658462293115\n",
      "Generation 95/100, Best RMSE: 2.6773658462293066\n",
      "Generation 96/100, Best RMSE: 2.6773658462292937\n",
      "Generation 97/100, Best RMSE: 2.67736584622929\n",
      "Generation 98/100, Best RMSE: 2.6773658462292698\n",
      "Generation 99/100, Best RMSE: 2.6773658462292658\n",
      "Generation 100/100, Best RMSE: 2.677365846229264\n",
      "Optimal Weights: [0.64270542 0.06810121 0.         0.         0.28919337]\n",
      "(25, 5, 48, 2) (25, 48, 2)\n",
      "Generation 1/100, Best RMSE: 2.475999674318466\n",
      "Generation 2/100, Best RMSE: 2.4285330644744145\n",
      "Generation 3/100, Best RMSE: 2.4285330644744145\n",
      "Generation 4/100, Best RMSE: 2.4285330644744145\n",
      "Generation 5/100, Best RMSE: 2.410943776952027\n",
      "Generation 6/100, Best RMSE: 2.402265361172251\n",
      "Generation 7/100, Best RMSE: 2.389302479487173\n",
      "Generation 8/100, Best RMSE: 2.389302479487173\n",
      "Generation 9/100, Best RMSE: 2.389302479487173\n",
      "Generation 10/100, Best RMSE: 2.3877901539013267\n",
      "Generation 11/100, Best RMSE: 2.3877901539013267\n",
      "Generation 12/100, Best RMSE: 2.3877901539013267\n",
      "Generation 13/100, Best RMSE: 2.3877901539013267\n",
      "Generation 14/100, Best RMSE: 2.3877901539013267\n",
      "Generation 15/100, Best RMSE: 2.3877872743369983\n",
      "Generation 16/100, Best RMSE: 2.3877872743369983\n",
      "Generation 17/100, Best RMSE: 2.38777286402861\n",
      "Generation 18/100, Best RMSE: 2.387759664704638\n",
      "Generation 19/100, Best RMSE: 2.3877475643971846\n",
      "Generation 20/100, Best RMSE: 2.387736463156062\n",
      "Generation 21/100, Best RMSE: 2.387736463156062\n",
      "Generation 22/100, Best RMSE: 2.387736463156062\n",
      "Generation 23/100, Best RMSE: 2.387736463156062\n",
      "Generation 24/100, Best RMSE: 2.387736463156062\n",
      "Generation 25/100, Best RMSE: 2.387736463156062\n",
      "Generation 26/100, Best RMSE: 2.387736463156062\n",
      "Generation 27/100, Best RMSE: 2.387736463156062\n",
      "Generation 28/100, Best RMSE: 2.387736463156062\n",
      "Generation 29/100, Best RMSE: 2.387736463156062\n",
      "Generation 30/100, Best RMSE: 2.387736463156062\n",
      "Generation 31/100, Best RMSE: 2.387736463156062\n",
      "Generation 32/100, Best RMSE: 2.387736463156062\n",
      "Generation 33/100, Best RMSE: 2.387736463156062\n",
      "Generation 34/100, Best RMSE: 2.387736463156062\n",
      "Generation 35/100, Best RMSE: 2.387736463156062\n",
      "Generation 36/100, Best RMSE: 2.387736463156062\n",
      "Generation 37/100, Best RMSE: 2.387736463156062\n",
      "Generation 38/100, Best RMSE: 2.3876421124302887\n",
      "Generation 39/100, Best RMSE: 2.3876421124302887\n",
      "Generation 40/100, Best RMSE: 2.3876421124302887\n",
      "Generation 41/100, Best RMSE: 2.3876421124302887\n",
      "Generation 42/100, Best RMSE: 2.3876421124302887\n",
      "Generation 43/100, Best RMSE: 2.3876421124302887\n",
      "Generation 44/100, Best RMSE: 2.3876421124302887\n",
      "Generation 45/100, Best RMSE: 2.3876421124302887\n",
      "Generation 46/100, Best RMSE: 2.3876421124302887\n",
      "Generation 47/100, Best RMSE: 2.3876421124302887\n",
      "Generation 48/100, Best RMSE: 2.3876421124302887\n",
      "Generation 49/100, Best RMSE: 2.3876421124302887\n",
      "Generation 50/100, Best RMSE: 2.3876421124302887\n",
      "Generation 51/100, Best RMSE: 2.3876421124302887\n",
      "Generation 52/100, Best RMSE: 2.3876421124302887\n",
      "Generation 53/100, Best RMSE: 2.3876421124302887\n",
      "Generation 54/100, Best RMSE: 2.3876421124302887\n",
      "Generation 55/100, Best RMSE: 2.3876421124302887\n",
      "Generation 56/100, Best RMSE: 2.3876421124302887\n",
      "Generation 57/100, Best RMSE: 2.3876421124302887\n",
      "Generation 58/100, Best RMSE: 2.3876421124302887\n",
      "Generation 59/100, Best RMSE: 2.3876421124302887\n",
      "Generation 60/100, Best RMSE: 2.3876421124302887\n",
      "Generation 61/100, Best RMSE: 2.3876421124302887\n",
      "Generation 62/100, Best RMSE: 2.3876421124302887\n",
      "Generation 63/100, Best RMSE: 2.3876421124302887\n",
      "Generation 64/100, Best RMSE: 2.3876421124302887\n",
      "Generation 65/100, Best RMSE: 2.3876421124302887\n",
      "Generation 66/100, Best RMSE: 2.3876421124302882\n",
      "Generation 67/100, Best RMSE: 2.3876421124302882\n",
      "Generation 68/100, Best RMSE: 2.3876421124302882\n",
      "Generation 69/100, Best RMSE: 2.3876421124302882\n",
      "Generation 70/100, Best RMSE: 2.3876421124302882\n",
      "Generation 71/100, Best RMSE: 2.3876421124302882\n",
      "Generation 72/100, Best RMSE: 2.3876421124302882\n",
      "Generation 73/100, Best RMSE: 2.3876421124302882\n",
      "Generation 74/100, Best RMSE: 2.3876421124302882\n",
      "Generation 75/100, Best RMSE: 2.3876421124302882\n",
      "Generation 76/100, Best RMSE: 2.3876421124302882\n",
      "Generation 77/100, Best RMSE: 2.3876421124302882\n",
      "Generation 78/100, Best RMSE: 2.3876421124302882\n",
      "Generation 79/100, Best RMSE: 2.3876421124302882\n",
      "Generation 80/100, Best RMSE: 2.3876421124302882\n",
      "Generation 81/100, Best RMSE: 2.3876421124302882\n",
      "Generation 82/100, Best RMSE: 2.3876421124302882\n",
      "Generation 83/100, Best RMSE: 2.3876421124302882\n",
      "Generation 84/100, Best RMSE: 2.3876421124302882\n",
      "Generation 85/100, Best RMSE: 2.3876421124302882\n",
      "Generation 86/100, Best RMSE: 2.3876421124302882\n",
      "Generation 87/100, Best RMSE: 2.3876421124302882\n",
      "Generation 88/100, Best RMSE: 2.3876421124302882\n",
      "Generation 89/100, Best RMSE: 2.3876421124302882\n",
      "Generation 90/100, Best RMSE: 2.3876421124302882\n",
      "Generation 91/100, Best RMSE: 2.3876421124302882\n",
      "Generation 92/100, Best RMSE: 2.3876421124302882\n",
      "Generation 93/100, Best RMSE: 2.3876421124302882\n",
      "Generation 94/100, Best RMSE: 2.3876421124302882\n",
      "Generation 95/100, Best RMSE: 2.3876421124302882\n",
      "Generation 96/100, Best RMSE: 2.3876421124302882\n",
      "Generation 97/100, Best RMSE: 2.3876421124302882\n",
      "Generation 98/100, Best RMSE: 2.3876421124302882\n",
      "Generation 99/100, Best RMSE: 2.3876421124302882\n",
      "Generation 100/100, Best RMSE: 2.3876421124302882\n",
      "Optimal Weights: [0.01527766 0.         0.         0.         0.98472234]\n",
      "(28, 5, 48, 2) (28, 48, 2)\n",
      "Generation 1/100, Best RMSE: 2.423599796620295\n",
      "Generation 2/100, Best RMSE: 2.423599796620295\n",
      "Generation 3/100, Best RMSE: 2.423599796620295\n",
      "Generation 4/100, Best RMSE: 2.423005734473843\n",
      "Generation 5/100, Best RMSE: 2.423005734473843\n",
      "Generation 6/100, Best RMSE: 2.4214115364927933\n",
      "Generation 7/100, Best RMSE: 2.421296010907467\n",
      "Generation 8/100, Best RMSE: 2.4202002728348733\n",
      "Generation 9/100, Best RMSE: 2.419707621240856\n",
      "Generation 10/100, Best RMSE: 2.419386875704292\n",
      "Generation 11/100, Best RMSE: 2.4193824165284523\n",
      "Generation 12/100, Best RMSE: 2.4193774871250535\n",
      "Generation 13/100, Best RMSE: 2.4193774871250535\n",
      "Generation 14/100, Best RMSE: 2.419373354388223\n",
      "Generation 15/100, Best RMSE: 2.419371912625763\n",
      "Generation 16/100, Best RMSE: 2.419371912625763\n",
      "Generation 17/100, Best RMSE: 2.4193718038845367\n",
      "Generation 18/100, Best RMSE: 2.4193715595865224\n",
      "Generation 19/100, Best RMSE: 2.4193715595865224\n",
      "Generation 20/100, Best RMSE: 2.4193715595865224\n",
      "Generation 21/100, Best RMSE: 2.419371428761433\n",
      "Generation 22/100, Best RMSE: 2.419371428761433\n",
      "Generation 23/100, Best RMSE: 2.419371428761433\n",
      "Generation 24/100, Best RMSE: 2.4193714149106973\n",
      "Generation 25/100, Best RMSE: 2.419371412310468\n",
      "Generation 26/100, Best RMSE: 2.419371412310468\n",
      "Generation 27/100, Best RMSE: 2.4193714117455056\n",
      "Generation 28/100, Best RMSE: 2.419371411693419\n",
      "Generation 29/100, Best RMSE: 2.4193714103387682\n",
      "Generation 30/100, Best RMSE: 2.41937140845863\n",
      "Generation 31/100, Best RMSE: 2.41937140845863\n",
      "Generation 32/100, Best RMSE: 2.419371408100425\n",
      "Generation 33/100, Best RMSE: 2.419371408100425\n",
      "Generation 34/100, Best RMSE: 2.419371408100425\n",
      "Generation 35/100, Best RMSE: 2.4193714080174376\n",
      "Generation 36/100, Best RMSE: 2.4193714076617923\n",
      "Generation 37/100, Best RMSE: 2.4193714076617923\n",
      "Generation 38/100, Best RMSE: 2.4193714075462203\n",
      "Generation 39/100, Best RMSE: 2.4193714075462203\n",
      "Generation 40/100, Best RMSE: 2.4193714074761488\n",
      "Generation 41/100, Best RMSE: 2.4193714074723554\n",
      "Generation 42/100, Best RMSE: 2.419371407452133\n",
      "Generation 43/100, Best RMSE: 2.4193714073546437\n",
      "Generation 44/100, Best RMSE: 2.4193714073546437\n",
      "Generation 45/100, Best RMSE: 2.4193714073229238\n",
      "Generation 46/100, Best RMSE: 2.419371407320913\n",
      "Generation 47/100, Best RMSE: 2.419371407306648\n",
      "Generation 48/100, Best RMSE: 2.4193714072820893\n",
      "Generation 49/100, Best RMSE: 2.4193714072601757\n",
      "Generation 50/100, Best RMSE: 2.4193714072601757\n",
      "Generation 51/100, Best RMSE: 2.4193714072362122\n",
      "Generation 52/100, Best RMSE: 2.4193714072294936\n",
      "Generation 53/100, Best RMSE: 2.4193714072094434\n",
      "Generation 54/100, Best RMSE: 2.419371407202678\n",
      "Generation 55/100, Best RMSE: 2.41937140719381\n",
      "Generation 56/100, Best RMSE: 2.4193714071794563\n",
      "Generation 57/100, Best RMSE: 2.4193714071734314\n",
      "Generation 58/100, Best RMSE: 2.4193714071661905\n",
      "Generation 59/100, Best RMSE: 2.4193714071661905\n",
      "Generation 60/100, Best RMSE: 2.4193714071616066\n",
      "Generation 61/100, Best RMSE: 2.4193714071616066\n",
      "Generation 62/100, Best RMSE: 2.419371407158535\n",
      "Generation 63/100, Best RMSE: 2.419371407157296\n",
      "Generation 64/100, Best RMSE: 2.4193714071565178\n",
      "Generation 65/100, Best RMSE: 2.4193714071563233\n",
      "Generation 66/100, Best RMSE: 2.4193714071550967\n",
      "Generation 67/100, Best RMSE: 2.419371407152291\n",
      "Generation 68/100, Best RMSE: 2.4193714071507504\n",
      "Generation 69/100, Best RMSE: 2.419371407150612\n",
      "Generation 70/100, Best RMSE: 2.419371407150253\n",
      "Generation 71/100, Best RMSE: 2.419371407150253\n",
      "Generation 72/100, Best RMSE: 2.4193714071501446\n",
      "Generation 73/100, Best RMSE: 2.4193714071496992\n",
      "Generation 74/100, Best RMSE: 2.4193714071493795\n",
      "Generation 75/100, Best RMSE: 2.4193714071493244\n",
      "Generation 76/100, Best RMSE: 2.4193714071490557\n",
      "Generation 77/100, Best RMSE: 2.419371407149024\n",
      "Generation 78/100, Best RMSE: 2.419371407148933\n",
      "Generation 79/100, Best RMSE: 2.4193714071482404\n",
      "Generation 80/100, Best RMSE: 2.4193714071480965\n",
      "Generation 81/100, Best RMSE: 2.419371407147504\n",
      "Generation 82/100, Best RMSE: 2.419371407147301\n",
      "Generation 83/100, Best RMSE: 2.419371407147089\n",
      "Generation 84/100, Best RMSE: 2.419371407146665\n",
      "Generation 85/100, Best RMSE: 2.4193714071462518\n",
      "Generation 86/100, Best RMSE: 2.419371407146168\n",
      "Generation 87/100, Best RMSE: 2.4193714071459644\n",
      "Generation 88/100, Best RMSE: 2.419371407145542\n",
      "Generation 89/100, Best RMSE: 2.419371407145392\n",
      "Generation 90/100, Best RMSE: 2.4193714071450736\n",
      "Generation 91/100, Best RMSE: 2.419371407144981\n",
      "Generation 92/100, Best RMSE: 2.419371407144981\n",
      "Generation 93/100, Best RMSE: 2.4193714071447605\n",
      "Generation 94/100, Best RMSE: 2.41937140714453\n",
      "Generation 95/100, Best RMSE: 2.4193714071443853\n",
      "Generation 96/100, Best RMSE: 2.4193714071443586\n",
      "Generation 97/100, Best RMSE: 2.4193714071441854\n",
      "Generation 98/100, Best RMSE: 2.4193714071439825\n",
      "Generation 99/100, Best RMSE: 2.4193714071439123\n",
      "Generation 100/100, Best RMSE: 2.419371407143743\n",
      "Optimal Weights: [0.56332574 0.11808843 0.08211074 0.         0.23647509]\n"
     ]
    }
   ],
   "source": [
    "# 새로운 블록: GA 실행 및 최적 가중치 찾기\n",
    "input_directory = 'ga_e2'\n",
    "optimal_weights_list=[]\n",
    "for month in range(1, 13):\n",
    "    try:\n",
    "\n",
    "        model_predictions, true_values = load_and_process_validation_data(input_directory, month)\n",
    "        print(model_predictions.shape, true_values.shape)\n",
    "        if len(model_predictions) == 0 or len(true_values) == 0:\n",
    "            print(f\"{month}월: 데이터가 부족하여 건너뜁니다.\")\n",
    "            continue\n",
    "\n",
    "        # GA 실행하여 최적 가중치 찾기\n",
    "        optimal_weights = genetic_algorithm_with_elitism(\n",
    "            model_predictions, true_values, population_size=100, generations=100, mutation_rate=0.03\n",
    "        )\n",
    "        optimal_weights_list.append(optimal_weights)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"{month}월 처리 중 오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.51842763 0.03934001 0.37414119 0.         0.06809118]\n",
      "[0.38389873 0.13705036 0.08239942 0.         0.39665149]\n",
      "[0.         0.02975621 0.31423977 0.39087923 0.26512478]\n",
      "[0. 0. 0. 1. 0.]\n",
      "[0.45259968 0.02216514 0.30682226 0.         0.21841293]\n",
      "[0.02991626 0.         0.50781986 0.         0.46226387]\n",
      "[0.11257954 0.         0.         0.30544933 0.58197113]\n",
      "[0.         0.19879487 0.05556217 0.21745841 0.52818455]\n",
      "[0.3674709  0.         0.10396985 0.         0.52855925]\n",
      "[0.64270542 0.06810121 0.         0.         0.28919337]\n",
      "[0.01527766 0.         0.         0.         0.98472234]\n",
      "[0.56332574 0.11808843 0.08211074 0.         0.23647509]\n"
     ]
    }
   ],
   "source": [
    "for i in optimal_weights_list:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_test_data(input_directory, month, models=4, time_window=48):\n",
    "    \"\"\"\n",
    "    Test 데이터를 로드하고, 모델 예측값과 True 값을 추출해 시간 단위로 이어붙이기기\n",
    "\n",
    "    Args:\n",
    "        input_directory (str): 모델별 test 데이터가 있는 디렉토리\n",
    "        models (int): 모델 개수 (default=5)\n",
    "        time_window (int): 샘플당 시간 창 (default=48)\n",
    "\n",
    "    Returns:\n",
    "        model_predictions (np.ndarray): (n_samples, models, time_window, 2)\n",
    "        true_values (np.ndarray): (n_samples, time_window, 2)\n",
    "    \"\"\"\n",
    "    model_predictions = []  # 모델별 예측값 저장\n",
    "    true_values_list = []  # True U, True V 저장\n",
    "\n",
    "    for model_idx in range(1,6):\n",
    "        model_dir = os.path.join(input_directory, f\"model{model_idx}\")\n",
    "        \n",
    "        model_data_list = []\n",
    "\n",
    "        file_path = os.path.join(model_dir, f'test_month_{month}_model_{model_idx}_results.csv')\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # 모델 예측값 추출\n",
    "        pred_u = df[f\"Model {model_idx} Test Pred U\"].values\n",
    "        pred_v = df[f\"Model {model_idx} Test Pred V\"].values\n",
    "\n",
    "        # 48시간 단위로 자르기\n",
    "        n_samples = len(pred_u) // time_window\n",
    "        pred_u = pred_u[:n_samples * time_window].reshape(n_samples, time_window, 1)\n",
    "        pred_v = pred_v[:n_samples * time_window].reshape(n_samples, time_window, 1)\n",
    "\n",
    "        model_data = np.concatenate([pred_u, pred_v], axis=2)  # (n_samples, 48, 2)\n",
    "        model_data_list.append(model_data)\n",
    "\n",
    "        # True U와 True V 추출 (첫 번째 모델 파일에서만 처리)\n",
    "        if model_idx == 1:\n",
    "            true_u = df[\"True U\"].values[:n_samples * time_window].reshape(n_samples, time_window, 1)\n",
    "            true_v = df[\"True V\"].values[:n_samples * time_window].reshape(n_samples, time_window, 1)\n",
    "            true_values_sample = np.concatenate([true_u, true_v], axis=2)\n",
    "            true_values_list.append(true_values_sample)\n",
    "\n",
    "        # 모델별 데이터 병합\n",
    "        model_predictions.append(np.concatenate(model_data_list, axis=0))  # (total_samples, 48, 2)\n",
    "\n",
    "    # 모델 예측값 형태 변환: (n_samples, models, 48, 2)\n",
    "    model_predictions = np.stack(model_predictions, axis=1)\n",
    "\n",
    "    # True Values 병합: (n_samples, 48, 2)\n",
    "    true_values = np.concatenate(true_values_list, axis=0)\n",
    "\n",
    "    return model_predictions, true_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def calculate_ensemble_rmse(model_predictions, true_values, weights, output_steps):\n",
    "    \"\"\"\n",
    "    최적 가중치를 사용하여 앙상블 예측값을 저장하고 나중에 RMSE를 계산\n",
    "\n",
    "    Args:\n",
    "        model_predictions (np.ndarray): 모델 예측값 (n_samples, models, time_window, 2)\n",
    "        true_values (np.ndarray): 실제 값 (n_samples, time_window, 2)\n",
    "        weights (np.ndarray): 최적 가중치 (models,)\n",
    "        output_steps (int): 예측 타임스텝 수\n",
    "\n",
    "    Returns:\n",
    "        results_dict (dict): 예측값과 실제값 저장 딕셔너리\n",
    "        overall_rmse (float): 전체 평균 RMSE\n",
    "    \"\"\"\n",
    "    # 입력 데이터 형태 검증\n",
    "    if model_predictions.ndim != 4 or true_values.ndim != 3:\n",
    "        raise ValueError(\"입력 데이터의 형태가 올바르지 않습니다. \"\n",
    "                         \"model_predictions는 (n_samples, models, time_window, 2) 형태여야 하고, \"\n",
    "                         \"true_values는 (n_samples, time_window, 2) 형태여야 합니다.\")\n",
    "\n",
    "    n_samples, n_models, time_window, _ = model_predictions.shape\n",
    "\n",
    "    # 디버깅 출력\n",
    "    print(f\"model_predictions.shape: {model_predictions.shape}\")\n",
    "    print(f\"true_values.shape: {true_values.shape}\")\n",
    "    print(f\"weights.shape: {weights.shape}\")\n",
    "    print(f\"weights: {weights}\")\n",
    "    print(f\"time_window: {time_window}, output_steps: {output_steps}\")\n",
    "\n",
    "    # weights 크기 검증\n",
    "    if len(weights) != n_models:\n",
    "        raise ValueError(f\"weights 길이({len(weights)})가 모델 개수({n_models})와 일치하지 않습니다.\")\n",
    "\n",
    "    # weights 합 검증\n",
    "    if not np.isclose(np.sum(weights), 1.0):\n",
    "        raise ValueError(f\"weights의 합({np.sum(weights)})이 1이 아닙니다. 앙상블 결과가 왜곡될 수 있습니다.\")\n",
    "\n",
    "    # 앙상블 예측값 계산 (가중치 적용)\n",
    "    ensemble_predictions = np.tensordot(model_predictions, weights, axes=(1, 0))  # (n_samples, time_window, 2)\n",
    "\n",
    "    # 예측값과 실제값을 저장할 딕셔너리 초기화\n",
    "    results_dict = {i: {'predictions': [], 'true_values': []} for i in range(time_window)}\n",
    "\n",
    "    # 예측값과 실제값 저장\n",
    "    # 예측값과 실제값 저장\n",
    "    for i in range(time_window):  # 전체 time_window만큼 반복\n",
    "        results_dict[i]['predictions'].extend(ensemble_predictions[:, i, :].tolist())\n",
    "        results_dict[i]['true_values'].extend(true_values[:, i, :].tolist())\n",
    "\n",
    "    # 전체 RMSE 계산\n",
    "    all_predictions = np.concatenate(\n",
    "        [np.array(results_dict[i]['predictions']) for i in range(time_window)], axis=0\n",
    "    )\n",
    "    all_true_values = np.concatenate(\n",
    "        [np.array(results_dict[i]['true_values']) for i in range(time_window)], axis=0\n",
    "    )\n",
    "    mse = mean_squared_error(all_true_values, all_predictions, multioutput=\"uniform_average\")\n",
    "    overall_rmse = np.sqrt(mse)\n",
    "\n",
    "\n",
    "    return results_dict, round(overall_rmse, 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Predictions Shape: (28, 48, 2)\n",
      "Ensemble Predictions Shape: (28, 48, 2)\n",
      "Ensemble Predictions Shape: (31, 48, 2)\n",
      "Ensemble Predictions Shape: (30, 48, 2)\n",
      "Ensemble Predictions Shape: (27, 48, 2)\n",
      "Ensemble Predictions Shape: (24, 48, 2)\n",
      "Ensemble Predictions Shape: (16, 48, 2)\n",
      "Ensemble Predictions Shape: (16, 48, 2)\n",
      "Ensemble Predictions Shape: (27, 48, 2)\n",
      "Ensemble Predictions Shape: (31, 48, 2)\n",
      "Ensemble Predictions Shape: (24, 48, 2)\n",
      "Ensemble Predictions Shape: (25, 48, 2)\n",
      "\n",
      "시간별 평균 RMSE:\n",
      "시간 0: 1.9308347952351925\n",
      "시간 1: 2.1503399695049765\n",
      "시간 2: 2.347095677139922\n",
      "시간 3: 2.4523212845911746\n",
      "시간 4: 2.489561923998185\n",
      "시간 5: 2.697231415458439\n",
      "시간 6: 2.837455448676082\n",
      "시간 7: 2.8396478438079833\n",
      "시간 8: 2.8384387769672785\n",
      "시간 9: 2.9070910378414982\n",
      "시간 10: 2.8615164801799557\n",
      "시간 11: 2.795142005307776\n",
      "시간 12: 2.836459119208539\n",
      "시간 13: 2.812351267079061\n",
      "시간 14: 2.833644151841366\n",
      "시간 15: 2.7713266899508295\n",
      "시간 16: 2.8061837330292954\n",
      "시간 17: 2.834737727195998\n",
      "시간 18: 2.9207619274804837\n",
      "시간 19: 2.865423438395594\n",
      "시간 20: 2.821491257904729\n",
      "시간 21: 2.776110563228355\n",
      "시간 22: 2.893676705794238\n",
      "시간 23: 2.90966871335303\n",
      "시간 24: 3.0643628982036173\n",
      "시간 25: 3.1981612905290047\n",
      "시간 26: 3.241839074343685\n",
      "시간 27: 3.229930425635844\n",
      "시간 28: 3.141395750892053\n",
      "시간 29: 3.219042240499517\n",
      "시간 30: 3.2880385014692624\n",
      "시간 31: 3.349406251740548\n",
      "시간 32: 3.3628798901183234\n",
      "시간 33: 3.3458303127724434\n",
      "시간 34: 3.2143933872487462\n",
      "시간 35: 3.0525031510380978\n",
      "시간 36: 3.0523673798547275\n",
      "시간 37: 2.987767876131341\n",
      "시간 38: 2.933566876696476\n",
      "시간 39: 2.8877406171161852\n",
      "시간 40: 2.9131447537054087\n",
      "시간 41: 2.947776501017461\n",
      "시간 42: 3.061482898057337\n",
      "시간 43: 3.0248518354782203\n",
      "시간 44: 3.0312257922511976\n",
      "시간 45: 3.1130231605219216\n",
      "시간 46: 3.3097638577115123\n",
      "시간 47: 3.3826983970973057\n",
      "\n",
      "전체 평균 RMSE:\n",
      "월별 전체 평균 RMSE: 2.962122800224259\n",
      "그룹별 전체 평균 RMSE: 2.928785522360421\n"
     ]
    }
   ],
   "source": [
    "def calculate_uniform_ensemble_rmse(model_predictions, true_values):\n",
    "    n_samples, n_models, time_window, n_features = model_predictions.shape\n",
    "\n",
    "    # 동일 가중치 설정\n",
    "    weights = np.array([1.0 / n_models] * n_models).reshape(1, -1, 1, 1)\n",
    "    ensemble_predictions = np.sum(model_predictions * weights, axis=1)\n",
    "\n",
    "    print(f\"Ensemble Predictions Shape: {ensemble_predictions.shape}\")\n",
    "\n",
    "    results_dict = {i: [] for i in range(time_window)}\n",
    "\n",
    "    for i in range(time_window):\n",
    "        predictions_sample = ensemble_predictions[:, i, :]\n",
    "        true_values_sample = true_values[:, i, :]\n",
    "\n",
    "        mse = mean_squared_error(true_values_sample, predictions_sample, multioutput='uniform_average')\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        results_dict[i].append(rmse)\n",
    "\n",
    "    all_predictions = ensemble_predictions.reshape(-1, n_features)\n",
    "    all_true_values = true_values.reshape(-1, n_features)\n",
    "\n",
    "    overall_mse = mean_squared_error(all_true_values, all_predictions, multioutput='uniform_average')\n",
    "    overall_rmse = np.sqrt(overall_mse)\n",
    "\n",
    "    return results_dict, overall_rmse\n",
    "\n",
    "\n",
    "def calculate_groupwise_rmse(all_results):\n",
    "    time_window = len(all_results[0])\n",
    "    average_rmse = {i: [] for i in range(time_window)}\n",
    "\n",
    "    for month_results in all_results:\n",
    "        for key, rmse_list in month_results.items():\n",
    "            average_rmse[key].extend(rmse_list)\n",
    "\n",
    "    groupwise_rmse = {key: np.mean(rmse_list) for key, rmse_list in average_rmse.items()}\n",
    "    overall_rmse = np.mean(list(groupwise_rmse.values()))\n",
    "\n",
    "    return groupwise_rmse, overall_rmse\n",
    "\n",
    "\n",
    "def main():\n",
    "    input_directory = \"./ga_e2\"\n",
    "    all_results = []\n",
    "    overall_rmse_list = []\n",
    "\n",
    "    for month in range(1, 13):\n",
    "        model_predictions, true_values = load_and_process_test_data(input_directory, month)\n",
    "        results_dict, overall_rmse = calculate_uniform_ensemble_rmse(model_predictions, true_values)\n",
    "\n",
    "        all_results.append(results_dict)\n",
    "        overall_rmse_list.append(overall_rmse)\n",
    "\n",
    "    groupwise_rmse, overall_rmse = calculate_groupwise_rmse(all_results)\n",
    "\n",
    "    print(\"\\n시간별 평균 RMSE:\")\n",
    "    for time, rmse in groupwise_rmse.items():\n",
    "        print(f\"시간 {time}: {rmse}\")\n",
    "\n",
    "    print(\"\\n전체 평균 RMSE:\")\n",
    "    print(f\"월별 전체 평균 RMSE: {np.mean(overall_rmse_list)}\")\n",
    "    print(f\"그룹별 전체 평균 RMSE: {overall_rmse}\")\n",
    "\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Predictions Shape: (28, 48, 2)\n",
      "Ensemble Predictions Shape: (28, 48, 2)\n",
      "Ensemble Predictions Shape: (31, 48, 2)\n",
      "Ensemble Predictions Shape: (30, 48, 2)\n",
      "Ensemble Predictions Shape: (27, 48, 2)\n",
      "Ensemble Predictions Shape: (24, 48, 2)\n",
      "Ensemble Predictions Shape: (16, 48, 2)\n",
      "Ensemble Predictions Shape: (16, 48, 2)\n",
      "Ensemble Predictions Shape: (27, 48, 2)\n",
      "Ensemble Predictions Shape: (31, 48, 2)\n",
      "Ensemble Predictions Shape: (24, 48, 2)\n",
      "Ensemble Predictions Shape: (25, 48, 2)\n",
      "\n",
      "시간별 평균 RMSE:\n",
      "시간 0: 1.908914416627704\n",
      "시간 1: 2.1584899597522575\n",
      "시간 2: 2.3767879925564808\n",
      "시간 3: 2.5005901845987775\n",
      "시간 4: 2.516683930915962\n",
      "시간 5: 2.726301665568105\n",
      "시간 6: 2.861749174238957\n",
      "시간 7: 2.842491294672113\n",
      "시간 8: 2.7931412841194057\n",
      "시간 9: 2.8590432379168136\n",
      "시간 10: 2.829547431126821\n",
      "시간 11: 2.777772945234856\n",
      "시간 12: 2.842217522356167\n",
      "시간 13: 2.820359131996589\n",
      "시간 14: 2.848363485329614\n",
      "시간 15: 2.75257727220497\n",
      "시간 16: 2.8001892821403875\n",
      "시간 17: 2.861815149817567\n",
      "시간 18: 2.9527291871678316\n",
      "시간 19: 2.888670616764003\n",
      "시간 20: 2.8241486141320045\n",
      "시간 21: 2.7727642148449543\n",
      "시간 22: 2.8759938205233078\n",
      "시간 23: 2.88435093428656\n",
      "시간 24: 3.0419692656502644\n",
      "시간 25: 3.1659527738223967\n",
      "시간 26: 3.205888987383331\n",
      "시간 27: 3.2026138893852356\n",
      "시간 28: 3.1218801062729113\n",
      "시간 29: 3.207866780043407\n",
      "시간 30: 3.2797750076115295\n",
      "시간 31: 3.3308330966867037\n",
      "시간 32: 3.304687641936367\n",
      "시간 33: 3.28802722897989\n",
      "시간 34: 3.1872158444310332\n",
      "시간 35: 3.0419344615573203\n",
      "시간 36: 3.0605992937548\n",
      "시간 37: 2.999381677656237\n",
      "시간 38: 2.9552073356644617\n",
      "시간 39: 2.912891328184557\n",
      "시간 40: 2.9151569071143464\n",
      "시간 41: 2.959214659952803\n",
      "시간 42: 3.04544747511665\n",
      "시간 43: 3.0457114566144288\n",
      "시간 44: 3.0581967885646875\n",
      "시간 45: 3.1019729222428434\n",
      "시간 46: 3.288656735389258\n",
      "시간 47: 3.3645858397552293\n",
      "\n",
      "전체 평균 RMSE:\n",
      "월별 전체 평균 RMSE: 2.957734948024624\n",
      "그룹별 전체 평균 RMSE: 2.9241950052638104\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# 기존 optimal_weights_list 사용\n",
    "def calculate_ga_ensemble_rmse(model_predictions, true_values, weights):\n",
    "    n_samples, n_models, time_window, n_features = model_predictions.shape\n",
    "\n",
    "    # GA 기반 가중치를 적용한 앙상블 예측값 계산\n",
    "    weights = np.array(weights).reshape(1, -1, 1, 1)\n",
    "    ensemble_predictions = np.sum(model_predictions * weights, axis=1)\n",
    "\n",
    "    print(f\"Ensemble Predictions Shape: {ensemble_predictions.shape}\")\n",
    "\n",
    "    results_dict = {i: [] for i in range(time_window)}\n",
    "\n",
    "    for i in range(time_window):\n",
    "        predictions_sample = ensemble_predictions[:, i, :]\n",
    "        true_values_sample = true_values[:, i, :]\n",
    "\n",
    "        mse = mean_squared_error(true_values_sample, predictions_sample, multioutput='uniform_average')\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        results_dict[i].append(rmse)\n",
    "\n",
    "    all_predictions = ensemble_predictions.reshape(-1, n_features)\n",
    "    all_true_values = true_values.reshape(-1, n_features)\n",
    "\n",
    "    overall_mse = mean_squared_error(all_true_values, all_predictions, multioutput='uniform_average')\n",
    "    overall_rmse = np.sqrt(overall_mse)\n",
    "\n",
    "    return results_dict, overall_rmse\n",
    "\n",
    "\n",
    "def calculate_groupwise_rmse(all_results):\n",
    "    time_window = len(all_results[0])\n",
    "    average_rmse = {i: [] for i in range(time_window)}\n",
    "\n",
    "    for month_results in all_results:\n",
    "        for key, rmse_list in month_results.items():\n",
    "            average_rmse[key].extend(rmse_list)\n",
    "\n",
    "    groupwise_rmse = {key: np.mean(rmse_list) for key, rmse_list in average_rmse.items()}\n",
    "    overall_rmse = np.mean(list(groupwise_rmse.values()))\n",
    "\n",
    "    return groupwise_rmse, overall_rmse\n",
    "\n",
    "\n",
    "def main():\n",
    "    input_directory = \"./ga_e2\"\n",
    "    all_results = []\n",
    "    overall_rmse_list = []\n",
    "\n",
    "    for month in range(1, 13):\n",
    "        model_predictions, true_values = load_and_process_test_data(input_directory, month)\n",
    "        month_weights = optimal_weights_list[month - 1]\n",
    "\n",
    "        results_dict, overall_rmse = calculate_ga_ensemble_rmse(model_predictions, true_values, month_weights)\n",
    "\n",
    "        all_results.append(results_dict)\n",
    "        overall_rmse_list.append(overall_rmse)\n",
    "\n",
    "    groupwise_rmse, overall_rmse = calculate_groupwise_rmse(all_results)\n",
    "\n",
    "    print(\"\\n시간별 평균 RMSE:\")\n",
    "    for time, rmse in groupwise_rmse.items():\n",
    "        print(f\"시간 {time}: {rmse}\")\n",
    "\n",
    "    print(\"\\n전체 평균 RMSE:\")\n",
    "    print(f\"월별 전체 평균 RMSE: {np.mean(overall_rmse_list)}\")\n",
    "    print(f\"그룹별 전체 평균 RMSE: {overall_rmse}\")\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Model Predictions Shape: (28, 48, 2)\n",
      "Selected Model Predictions Shape: (28, 48, 2)\n",
      "Selected Model Predictions Shape: (31, 48, 2)\n",
      "Selected Model Predictions Shape: (30, 48, 2)\n",
      "Selected Model Predictions Shape: (27, 48, 2)\n",
      "Selected Model Predictions Shape: (24, 48, 2)\n",
      "Selected Model Predictions Shape: (16, 48, 2)\n",
      "Selected Model Predictions Shape: (16, 48, 2)\n",
      "Selected Model Predictions Shape: (27, 48, 2)\n",
      "Selected Model Predictions Shape: (31, 48, 2)\n",
      "Selected Model Predictions Shape: (24, 48, 2)\n",
      "Selected Model Predictions Shape: (25, 48, 2)\n",
      "\n",
      "시간별 평균 RMSE:\n",
      "시간 0: 1.984331658647621\n",
      "시간 1: 2.2221129423938786\n",
      "시간 2: 2.4336507532445735\n",
      "시간 3: 2.5562521253112425\n",
      "시간 4: 2.575441727389952\n",
      "시간 5: 2.8009970386971887\n",
      "시간 6: 2.905611658022128\n",
      "시간 7: 2.9048699122973005\n",
      "시간 8: 2.869018171060301\n",
      "시간 9: 2.9350392016772453\n",
      "시간 10: 2.9461819449577376\n",
      "시간 11: 2.8668743590699375\n",
      "시간 12: 2.882881690991066\n",
      "시간 13: 2.863726172037571\n",
      "시간 14: 2.8613816125251894\n",
      "시간 15: 2.787707456042242\n",
      "시간 16: 2.8071839594062173\n",
      "시간 17: 2.8666571183782916\n",
      "시간 18: 2.94594243077668\n",
      "시간 19: 2.883465982361764\n",
      "시간 20: 2.821123001213071\n",
      "시간 21: 2.77834356906316\n",
      "시간 22: 2.885246012315116\n",
      "시간 23: 2.930673274164791\n",
      "시간 24: 3.093481723491781\n",
      "시간 25: 3.227775649741654\n",
      "시간 26: 3.274974222532532\n",
      "시간 27: 3.218811762818356\n",
      "시간 28: 3.141403223874924\n",
      "시간 29: 3.2354274976327275\n",
      "시간 30: 3.2962735086343895\n",
      "시간 31: 3.327063106561892\n",
      "시간 32: 3.302423879984222\n",
      "시간 33: 3.3027033932552103\n",
      "시간 34: 3.1915614221062456\n",
      "시간 35: 3.055903022226328\n",
      "시간 36: 3.04319352595078\n",
      "시간 37: 2.971066701566657\n",
      "시간 38: 2.9161106257867426\n",
      "시간 39: 2.8816168260247874\n",
      "시간 40: 2.865819482578644\n",
      "시간 41: 2.8924833366607925\n",
      "시간 42: 2.976455779560698\n",
      "시간 43: 2.96210872607036\n",
      "시간 44: 2.9598433740289227\n",
      "시간 45: 2.9952365665543503\n",
      "시간 46: 3.2207790740890787\n",
      "시간 47: 3.316512063161005\n",
      "\n",
      "전체 평균 RMSE:\n",
      "월별 전체 평균 RMSE: 2.9677224219570584\n",
      "그룹별 전체 평균 RMSE: 2.9371612972278616\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def calculate_model_rmse(model_predictions, true_values, model_index):\n",
    "    \"\"\"\n",
    "    특정 모델의 RMSE를 계산\n",
    "    Args:\n",
    "        model_predictions: (n_samples, models, time_window, n_features) 형태의 모델 예측값\n",
    "        true_values: (n_samples, time_window, n_features) 형태의 실제값\n",
    "        model_index: 계산하려는 모델의 인덱스\n",
    "    Returns:\n",
    "        시간별 RMSE 딕셔너리와 전체 RMSE\n",
    "    \"\"\"\n",
    "    n_samples, n_models, time_window, n_features = model_predictions.shape\n",
    "\n",
    "    # 특정 모델의 예측값 선택\n",
    "    selected_model_predictions = model_predictions[:, model_index, :, :]\n",
    "\n",
    "    print(f\"Selected Model Predictions Shape: {selected_model_predictions.shape}\")\n",
    "\n",
    "    results_dict = {i: [] for i in range(time_window)}\n",
    "\n",
    "    for i in range(time_window):\n",
    "        predictions_sample = selected_model_predictions[:, i, :]\n",
    "        true_values_sample = true_values[:, i, :]\n",
    "\n",
    "        mse = mean_squared_error(true_values_sample, predictions_sample, multioutput='uniform_average')\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        results_dict[i].append(rmse)\n",
    "\n",
    "    all_predictions = selected_model_predictions.reshape(-1, n_features)\n",
    "    all_true_values = true_values.reshape(-1, n_features)\n",
    "\n",
    "    overall_mse = mean_squared_error(all_true_values, all_predictions, multioutput='uniform_average')\n",
    "    overall_rmse = np.sqrt(overall_mse)\n",
    "\n",
    "    return results_dict, overall_rmse\n",
    "\n",
    "def calculate_groupwise_rmse(all_results):\n",
    "    time_window = len(all_results[0])\n",
    "    average_rmse = {i: [] for i in range(time_window)}\n",
    "\n",
    "    for month_results in all_results:\n",
    "        for key, rmse_list in month_results.items():\n",
    "            average_rmse[key].extend(rmse_list)\n",
    "\n",
    "    groupwise_rmse = {key: np.mean(rmse_list) for key, rmse_list in average_rmse.items()}\n",
    "    overall_rmse = np.mean(list(groupwise_rmse.values()))\n",
    "\n",
    "    return groupwise_rmse, overall_rmse\n",
    "\n",
    "def main():\n",
    "    input_directory = \"./ga_e2\"\n",
    "    all_results = []\n",
    "    overall_rmse_list = []\n",
    "\n",
    "    # 모델 인덱스\n",
    "    model_index = 4\n",
    "\n",
    "    for month in range(1, 13):\n",
    "        model_predictions, true_values = load_and_process_test_data(input_directory, month)\n",
    "\n",
    "        # 모델 2의 RMSE 계산\n",
    "        results_dict, overall_rmse = calculate_model_rmse(model_predictions, true_values, model_index)\n",
    "\n",
    "        all_results.append(results_dict)\n",
    "        overall_rmse_list.append(overall_rmse)\n",
    "\n",
    "    groupwise_rmse, overall_rmse = calculate_groupwise_rmse(all_results)\n",
    "\n",
    "    print(\"\\n시간별 평균 RMSE:\")\n",
    "    for time, rmse in groupwise_rmse.items():\n",
    "        print(f\"시간 {time}: {rmse}\")\n",
    "\n",
    "    print(\"\\n전체 평균 RMSE:\")\n",
    "    print(f\"월별 전체 평균 RMSE: {np.mean(overall_rmse_list)}\")\n",
    "    print(f\"그룹별 전체 평균 RMSE: {overall_rmse}\")\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GA, Uniform 평균"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1월 가중치: [0.5000817 0.3067802 0.        0.        0.1931381]\n",
      "model_predictions.shape: (31, 5, 48, 2)\n",
      "true_values.shape: (31, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.5000817 0.3067802 0.        0.        0.1931381]\n",
      "time_window: 48, output_steps: 2\n",
      "1월 예측값: (31, 5, 48, 2), 실제값: (31, 48, 2), 가중치: [0.5000817 0.3067802 0.        0.        0.1931381]\n",
      "Ensemble Predictions Shape: (31, 48, 2)\n",
      "\n",
      "1월 전체 앙상블 평균 RMSE: 2.3333\n",
      "\n",
      "1월 전체 Uniform 앙상블 평균 RMSE: 2.3300964159450963\n",
      "2월 가중치: [0.29596147 0.1418722  0.16408054 0.         0.39808579]\n",
      "model_predictions.shape: (28, 5, 48, 2)\n",
      "true_values.shape: (28, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.29596147 0.1418722  0.16408054 0.         0.39808579]\n",
      "time_window: 48, output_steps: 2\n",
      "2월 예측값: (28, 5, 48, 2), 실제값: (28, 48, 2), 가중치: [0.29596147 0.1418722  0.16408054 0.         0.39808579]\n",
      "Ensemble Predictions Shape: (28, 48, 2)\n",
      "\n",
      "2월 전체 앙상블 평균 RMSE: 2.6354\n",
      "\n",
      "2월 전체 Uniform 앙상블 평균 RMSE: 2.664461904475412\n",
      "3월 가중치: [0.35246473 0.         0.         0.25453205 0.39300322]\n",
      "model_predictions.shape: (29, 5, 48, 2)\n",
      "true_values.shape: (29, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.35246473 0.         0.         0.25453205 0.39300322]\n",
      "time_window: 48, output_steps: 2\n",
      "3월 예측값: (29, 5, 48, 2), 실제값: (29, 48, 2), 가중치: [0.35246473 0.         0.         0.25453205 0.39300322]\n",
      "Ensemble Predictions Shape: (29, 48, 2)\n",
      "\n",
      "3월 전체 앙상블 평균 RMSE: 2.5035\n",
      "\n",
      "3월 전체 Uniform 앙상블 평균 RMSE: 2.553024963147584\n",
      "4월 가중치: [0. 0. 0. 1. 0.]\n",
      "model_predictions.shape: (29, 5, 48, 2)\n",
      "true_values.shape: (29, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0. 0. 0. 1. 0.]\n",
      "time_window: 48, output_steps: 2\n",
      "4월 예측값: (29, 5, 48, 2), 실제값: (29, 48, 2), 가중치: [0. 0. 0. 1. 0.]\n",
      "Ensemble Predictions Shape: (29, 48, 2)\n",
      "\n",
      "4월 전체 앙상블 평균 RMSE: 4.2844\n",
      "\n",
      "4월 전체 Uniform 앙상블 평균 RMSE: 4.117869544705043\n",
      "5월 가중치: [0.51310989 0.         0.         0.03079107 0.45609904]\n",
      "model_predictions.shape: (27, 5, 48, 2)\n",
      "true_values.shape: (27, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.51310989 0.         0.         0.03079107 0.45609904]\n",
      "time_window: 48, output_steps: 2\n",
      "5월 예측값: (27, 5, 48, 2), 실제값: (27, 48, 2), 가중치: [0.51310989 0.         0.         0.03079107 0.45609904]\n",
      "Ensemble Predictions Shape: (27, 48, 2)\n",
      "\n",
      "5월 전체 앙상블 평균 RMSE: 5.2274\n",
      "\n",
      "5월 전체 Uniform 앙상블 평균 RMSE: 5.113014326085761\n",
      "6월 가중치: [0.01769239 0.14774915 0.13385553 0.03646775 0.66423518]\n",
      "model_predictions.shape: (14, 5, 48, 2)\n",
      "true_values.shape: (14, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.01769239 0.14774915 0.13385553 0.03646775 0.66423518]\n",
      "time_window: 48, output_steps: 2\n",
      "6월 예측값: (14, 5, 48, 2), 실제값: (14, 48, 2), 가중치: [0.01769239 0.14774915 0.13385553 0.03646775 0.66423518]\n",
      "Ensemble Predictions Shape: (14, 48, 2)\n",
      "\n",
      "6월 전체 앙상블 평균 RMSE: 2.7014\n",
      "\n",
      "6월 전체 Uniform 앙상블 평균 RMSE: 2.8941050410873275\n",
      "7월 가중치: [0.39083857 0.         0.10155258 0.37433248 0.13327637]\n",
      "model_predictions.shape: (17, 5, 48, 2)\n",
      "true_values.shape: (17, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.39083857 0.         0.10155258 0.37433248 0.13327637]\n",
      "time_window: 48, output_steps: 2\n",
      "7월 예측값: (17, 5, 48, 2), 실제값: (17, 48, 2), 가중치: [0.39083857 0.         0.10155258 0.37433248 0.13327637]\n",
      "Ensemble Predictions Shape: (17, 48, 2)\n",
      "\n",
      "7월 전체 앙상블 평균 RMSE: 2.6119\n",
      "\n",
      "7월 전체 Uniform 앙상블 평균 RMSE: 2.661392138759049\n",
      "8월 가중치: [0.07853944 0.16892469 0.00805325 0.31325654 0.43122608]\n",
      "model_predictions.shape: (14, 5, 48, 2)\n",
      "true_values.shape: (14, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.07853944 0.16892469 0.00805325 0.31325654 0.43122608]\n",
      "time_window: 48, output_steps: 2\n",
      "8월 예측값: (14, 5, 48, 2), 실제값: (14, 48, 2), 가중치: [0.07853944 0.16892469 0.00805325 0.31325654 0.43122608]\n",
      "Ensemble Predictions Shape: (14, 48, 2)\n",
      "\n",
      "8월 전체 앙상블 평균 RMSE: 2.4975\n",
      "\n",
      "8월 전체 Uniform 앙상블 평균 RMSE: 2.5799959049603363\n",
      "9월 가중치: [0.43920469 0.0366207  0.1641563  0.         0.36001831]\n",
      "model_predictions.shape: (21, 5, 48, 2)\n",
      "true_values.shape: (21, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.43920469 0.0366207  0.1641563  0.         0.36001831]\n",
      "time_window: 48, output_steps: 2\n",
      "9월 예측값: (21, 5, 48, 2), 실제값: (21, 48, 2), 가중치: [0.43920469 0.0366207  0.1641563  0.         0.36001831]\n",
      "Ensemble Predictions Shape: (21, 48, 2)\n",
      "\n",
      "9월 전체 앙상블 평균 RMSE: 2.4493\n",
      "\n",
      "9월 전체 Uniform 앙상블 평균 RMSE: 2.3279227335370365\n",
      "10월 가중치: [0.62670923 0.         0.02065075 0.         0.35264002]\n",
      "model_predictions.shape: (27, 5, 48, 2)\n",
      "true_values.shape: (27, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.62670923 0.         0.02065075 0.         0.35264002]\n",
      "time_window: 48, output_steps: 2\n",
      "10월 예측값: (27, 5, 48, 2), 실제값: (27, 48, 2), 가중치: [0.62670923 0.         0.02065075 0.         0.35264002]\n",
      "Ensemble Predictions Shape: (27, 48, 2)\n",
      "\n",
      "10월 전체 앙상블 평균 RMSE: 3.2618\n",
      "\n",
      "10월 전체 Uniform 앙상블 평균 RMSE: 3.2344861197750676\n",
      "11월 가중치: [0.4905564  0.06569518 0.         0.         0.44374842]\n",
      "model_predictions.shape: (26, 5, 48, 2)\n",
      "true_values.shape: (26, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.4905564  0.06569518 0.         0.         0.44374842]\n",
      "time_window: 48, output_steps: 2\n",
      "11월 예측값: (26, 5, 48, 2), 실제값: (26, 48, 2), 가중치: [0.4905564  0.06569518 0.         0.         0.44374842]\n",
      "Ensemble Predictions Shape: (26, 48, 2)\n",
      "\n",
      "11월 전체 앙상블 평균 RMSE: 2.6216\n",
      "\n",
      "11월 전체 Uniform 앙상블 평균 RMSE: 2.772242016988633\n",
      "12월 가중치: [0.32626231 0.         0.         0.         0.67373769]\n",
      "model_predictions.shape: (28, 5, 48, 2)\n",
      "true_values.shape: (28, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.32626231 0.         0.         0.         0.67373769]\n",
      "time_window: 48, output_steps: 2\n",
      "12월 예측값: (28, 5, 48, 2), 실제값: (28, 48, 2), 가중치: [0.32626231 0.         0.         0.         0.67373769]\n",
      "Ensemble Predictions Shape: (28, 48, 2)\n",
      "\n",
      "12월 전체 앙상블 평균 RMSE: 2.2347\n",
      "\n",
      "12월 전체 Uniform 앙상블 평균 RMSE: 2.4921078193156276\n",
      "\n",
      "전체 월 평균 앙상블 RMSE:  2.94685\n",
      "\n",
      "전체 월 평균 Uniform 앙상블 RMSE:  2.9783932440651646\n"
     ]
    }
   ],
   "source": [
    "overall_rmse_list = []\n",
    "uniform_overall_rmse_list = []\n",
    "\n",
    "for month in range(1, 13):  # 1월부터 12월까지 반복\n",
    "    try:\n",
    "        # 테스트 데이터 로드 및 처리\n",
    "        model_predictions, true_values = load_and_process_test_data(input_directory, month)\n",
    "\n",
    "        # 월별 optimal_weights 확인\n",
    "        if isinstance(optimal_weights_list, list):\n",
    "            month_weights = optimal_weights_list[month - 1]\n",
    "        else:\n",
    "            raise ValueError(\"optimal_weights_list가 월별 가중치를 포함한 리스트가 아닙니다.\")\n",
    "\n",
    "        print(f\"{month}월 가중치: {month_weights}\")\n",
    "\n",
    "        # 앙상블 RMSE 계산\n",
    "        ensemble_rmse, overall_rmse = calculate_ensemble_rmse(model_predictions, true_values, month_weights, 2)\n",
    "        print(f\"{month}월 예측값: {model_predictions.shape}, 실제값: {true_values.shape}, 가중치: {month_weights}\")\n",
    "\n",
    "        overall_rmse_list.append(overall_rmse)\n",
    "\n",
    "        # Uniform 가중치 계산\n",
    "        uniform_ensemble_rmse_dict, uniform_overall_rmse = calculate_uniform_ensemble_rmse(model_predictions, true_values)\n",
    "        uniform_overall_rmse_list.append(uniform_overall_rmse)\n",
    "\n",
    "        # 결과 출력\n",
    "        print(f\"\\n{month}월 전체 앙상블 평균 RMSE: {overall_rmse}\")\n",
    "        print(f\"\\n{month}월 전체 Uniform 앙상블 평균 RMSE: {uniform_overall_rmse}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"{month}월 처리 중 오류 발생: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# 최종 평균 RMSE 출력\n",
    "if overall_rmse_list:\n",
    "    print(\"\\n전체 월 평균 앙상블 RMSE: \", np.mean(overall_rmse_list))\n",
    "else:\n",
    "    print(\"\\n앙상블 RMSE 결과가 없습니다.\")\n",
    "\n",
    "if uniform_overall_rmse_list:\n",
    "    print(\"\\n전체 월 평균 Uniform 앙상블 RMSE: \", np.mean(uniform_overall_rmse_list))\n",
    "else:\n",
    "    print(\"\\nUniform 앙상블 RMSE 결과가 없습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1월 가중치: [0.5000817 0.3067802 0.        0.        0.1931381]\n",
      "1월 개별 모델 RMSE: [2.7992562017232707, 3.435724146217819, 2.9091694143373332, 3.1523000372899177, 2.2812916653281783]\n",
      "1월 개별 모델 0~24 시간 평균 RMSE: [2.7113599895250564, 3.7549890097987966, 2.528991058192812, 3.03571091226746, 2.1059543190391694]\n",
      "1월 개별 모델 25~47 시간 평균 RMSE: [2.8338674417916825, 2.9842861730224763, 3.2344797520361475, 3.263720778720573, 2.4422898468569874]\n",
      "model_predictions.shape: (31, 5, 48, 2)\n",
      "true_values.shape: (31, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.5000817 0.3067802 0.        0.        0.1931381]\n",
      "time_window: 48, output_steps: 48\n",
      "1월 예측값: (31, 5, 48, 2), 실제값: (31, 48, 2), 가중치: [0.5000817 0.3067802 0.        0.        0.1931381]\n",
      "1월 앙상블 0~24 시간 평균 RMSE: 2.225072495661352\n",
      "1월 앙상블 25~47 시간 평균 RMSE: 2.412914148086691\n",
      "2월 가중치: [0.29596147 0.1418722  0.16408054 0.         0.39808579]\n",
      "2월 개별 모델 RMSE: [3.0268099734978446, 3.099785845142844, 2.849123445790035, 3.1678682796686743, 2.721757194512857]\n",
      "2월 개별 모델 0~24 시간 평균 RMSE: [2.9028742489818398, 2.8277906097205143, 2.628325985196125, 3.021098791798282, 2.4985661891411777]\n",
      "2월 개별 모델 25~47 시간 평균 RMSE: [3.118568547365874, 3.3431991978036923, 3.0225549867268473, 3.3009052478569454, 2.9064260190846007]\n",
      "model_predictions.shape: (28, 5, 48, 2)\n",
      "true_values.shape: (28, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.29596147 0.1418722  0.16408054 0.         0.39808579]\n",
      "time_window: 48, output_steps: 48\n",
      "2월 예측값: (28, 5, 48, 2), 실제값: (28, 48, 2), 가중치: [0.29596147 0.1418722  0.16408054 0.         0.39808579]\n",
      "2월 앙상블 0~24 시간 평균 RMSE: 2.418934759700756\n",
      "2월 앙상블 25~47 시간 평균 RMSE: 2.8173521221003206\n",
      "3월 가중치: [0.35246473 0.         0.         0.25453205 0.39300322]\n",
      "3월 개별 모델 RMSE: [2.67642271488374, 3.5023000004897504, 2.763364444418859, 3.0782404553389857, 2.540349029085225]\n",
      "3월 개별 모델 0~24 시간 평균 RMSE: [2.4158035145123433, 3.401225158860928, 2.412401703024746, 2.9269529892859505, 2.373126525342367]\n",
      "3월 개별 모델 25~47 시간 평균 RMSE: [2.9028204924454677, 3.5862371469698253, 3.050572482313062, 3.217040836762408, 2.6822527494297135]\n",
      "model_predictions.shape: (29, 5, 48, 2)\n",
      "true_values.shape: (29, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.35246473 0.         0.         0.25453205 0.39300322]\n",
      "time_window: 48, output_steps: 48\n",
      "3월 예측값: (29, 5, 48, 2), 실제값: (29, 48, 2), 가중치: [0.35246473 0.         0.         0.25453205 0.39300322]\n",
      "3월 앙상블 0~24 시간 평균 RMSE: 2.2965963043874655\n",
      "3월 앙상블 25~47 시간 평균 RMSE: 2.6846949406945693\n",
      "4월 가중치: [0. 0. 0. 1. 0.]\n",
      "4월 개별 모델 RMSE: [4.250000084865319, 4.984789153268684, 4.2596671982591845, 4.28439052190512, 4.3940264615868685]\n",
      "4월 개별 모델 0~24 시간 평균 RMSE: [3.837797397091262, 4.437174672451323, 3.9269774356581975, 4.165092116368467, 4.153054151911194]\n",
      "4월 개별 모델 25~47 시간 평균 RMSE: [4.594165605060698, 5.492902924600419, 4.500444127106979, 4.387119978899296, 4.595316515980451]\n",
      "model_predictions.shape: (29, 5, 48, 2)\n",
      "true_values.shape: (29, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0. 0. 0. 1. 0.]\n",
      "time_window: 48, output_steps: 48\n",
      "4월 예측값: (29, 5, 48, 2), 실제값: (29, 48, 2), 가중치: [0. 0. 0. 1. 0.]\n",
      "4월 앙상블 0~24 시간 평균 RMSE: 4.165092116368467\n",
      "4월 앙상블 25~47 시간 평균 RMSE: 4.387119978899296\n",
      "5월 가중치: [0.51310989 0.         0.         0.03079107 0.45609904]\n",
      "5월 개별 모델 RMSE: [5.413165666826279, 5.8124029557369274, 5.657787431244488, 4.605612400701194, 5.354962348503337]\n",
      "5월 개별 모델 0~24 시간 평균 RMSE: [5.015933872271337, 5.836072575097241, 5.181724393175715, 4.511973497751534, 5.031639664125183]\n",
      "5월 개별 모델 25~47 시간 평균 RMSE: [5.76263467620908, 5.770471261534222, 6.077988577565351, 4.692982163170572, 5.655712146335214]\n",
      "model_predictions.shape: (27, 5, 48, 2)\n",
      "true_values.shape: (27, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.51310989 0.         0.         0.03079107 0.45609904]\n",
      "time_window: 48, output_steps: 48\n",
      "5월 예측값: (27, 5, 48, 2), 실제값: (27, 48, 2), 가중치: [0.51310989 0.         0.         0.03079107 0.45609904]\n",
      "5월 앙상블 0~24 시간 평균 RMSE: 4.89221841022308\n",
      "5월 앙상블 25~47 시간 평균 RMSE: 5.533779997011514\n",
      "6월 가중치: [0.01769239 0.14774915 0.13385553 0.03646775 0.66423518]\n",
      "6월 개별 모델 RMSE: [3.2081062521515094, 2.869904777461093, 3.162297001434166, 4.270121263393588, 2.7454660217007993]\n",
      "6월 개별 모델 0~24 시간 평균 RMSE: [2.7906078555329317, 3.041320604791241, 2.5634503364857433, 4.034106049607893, 2.294300130145386]\n",
      "6월 개별 모델 25~47 시간 평균 RMSE: [3.502627926041254, 2.634079282079703, 3.5883960139862263, 4.405837268596728, 3.0285608463886065]\n",
      "model_predictions.shape: (14, 5, 48, 2)\n",
      "true_values.shape: (14, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.01769239 0.14774915 0.13385553 0.03646775 0.66423518]\n",
      "time_window: 48, output_steps: 48\n",
      "6월 예측값: (14, 5, 48, 2), 실제값: (14, 48, 2), 가중치: [0.01769239 0.14774915 0.13385553 0.03646775 0.66423518]\n",
      "6월 앙상블 0~24 시간 평균 RMSE: 2.3078684009407544\n",
      "6월 앙상블 25~47 시간 평균 RMSE: 2.961765263769052\n",
      "7월 가중치: [0.39083857 0.         0.10155258 0.37433248 0.13327637]\n",
      "7월 개별 모델 RMSE: [2.7987040982126623, 3.3618542389373647, 2.9263531603567157, 2.7616815653738267, 2.6010533188373284]\n",
      "7월 개별 모델 0~24 시간 평균 RMSE: [2.584823754064329, 3.4237496744711238, 2.824166894275016, 2.524085520615319, 2.3653886885986855]\n",
      "7월 개별 모델 25~47 시간 평균 RMSE: [2.9431413534750464, 3.1892538723317094, 2.9811648529859394, 2.9577242411389366, 2.7708132540127597]\n",
      "model_predictions.shape: (17, 5, 48, 2)\n",
      "true_values.shape: (17, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.39083857 0.         0.10155258 0.37433248 0.13327637]\n",
      "time_window: 48, output_steps: 48\n",
      "7월 예측값: (17, 5, 48, 2), 실제값: (17, 48, 2), 가중치: [0.39083857 0.         0.10155258 0.37433248 0.13327637]\n",
      "7월 앙상블 0~24 시간 평균 RMSE: 2.3764999872149253\n",
      "7월 앙상블 25~47 시간 평균 RMSE: 2.7892115978844254\n",
      "8월 가중치: [0.07853944 0.16892469 0.00805325 0.31325654 0.43122608]\n",
      "8월 개별 모델 RMSE: [2.999364425489275, 3.6204624936251553, 2.679115614574365, 2.570370747753765, 2.3872125114028773]\n",
      "8월 개별 모델 0~24 시간 평균 RMSE: [2.5501515896531517, 3.4883831516199426, 2.480750946312221, 2.504380320038937, 2.1870665827727813]\n",
      "8월 개별 모델 25~47 시간 평균 RMSE: [3.378973066006609, 3.726056617482022, 2.858004137657886, 2.6116036386963803, 2.554050659259218]\n",
      "model_predictions.shape: (14, 5, 48, 2)\n",
      "true_values.shape: (14, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.07853944 0.16892469 0.00805325 0.31325654 0.43122608]\n",
      "time_window: 48, output_steps: 48\n",
      "8월 예측값: (14, 5, 48, 2), 실제값: (14, 48, 2), 가중치: [0.07853944 0.16892469 0.00805325 0.31325654 0.43122608]\n",
      "8월 앙상블 0~24 시간 평균 RMSE: 2.294668294052284\n",
      "8월 앙상블 25~47 시간 평균 RMSE: 2.673045074143381\n",
      "9월 가중치: [0.43920469 0.0366207  0.1641563  0.         0.36001831]\n",
      "9월 개별 모델 RMSE: [2.745202248171645, 3.0293367773907502, 2.740490928984092, 2.606448344974634, 2.463495288769133]\n",
      "9월 개별 모델 0~24 시간 평균 RMSE: [2.5855500262028785, 2.9976661091033407, 2.914318233375241, 2.6096872393226285, 2.6276119632479165]\n",
      "9월 개별 모델 25~47 시간 평균 RMSE: [2.7446949215424143, 3.029887887622836, 2.3727754196329154, 2.5168792415263823, 2.091365678403367]\n",
      "model_predictions.shape: (21, 5, 48, 2)\n",
      "true_values.shape: (21, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.43920469 0.0366207  0.1641563  0.         0.36001831]\n",
      "time_window: 48, output_steps: 48\n",
      "9월 예측값: (21, 5, 48, 2), 실제값: (21, 48, 2), 가중치: [0.43920469 0.0366207  0.1641563  0.         0.36001831]\n",
      "9월 앙상블 0~24 시간 평균 RMSE: 2.4969982941250297\n",
      "9월 앙상블 25~47 시간 평균 RMSE: 2.2101057530111556\n",
      "10월 가중치: [0.62670923 0.         0.02065075 0.         0.35264002]\n",
      "10월 개별 모델 RMSE: [3.474911540348785, 3.547467496076598, 3.4601939793734138, 4.176348732130302, 3.1640627115988456]\n",
      "10월 개별 모델 0~24 시간 평균 RMSE: [3.3707558525997157, 3.2876684437155133, 3.419058436802804, 4.125972151450225, 3.0571763021484526]\n",
      "10월 개별 모델 25~47 시간 평균 RMSE: [3.5653243261964844, 3.7697996363751813, 3.4838294540802432, 4.218212996256098, 3.254944298713493]\n",
      "model_predictions.shape: (27, 5, 48, 2)\n",
      "true_values.shape: (27, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.62670923 0.         0.02065075 0.         0.35264002]\n",
      "time_window: 48, output_steps: 48\n",
      "10월 예측값: (27, 5, 48, 2), 실제값: (27, 48, 2), 가중치: [0.62670923 0.         0.02065075 0.         0.35264002]\n",
      "10월 앙상블 0~24 시간 평균 RMSE: 3.1690629330995885\n",
      "10월 앙상블 25~47 시간 평균 RMSE: 3.3414405211091567\n",
      "11월 가중치: [0.4905564  0.06569518 0.         0.         0.44374842]\n",
      "11월 개별 모델 RMSE: [2.9195060974274845, 3.817278909241105, 2.8289493985699523, 3.7597670003996626, 2.7192305677448467]\n",
      "11월 개별 모델 0~24 시간 평균 RMSE: [2.8332498789905483, 3.3249471749044854, 2.594768295020055, 3.6839428156512635, 2.562193946289792]\n",
      "11월 개별 모델 25~47 시간 평균 RMSE: [2.9407033926872352, 4.250762875437241, 3.025829121155346, 3.8270843381460393, 2.8427404973724433]\n",
      "model_predictions.shape: (26, 5, 48, 2)\n",
      "true_values.shape: (26, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.4905564  0.06569518 0.         0.         0.44374842]\n",
      "time_window: 48, output_steps: 48\n",
      "11월 예측값: (26, 5, 48, 2), 실제값: (26, 48, 2), 가중치: [0.4905564  0.06569518 0.         0.         0.44374842]\n",
      "11월 앙상블 0~24 시간 평균 RMSE: 2.481395596135608\n",
      "11월 앙상블 25~47 시간 평균 RMSE: 2.7105507249346017\n",
      "12월 가중치: [0.32626231 0.         0.         0.         0.67373769]\n",
      "12월 개별 모델 RMSE: [2.612939800120858, 3.9893200089890843, 2.669654849320429, 4.350810078521139, 2.3210774997297428]\n",
      "12월 개별 모델 0~24 시간 평균 RMSE: [2.434126469633122, 4.254766670475678, 2.5515690943759255, 4.249905316488539, 2.2605738186790685]\n",
      "12월 개별 모델 25~47 시간 평균 RMSE: [2.763103355469809, 3.5809403598665206, 2.754721930294465, 4.434428759449746, 2.341969199121218]\n",
      "model_predictions.shape: (28, 5, 48, 2)\n",
      "true_values.shape: (28, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.32626231 0.         0.         0.         0.67373769]\n",
      "time_window: 48, output_steps: 48\n",
      "12월 예측값: (28, 5, 48, 2), 실제값: (28, 48, 2), 가중치: [0.32626231 0.         0.         0.         0.67373769]\n",
      "12월 앙상블 0~24 시간 평균 RMSE: 2.1606013478259127\n",
      "12월 앙상블 25~47 시간 평균 RMSE: 2.2880979733058435\n",
      "\n",
      "전체 월 평균 앙상블 RMSE:  2.94685\n",
      "\n",
      "구간별 평균 RMSE 비교 결과:\n",
      "1월:\n",
      "  모델 0~24 시간 평균 RMSE: [2.7113599895250564, 3.7549890097987966, 2.528991058192812, 3.03571091226746, 2.1059543190391694]\n",
      "  모델 25~47 시간 평균 RMSE: [2.8338674417916825, 2.9842861730224763, 3.2344797520361475, 3.263720778720573, 2.4422898468569874]\n",
      "  앙상블 0~24 시간 평균 RMSE: 2.2251\n",
      "  앙상블 25~47 시간 평균 RMSE: 2.4129\n",
      "2월:\n",
      "  모델 0~24 시간 평균 RMSE: [2.9028742489818398, 2.8277906097205143, 2.628325985196125, 3.021098791798282, 2.4985661891411777]\n",
      "  모델 25~47 시간 평균 RMSE: [3.118568547365874, 3.3431991978036923, 3.0225549867268473, 3.3009052478569454, 2.9064260190846007]\n",
      "  앙상블 0~24 시간 평균 RMSE: 2.4189\n",
      "  앙상블 25~47 시간 평균 RMSE: 2.8174\n",
      "3월:\n",
      "  모델 0~24 시간 평균 RMSE: [2.4158035145123433, 3.401225158860928, 2.412401703024746, 2.9269529892859505, 2.373126525342367]\n",
      "  모델 25~47 시간 평균 RMSE: [2.9028204924454677, 3.5862371469698253, 3.050572482313062, 3.217040836762408, 2.6822527494297135]\n",
      "  앙상블 0~24 시간 평균 RMSE: 2.2966\n",
      "  앙상블 25~47 시간 평균 RMSE: 2.6847\n",
      "4월:\n",
      "  모델 0~24 시간 평균 RMSE: [3.837797397091262, 4.437174672451323, 3.9269774356581975, 4.165092116368467, 4.153054151911194]\n",
      "  모델 25~47 시간 평균 RMSE: [4.594165605060698, 5.492902924600419, 4.500444127106979, 4.387119978899296, 4.595316515980451]\n",
      "  앙상블 0~24 시간 평균 RMSE: 4.1651\n",
      "  앙상블 25~47 시간 평균 RMSE: 4.3871\n",
      "5월:\n",
      "  모델 0~24 시간 평균 RMSE: [5.015933872271337, 5.836072575097241, 5.181724393175715, 4.511973497751534, 5.031639664125183]\n",
      "  모델 25~47 시간 평균 RMSE: [5.76263467620908, 5.770471261534222, 6.077988577565351, 4.692982163170572, 5.655712146335214]\n",
      "  앙상블 0~24 시간 평균 RMSE: 4.8922\n",
      "  앙상블 25~47 시간 평균 RMSE: 5.5338\n",
      "6월:\n",
      "  모델 0~24 시간 평균 RMSE: [2.7906078555329317, 3.041320604791241, 2.5634503364857433, 4.034106049607893, 2.294300130145386]\n",
      "  모델 25~47 시간 평균 RMSE: [3.502627926041254, 2.634079282079703, 3.5883960139862263, 4.405837268596728, 3.0285608463886065]\n",
      "  앙상블 0~24 시간 평균 RMSE: 2.3079\n",
      "  앙상블 25~47 시간 평균 RMSE: 2.9618\n",
      "7월:\n",
      "  모델 0~24 시간 평균 RMSE: [2.584823754064329, 3.4237496744711238, 2.824166894275016, 2.524085520615319, 2.3653886885986855]\n",
      "  모델 25~47 시간 평균 RMSE: [2.9431413534750464, 3.1892538723317094, 2.9811648529859394, 2.9577242411389366, 2.7708132540127597]\n",
      "  앙상블 0~24 시간 평균 RMSE: 2.3765\n",
      "  앙상블 25~47 시간 평균 RMSE: 2.7892\n",
      "8월:\n",
      "  모델 0~24 시간 평균 RMSE: [2.5501515896531517, 3.4883831516199426, 2.480750946312221, 2.504380320038937, 2.1870665827727813]\n",
      "  모델 25~47 시간 평균 RMSE: [3.378973066006609, 3.726056617482022, 2.858004137657886, 2.6116036386963803, 2.554050659259218]\n",
      "  앙상블 0~24 시간 평균 RMSE: 2.2947\n",
      "  앙상블 25~47 시간 평균 RMSE: 2.6730\n",
      "9월:\n",
      "  모델 0~24 시간 평균 RMSE: [2.5855500262028785, 2.9976661091033407, 2.914318233375241, 2.6096872393226285, 2.6276119632479165]\n",
      "  모델 25~47 시간 평균 RMSE: [2.7446949215424143, 3.029887887622836, 2.3727754196329154, 2.5168792415263823, 2.091365678403367]\n",
      "  앙상블 0~24 시간 평균 RMSE: 2.4970\n",
      "  앙상블 25~47 시간 평균 RMSE: 2.2101\n",
      "10월:\n",
      "  모델 0~24 시간 평균 RMSE: [3.3707558525997157, 3.2876684437155133, 3.419058436802804, 4.125972151450225, 3.0571763021484526]\n",
      "  모델 25~47 시간 평균 RMSE: [3.5653243261964844, 3.7697996363751813, 3.4838294540802432, 4.218212996256098, 3.254944298713493]\n",
      "  앙상블 0~24 시간 평균 RMSE: 3.1691\n",
      "  앙상블 25~47 시간 평균 RMSE: 3.3414\n",
      "11월:\n",
      "  모델 0~24 시간 평균 RMSE: [2.8332498789905483, 3.3249471749044854, 2.594768295020055, 3.6839428156512635, 2.562193946289792]\n",
      "  모델 25~47 시간 평균 RMSE: [2.9407033926872352, 4.250762875437241, 3.025829121155346, 3.8270843381460393, 2.8427404973724433]\n",
      "  앙상블 0~24 시간 평균 RMSE: 2.4814\n",
      "  앙상블 25~47 시간 평균 RMSE: 2.7106\n",
      "12월:\n",
      "  모델 0~24 시간 평균 RMSE: [2.434126469633122, 4.254766670475678, 2.5515690943759255, 4.249905316488539, 2.2605738186790685]\n",
      "  모델 25~47 시간 평균 RMSE: [2.763103355469809, 3.5809403598665206, 2.754721930294465, 4.434428759449746, 2.341969199121218]\n",
      "  앙상블 0~24 시간 평균 RMSE: 2.1606\n",
      "  앙상블 25~47 시간 평균 RMSE: 2.2881\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "overall_rmse_list = []\n",
    "uniform_overall_rmse_list = []\n",
    "individual_model_rmse = []  # 월별 개별 모델 RMSE 저장 리스트\n",
    "timewise_model_rmse = []  # 시간별 개별 모델 RMSE 저장 리스트\n",
    "comparison_results = []  # 구간별 평균 RMSE 비교 결과 저장 리스트\n",
    "\n",
    "for month in range(1, 13):  # 1월부터 12월까지 반복\n",
    "    try:\n",
    "        # 테스트 데이터 로드 및 처리\n",
    "        model_predictions, true_values = load_and_process_test_data(input_directory, month)\n",
    "\n",
    "        # 월별 optimal_weights 확인\n",
    "        if isinstance(optimal_weights_list, list):\n",
    "            month_weights = optimal_weights_list[month - 1]\n",
    "        else:\n",
    "            raise ValueError(\"optimal_weights_list가 월별 가중치를 포함한 리스트가 아닙니다.\")\n",
    "\n",
    "        print(f\"{month}월 가중치: {month_weights}\")\n",
    "\n",
    "        # 월별 개별 모델 RMSE 계산\n",
    "        n_models = model_predictions.shape[1]\n",
    "        time_window = model_predictions.shape[2]\n",
    "        monthly_model_rmse = []  # 해당 월의 각 모델 RMSE 저장\n",
    "        monthly_timewise_rmse = {t: [] for t in range(time_window)}  # 시간별 RMSE 저장\n",
    "\n",
    "        for model_idx in range(n_models):\n",
    "            model_prediction = model_predictions[:, model_idx, :, :]  # 해당 모델의 예측값 (n_samples, time_window, 2)\n",
    "            \n",
    "            # 월별 RMSE\n",
    "            mse = mean_squared_error(true_values.reshape(-1, 2), model_prediction.reshape(-1, 2), multioutput=\"uniform_average\")\n",
    "            rmse = np.sqrt(mse)\n",
    "            monthly_model_rmse.append(rmse)\n",
    "\n",
    "            # 시간별 RMSE\n",
    "            for t in range(time_window):\n",
    "                time_mse = mean_squared_error(true_values[:, t, :], model_prediction[:, t, :], multioutput=\"uniform_average\")\n",
    "                time_rmse = np.sqrt(time_mse)\n",
    "                monthly_timewise_rmse[t].append(time_rmse)\n",
    "\n",
    "        individual_model_rmse.append(monthly_model_rmse)\n",
    "        timewise_model_rmse.append(monthly_timewise_rmse)\n",
    "\n",
    "        print(f\"{month}월 개별 모델 RMSE: {monthly_model_rmse}\")\n",
    "\n",
    "        # 0~24, 25~47 시간 구간별 개별 모델 평균 RMSE 계산\n",
    "        avg_rmse_0_24 = [np.mean([monthly_timewise_rmse[t][model_idx] for t in range(0, 25)]) for model_idx in range(n_models)]\n",
    "        avg_rmse_25_47 = [np.mean([monthly_timewise_rmse[t][model_idx] for t in range(25, 48)]) for model_idx in range(n_models)]\n",
    "\n",
    "        print(f\"{month}월 개별 모델 0~24 시간 평균 RMSE: {avg_rmse_0_24}\")\n",
    "        print(f\"{month}월 개별 모델 25~47 시간 평균 RMSE: {avg_rmse_25_47}\")\n",
    "\n",
    "        # 앙상블 RMSE 계산\n",
    "        ensemble_rmse, overall_rmse = calculate_ensemble_rmse(model_predictions, true_values, month_weights, 48)\n",
    "        print(f\"{month}월 예측값: {model_predictions.shape}, 실제값: {true_values.shape}, 가중치: {month_weights}\")\n",
    "\n",
    "        # 0~24, 25~47 시간 구간별 앙상블 평균 RMSE 계산\n",
    "        ensemble_predictions = np.tensordot(model_predictions, month_weights, axes=(1, 0))  # (n_samples, time_window, 2)\n",
    "        avg_ensemble_rmse_0_24 = np.mean([\n",
    "            np.sqrt(mean_squared_error(true_values[:, t, :], ensemble_predictions[:, t, :], multioutput=\"uniform_average\"))\n",
    "            for t in range(0, 25)\n",
    "        ])\n",
    "        avg_ensemble_rmse_25_47 = np.mean([\n",
    "            np.sqrt(mean_squared_error(true_values[:, t, :], ensemble_predictions[:, t, :], multioutput=\"uniform_average\"))\n",
    "            for t in range(25, 48)\n",
    "        ])\n",
    "\n",
    "        print(f\"{month}월 앙상블 0~24 시간 평균 RMSE: {avg_ensemble_rmse_0_24}\")\n",
    "        print(f\"{month}월 앙상블 25~47 시간 평균 RMSE: {avg_ensemble_rmse_25_47}\")\n",
    "\n",
    "        # 결과 비교 저장\n",
    "        comparison_results.append({\n",
    "            \"month\": month,\n",
    "            \"model_avg_rmse_0_24\": avg_rmse_0_24,\n",
    "            \"model_avg_rmse_25_47\": avg_rmse_25_47,\n",
    "            \"ensemble_avg_rmse_0_24\": avg_ensemble_rmse_0_24,\n",
    "            \"ensemble_avg_rmse_25_47\": avg_ensemble_rmse_25_47\n",
    "        })\n",
    "\n",
    "        overall_rmse_list.append(overall_rmse)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"{month}월 처리 중 오류 발생: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# 최종 평균 RMSE 출력\n",
    "if overall_rmse_list:\n",
    "    print(\"\\n전체 월 평균 앙상블 RMSE: \", np.mean(overall_rmse_list))\n",
    "else:\n",
    "    print(\"\\n앙상블 RMSE 결과가 없습니다.\")\n",
    "\n",
    "# 구간별 결과 출력\n",
    "print(\"\\n구간별 평균 RMSE 비교 결과:\")\n",
    "for result in comparison_results:\n",
    "    print(f\"{result['month']}월:\")\n",
    "    print(f\"  모델 0~24 시간 평균 RMSE: {result['model_avg_rmse_0_24']}\")\n",
    "    print(f\"  모델 25~47 시간 평균 RMSE: {result['model_avg_rmse_25_47']}\")\n",
    "    print(f\"  앙상블 0~24 시간 평균 RMSE: {result['ensemble_avg_rmse_0_24']:.4f}\")\n",
    "    print(f\"  앙상블 25~47 시간 평균 RMSE: {result['ensemble_avg_rmse_25_47']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GA 검증 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmse(model_predictions, true_values, individual):\n",
    "    \"\"\" 주어진 개체에 대해 앙상블 예측값을 계산하고 RMSE를 반환 \"\"\"\n",
    "    ensemble_prediction = np.sum([weight * model_predictions[:, i, :, :] for i, weight in enumerate(individual)], axis=0)\n",
    "    rmse = np.sqrt(np.mean((true_values - ensemble_prediction) ** 2))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genetic_algorithm_with_elitism(model_predictions, true_values, population_size=100, generations=100, mutation_rate=0.03, seed=None):\n",
    "    \"\"\"\n",
    "    GA를 사용하여 최적의 가중치 찾기\n",
    "    Args:\n",
    "        model_predictions: (n_samples, models, time_window, 2) 형태의 모델 예측값\n",
    "        true_values: (n_samples, time_window, 2) 형태의 실제값\n",
    "        population_size: 초기 개체군 크기\n",
    "        generations: 세대 수\n",
    "        mutation_rate: 돌연변이 확률\n",
    "        seed: 난수 시드를 고정하기 위한 값\n",
    "    Returns:\n",
    "        최적 가중치 배열\n",
    "    \"\"\"\n",
    "    num_models = model_predictions.shape[1]  # 모델 수\n",
    "    time_window = model_predictions.shape[2]  # 시간 단위\n",
    "    \n",
    "    # 초기 population 생성\n",
    "    population = np.random.dirichlet(np.ones(num_models), size=population_size)  # 초기 가중치 개체군\n",
    "\n",
    "    for generation in range(generations):\n",
    "        fitness_scores = []\n",
    "\n",
    "        # 현재 population의 fitness (RMSE) 계산\n",
    "        for individual in population:\n",
    "            ensemble_prediction = np.sum(\n",
    "                [weight * model_predictions[:, i, :, :] for i, weight in enumerate(individual)],\n",
    "                axis=0\n",
    "            )\n",
    "            rmse = np.sqrt(np.mean((true_values - ensemble_prediction) ** 2))\n",
    "            fitness_scores.append(rmse)\n",
    "        \n",
    "        fitness_scores = np.array(fitness_scores)\n",
    "\n",
    "        # 새로운 population 생성\n",
    "        new_population = []\n",
    "        while len(new_population) < population_size:\n",
    "            # 부모 선택\n",
    "            np.random.seed(seed + generation)  # 세대마다 다른 시드 적용\n",
    "            parent1 = roulette_wheel_selection(population, fitness_scores)\n",
    "            parent2 = roulette_wheel_selection(population, fitness_scores)\n",
    "\n",
    "            # 교차 연산\n",
    "            np.random.seed(seed + generation + 1)  # 세대마다 다른 시드 적용\n",
    "            crossover_point = np.random.randint(1, num_models)\n",
    "            child = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))\n",
    "\n",
    "            # 돌연변이\n",
    "            if np.random.rand() < mutation_rate:\n",
    "                np.random.seed(seed + generation + 2)  # 세대마다 다른 시드 적용\n",
    "                mutation_vector = np.random.normal(0, 0.1, size=num_models)\n",
    "                child = np.clip(child + mutation_vector, 0, 1)\n",
    "\n",
    "            # 정규화\n",
    "            child = child / np.sum(child)\n",
    "            new_population.append(child)\n",
    "        \n",
    "        new_population = np.array(new_population)\n",
    "\n",
    "        # 엘리티즘 적용: 상위 50% 개체 선택\n",
    "        combined_population = np.vstack((population, new_population))\n",
    "        combined_fitness = np.concatenate((fitness_scores, np.zeros(len(new_population))))\n",
    "\n",
    "        for idx, individual in enumerate(new_population):\n",
    "            ensemble_prediction = np.sum(\n",
    "                [weight * model_predictions[:, i, :, :] for i, weight in enumerate(individual)],\n",
    "                axis=0\n",
    "            )\n",
    "            combined_fitness[len(fitness_scores) + idx] = np.sqrt(np.mean((true_values - ensemble_prediction) ** 2))\n",
    "\n",
    "        sorted_indices = np.argsort(combined_fitness)\n",
    "        population = combined_population[sorted_indices][:population_size]\n",
    "\n",
    "        print(f\"Generation {generation + 1}/{generations}, Best RMSE: {combined_fitness[sorted_indices][0]}\")\n",
    "\n",
    "    # 최적 개체 반환\n",
    "    best_weights = population[0]\n",
    "    print(f\"Optimal Weights: {best_weights}\")\n",
    "    return best_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def run_ga_experiment(model_predictions, true_values, population_size=100, generations=100, mutation_rate=0.03, seed=None):\n",
    "    \"\"\"\n",
    "    유전 알고리즘 실험을 한 번 실행하고, GA 계산 시간을 측정하여 최적 가중치를 반환합니다.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)  # seed 설정\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    optimal_weights = genetic_algorithm_with_elitism(model_predictions, true_values, \n",
    "                                                     population_size=population_size, \n",
    "                                                     generations=generations, mutation_rate=mutation_rate, seed=seed)\n",
    "\n",
    "    ga_time = time.time() - start_time\n",
    "    \n",
    "    # 앙상블 예측\n",
    "    ensemble_prediction = np.sum([weight * model_predictions[:, i, :, :] for i, weight in enumerate(optimal_weights)], axis=0)\n",
    "    \n",
    "    # 3D 배열을 2D 배열로 변환 (n_samples, time_window * 2)\n",
    "    ensemble_prediction_2d = ensemble_prediction.reshape(-1, ensemble_prediction.shape[1] * ensemble_prediction.shape[2])\n",
    "    true_values_2d = true_values.reshape(-1, true_values.shape[1] * true_values.shape[2])\n",
    "\n",
    "    # RMSE 계산\n",
    "    rmse = np.sqrt(mean_squared_error(true_values_2d, ensemble_prediction_2d))\n",
    "\n",
    "    return optimal_weights, ga_time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def calculate_ensemble_rmse2(model_predictions, true_values, weights):\n",
    "    \"\"\"\n",
    "    최적 가중치를 사용하여 앙상블 RMSE를 계산\n",
    "\n",
    "    Args:\n",
    "        model_predictions (np.ndarray): 모델 예측값 (n_samples, models, time_window, 2)\n",
    "        true_values (np.ndarray): 실제 값 (n_samples, time_window, 2)\n",
    "        weights (np.ndarray): 최적 가중치 (models,)\n",
    "\n",
    "    Returns:\n",
    "        ensemble_rmse_dict (dict): 시간별 RMSE 딕셔너리\n",
    "        overall_rmse (float): 전체 평균 RMSE\n",
    "    \"\"\"\n",
    "    n_samples, n_models, time_window, _ = model_predictions.shape\n",
    "    \n",
    "    # 앙상블 예측값 계산 (가중치 적용)\n",
    "    ensemble_predictions = np.tensordot(model_predictions, weights, axes=(1, 0))  # (n_samples, time_window, 2)\n",
    "\n",
    "    # 시간별 RMSE를 저장할 딕셔너리\n",
    "    ensemble_rmse_dict = {}\n",
    "    \n",
    "    for time_step in range(time_window):\n",
    "        # 시간별 예측값과 실제값 추출\n",
    "        preds = ensemble_predictions[:, time_step, :]\n",
    "        trues = true_values[:, time_step, :]\n",
    "        \n",
    "        # RMSE 계산\n",
    "        mse = mean_squared_error(trues, preds, multioutput='uniform_average')\n",
    "        rmse = np.sqrt(mse)\n",
    "        ensemble_rmse_dict[time_step] = round(rmse, 4)\n",
    "\n",
    "    # 전체 평균 RMSE 계산\n",
    "    overall_rmse = np.mean(list(ensemble_rmse_dict.values()))\n",
    "\n",
    "    return round(overall_rmse, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def save_to_csv_for_seed(seed, monthly_rmse_list, monthly_ga_time_list, output_dir=\"./ga_검증\"):\n",
    "    \"\"\"각 seed별로 CSV 파일로 저장하는 함수\"\"\"\n",
    "    \n",
    "    valid_months = [i for i in range(1, 12)]\n",
    "    \n",
    "    # 월별 RMSE와 GA 계산 시간을 DataFrame으로 변환\n",
    "    monthly_df_rmse = pd.DataFrame({\n",
    "        'Seed': [seed],\n",
    "        **{f'Month {month} RMSE': [monthly_rmse_list[idx]] for idx, month in enumerate(valid_months)}\n",
    "    })\n",
    "    \n",
    "    monthly_df_ga_time = pd.DataFrame({\n",
    "        'Seed': [seed],\n",
    "        **{f'Month {month} GA Time': [monthly_ga_time_list[idx]] for idx, month in enumerate(valid_months)}\n",
    "    })\n",
    "    \n",
    "    # 저장할 디렉토리 생성 (없는 경우 생성)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # 각 seed에 대해 결과 저장\n",
    "    monthly_df_rmse.to_csv(f'{output_dir}/seed_{seed}_monthly_rmse.csv', index=False)\n",
    "    monthly_df_ga_time.to_csv(f'{output_dir}/seed_{seed}_monthly_ga_time.csv', index=False)\n",
    "\n",
    "    print(f\"Seed {seed}의 CSV 파일들이 성공적으로 저장되었습니다.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def calculate_seed_statistics(output_dir=\"./ga_검증\"):\n",
    "    \"\"\"30개의 seed에 대한 전체 통계 (평균, 표준편차)를 계산하여 저장하는 함수\"\"\"\n",
    "    all_rmse_list = []\n",
    "    all_ga_time_list = []\n",
    "    \n",
    "    # 각 seed별 통계 계산을 위한 리스트\n",
    "    seed_statistics = []\n",
    "\n",
    "    for seed in range(31):  # 0부터 30까지 31번 반복 실험\n",
    "        # seed별로 저장된 CSV 파일 불러오기\n",
    "        monthly_df_rmse = pd.read_csv(f'{output_dir}/seed_{seed}_monthly_rmse.csv')\n",
    "        monthly_df_ga_time = pd.read_csv(f'{output_dir}/seed_{seed}_monthly_ga_time.csv')\n",
    "        \n",
    "        # 전체 RMSE와 GA 시간의 값만 저장 (모든 월을 합친 통계)\n",
    "        rmse_values = monthly_df_rmse.iloc[0, 1:].values  # 월별 RMSE\n",
    "        ga_time_values = monthly_df_ga_time.iloc[0, 1:].values  # 월별 GA Time\n",
    "        \n",
    "        all_rmse_list.append(rmse_values)\n",
    "        all_ga_time_list.append(ga_time_values)\n",
    "        \n",
    "        # 각 seed에 대한 전체 평균과 표준편차 계산\n",
    "        seed_rmse_mean = np.mean(rmse_values)\n",
    "        seed_ga_time_mean = np.mean(ga_time_values)\n",
    "        \n",
    "        # 각 seed별 통계를 저장\n",
    "        seed_statistics.append({\n",
    "            'Seed': seed,\n",
    "            'Mean RMSE': seed_rmse_mean,\n",
    "            'Mean GA Time': seed_ga_time_mean\n",
    "        })\n",
    "    \n",
    "    # 전체 RMSE와 GA 시간에 대한 평균과 표준편차 계산\n",
    "    total_rmse_mean = np.mean(all_rmse_list)\n",
    "    total_ga_time_mean = np.mean(all_ga_time_list)\n",
    "\n",
    "    # 최종 통계 DataFrame 생성 (전체 통계 + 각 seed별 통계)\n",
    "    final_df = pd.DataFrame({\n",
    "        'Total Mean RMSE': [total_rmse_mean],\n",
    "        'Total Mean GA Time': [total_ga_time_mean],\n",
    "    })\n",
    "\n",
    "    # 각 seed별 통계를 DataFrame으로 변환\n",
    "    seed_statistics_df = pd.DataFrame(seed_statistics)\n",
    "\n",
    "    # 저장할 디렉토리 생성 (없는 경우 생성)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # 전체 통계 결과를 CSV로 저장\n",
    "    final_df.to_csv(f'{output_dir}/final_statistics.csv', index=False)\n",
    "    # 각 seed별 통계 결과를 CSV로 저장\n",
    "    seed_statistics_df.to_csv(f'{output_dir}/seed_statistics.csv', index=False)\n",
    "\n",
    "    print(f\"30개의 seed에 대한 통계 파일이 성공적으로 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_ga(input_directory, population_size=100, generations=100, mutation_rate=0.03, output_dir=\"./ga_검증\"):\n",
    "    \"\"\"GA 가중치를 구하고, 테스트 데이터로 RMSE 계산\"\"\"\n",
    "    overall_rmse_list = []\n",
    "    ga_time_list = []\n",
    "\n",
    "    for seed in range(31):  # 0부터 30까지 31번 반복 실험\n",
    "        print(f\"\\nSeed {seed}로 실험 시작\")\n",
    "        \n",
    "        np.random.seed(seed)  # 각 seed마다 난수 초기화\n",
    "        \n",
    "        monthly_rmse_list = []  # 매 `seed`마다 월별 RMSE 리스트 초기화\n",
    "        monthly_ga_time_list = []  # 매 `seed`마다 월별 GA 계산 시간 리스트 초기화\n",
    "\n",
    "        # 1월부터 12월까지 월별로 처리\n",
    "        for month in range(1, 12):\n",
    "\n",
    "            # 검증 데이터를 통해 GA 가중치 구하기\n",
    "            model_predictions, true_values = load_and_process_validation_data(input_directory, month)  # 월별로 검증 데이터 로드\n",
    "            optimal_weights, ga_time = run_ga_experiment(model_predictions, true_values, population_size, generations, mutation_rate, seed)\n",
    "            \n",
    "            # 테스트 데이터를 로드하여 최적 가중치로 예측 및 RMSE 계산\n",
    "            test_predictions, test_true_values = load_and_process_test_data(input_directory, month)  # 월별로 테스트 데이터 로드\n",
    "            test_rmse = calculate_ensemble_rmse2(test_predictions, test_true_values, optimal_weights)\n",
    "\n",
    "            monthly_rmse_list.append(test_rmse)  # 월별 RMSE 추가\n",
    "            monthly_ga_time_list.append(ga_time)  # GA 계산 시간도 리스트에 추가\n",
    "\n",
    "        # 전체 실험 결과 (해당 seed에 대한 결과)\n",
    "        overall_rmse_list.append(np.mean(monthly_rmse_list))  # 월별 RMSE 평균값을 overall에 추가\n",
    "        ga_time_list.append(np.mean(monthly_ga_time_list))  # 월별 GA 계산 시간 평균값을 ga_time_list에 추가\n",
    "\n",
    "        # 해당 seed에 대한 결과를 CSV로 저장\n",
    "        save_to_csv_for_seed(seed, monthly_rmse_list.copy(), monthly_ga_time_list.copy(), output_dir)  # 복사된 리스트 전달\n",
    "\n",
    "    # 모든 seed에 대해 통계 계산 후 CSV로 저장\n",
    "    calculate_seed_statistics(output_dir)\n",
    "\n",
    "    return overall_rmse_list, ga_time_list  # 결과 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Seed 0로 실험 시작\n",
      "Generation 1/100, Best RMSE: 4.761268416323186\n",
      "Generation 2/100, Best RMSE: 4.761268416323186\n",
      "Generation 3/100, Best RMSE: 4.761268416323186\n",
      "Generation 4/100, Best RMSE: 4.761268416323186\n",
      "Generation 5/100, Best RMSE: 4.761268416323186\n",
      "Generation 6/100, Best RMSE: 4.761268416323186\n",
      "Generation 7/100, Best RMSE: 4.761268416323186\n",
      "Generation 8/100, Best RMSE: 4.761268416323186\n",
      "Generation 9/100, Best RMSE: 4.761268416323186\n",
      "Generation 10/100, Best RMSE: 4.761268416323186\n",
      "Generation 11/100, Best RMSE: 4.759915358486413\n",
      "Generation 12/100, Best RMSE: 4.759915358486413\n",
      "Generation 13/100, Best RMSE: 4.759915358486413\n",
      "Generation 14/100, Best RMSE: 4.759915358486413\n",
      "Generation 15/100, Best RMSE: 4.759915358486413\n",
      "Generation 16/100, Best RMSE: 4.759915358486413\n",
      "Generation 17/100, Best RMSE: 4.759915358486413\n",
      "Generation 18/100, Best RMSE: 4.759915358486413\n",
      "Generation 19/100, Best RMSE: 4.759915358486413\n",
      "Generation 20/100, Best RMSE: 4.759915358486413\n",
      "Generation 21/100, Best RMSE: 4.759915358486413\n",
      "Generation 22/100, Best RMSE: 4.759915358486413\n",
      "Generation 23/100, Best RMSE: 4.759915358486413\n",
      "Generation 24/100, Best RMSE: 4.759915358486413\n",
      "Generation 25/100, Best RMSE: 4.759915358486413\n",
      "Generation 26/100, Best RMSE: 4.759915358486413\n",
      "Generation 27/100, Best RMSE: 4.759915358486413\n",
      "Generation 28/100, Best RMSE: 4.759915358486413\n",
      "Generation 29/100, Best RMSE: 4.759915358486413\n",
      "Generation 30/100, Best RMSE: 4.759915358486413\n",
      "Generation 31/100, Best RMSE: 4.759915358486413\n",
      "Generation 32/100, Best RMSE: 4.759915358486413\n",
      "Generation 33/100, Best RMSE: 4.759915358486413\n",
      "Generation 34/100, Best RMSE: 4.759915358486413\n",
      "Generation 35/100, Best RMSE: 4.759915358486413\n",
      "Generation 36/100, Best RMSE: 4.759915358486413\n",
      "Generation 37/100, Best RMSE: 4.759915358486413\n",
      "Generation 38/100, Best RMSE: 4.759915358486413\n",
      "Generation 39/100, Best RMSE: 4.746740253879932\n",
      "Generation 40/100, Best RMSE: 4.746740253879932\n",
      "Generation 41/100, Best RMSE: 4.746740253879932\n",
      "Generation 42/100, Best RMSE: 4.746740253879932\n",
      "Generation 43/100, Best RMSE: 4.746740253879932\n",
      "Generation 44/100, Best RMSE: 4.746740253879932\n",
      "Generation 45/100, Best RMSE: 4.746740253879932\n",
      "Generation 46/100, Best RMSE: 4.746740253879932\n",
      "Generation 47/100, Best RMSE: 4.746740253879932\n",
      "Generation 48/100, Best RMSE: 4.746740253879932\n",
      "Generation 49/100, Best RMSE: 4.746740253879932\n",
      "Generation 50/100, Best RMSE: 4.746740253879932\n",
      "Generation 51/100, Best RMSE: 4.746740253879932\n",
      "Generation 52/100, Best RMSE: 4.746740253879932\n",
      "Generation 53/100, Best RMSE: 4.746740253879932\n",
      "Generation 54/100, Best RMSE: 4.746740253879932\n",
      "Generation 55/100, Best RMSE: 4.746740253879932\n",
      "Generation 56/100, Best RMSE: 4.746740253879932\n",
      "Generation 57/100, Best RMSE: 4.746740253879932\n",
      "Generation 58/100, Best RMSE: 4.746740253879932\n",
      "Generation 59/100, Best RMSE: 4.746740253879932\n",
      "Generation 60/100, Best RMSE: 4.746740253879932\n",
      "Generation 61/100, Best RMSE: 4.746740253879932\n",
      "Generation 62/100, Best RMSE: 4.746740253879932\n",
      "Generation 63/100, Best RMSE: 4.746740253879932\n",
      "Generation 64/100, Best RMSE: 4.746740253879932\n",
      "Generation 65/100, Best RMSE: 4.746740253879932\n",
      "Generation 66/100, Best RMSE: 4.746740253879932\n",
      "Generation 67/100, Best RMSE: 4.746740253879932\n",
      "Generation 68/100, Best RMSE: 4.746740253879932\n",
      "Generation 69/100, Best RMSE: 4.746740253879932\n",
      "Generation 70/100, Best RMSE: 4.746740253879932\n",
      "Generation 71/100, Best RMSE: 4.746740253879932\n",
      "Generation 72/100, Best RMSE: 4.746740253879932\n",
      "Generation 73/100, Best RMSE: 4.746740253879932\n",
      "Generation 74/100, Best RMSE: 4.746740253879932\n",
      "Generation 75/100, Best RMSE: 4.746740253879932\n",
      "Generation 76/100, Best RMSE: 4.746740253879932\n",
      "Generation 77/100, Best RMSE: 4.746740253879932\n",
      "Generation 78/100, Best RMSE: 4.746740253879932\n",
      "Generation 79/100, Best RMSE: 4.746740253879932\n",
      "Generation 80/100, Best RMSE: 4.746740253879932\n",
      "Generation 81/100, Best RMSE: 4.746740253879932\n",
      "Generation 82/100, Best RMSE: 4.746740253879932\n",
      "Generation 83/100, Best RMSE: 4.746740253879932\n",
      "Generation 84/100, Best RMSE: 4.746740253879932\n",
      "Generation 85/100, Best RMSE: 4.746740253879932\n",
      "Generation 86/100, Best RMSE: 4.746740253879932\n",
      "Generation 87/100, Best RMSE: 4.746740253879932\n",
      "Generation 88/100, Best RMSE: 4.746740253879932\n",
      "Generation 89/100, Best RMSE: 4.746740253879932\n",
      "Generation 90/100, Best RMSE: 4.746740253879932\n",
      "Generation 91/100, Best RMSE: 4.746740253879932\n",
      "Generation 92/100, Best RMSE: 4.746740253879932\n",
      "Generation 93/100, Best RMSE: 4.746740253879932\n",
      "Generation 94/100, Best RMSE: 4.746740253879932\n",
      "Generation 95/100, Best RMSE: 4.746740253879932\n",
      "Generation 96/100, Best RMSE: 4.746740253879932\n",
      "Generation 97/100, Best RMSE: 4.746740253879932\n",
      "Generation 98/100, Best RMSE: 4.746740253879932\n",
      "Generation 99/100, Best RMSE: 4.746740253879932\n",
      "Generation 100/100, Best RMSE: 4.746740253879932\n",
      "Optimal Weights: [0.13730062 0.0167808  0.57050898 0.27540961 0.        ]\n",
      "Generation 1/100, Best RMSE: 4.552369981929663\n",
      "Generation 2/100, Best RMSE: 4.552369981929663\n",
      "Generation 3/100, Best RMSE: 4.552369981929663\n",
      "Generation 4/100, Best RMSE: 4.552369981929663\n",
      "Generation 5/100, Best RMSE: 4.552369981929663\n",
      "Generation 6/100, Best RMSE: 4.552369981929663\n",
      "Generation 7/100, Best RMSE: 4.552369981929663\n",
      "Generation 8/100, Best RMSE: 4.547885377580273\n",
      "Generation 9/100, Best RMSE: 4.547885377580273\n",
      "Generation 10/100, Best RMSE: 4.547885377580273\n",
      "Generation 11/100, Best RMSE: 4.547885377580273\n",
      "Generation 12/100, Best RMSE: 4.547885377580273\n",
      "Generation 13/100, Best RMSE: 4.547885377580273\n",
      "Generation 14/100, Best RMSE: 4.547885377580273\n",
      "Generation 15/100, Best RMSE: 4.547885377580273\n",
      "Generation 16/100, Best RMSE: 4.547885377580273\n",
      "Generation 17/100, Best RMSE: 4.547885377580273\n",
      "Generation 18/100, Best RMSE: 4.547885377580273\n",
      "Generation 19/100, Best RMSE: 4.547885377580273\n",
      "Generation 20/100, Best RMSE: 4.547885377580273\n",
      "Generation 21/100, Best RMSE: 4.547885377580273\n",
      "Generation 22/100, Best RMSE: 4.547885377580273\n",
      "Generation 23/100, Best RMSE: 4.547885377580273\n",
      "Generation 24/100, Best RMSE: 4.547885377580273\n",
      "Generation 25/100, Best RMSE: 4.547885377580273\n",
      "Generation 26/100, Best RMSE: 4.547885377580273\n",
      "Generation 27/100, Best RMSE: 4.547885377580273\n",
      "Generation 28/100, Best RMSE: 4.547885377580273\n",
      "Generation 29/100, Best RMSE: 4.547885377580273\n",
      "Generation 30/100, Best RMSE: 4.547885377580273\n",
      "Generation 31/100, Best RMSE: 4.547885377580273\n",
      "Generation 32/100, Best RMSE: 4.547885377580273\n",
      "Generation 33/100, Best RMSE: 4.547885377580273\n",
      "Generation 34/100, Best RMSE: 4.547885377580273\n",
      "Generation 35/100, Best RMSE: 4.547885377580273\n",
      "Generation 36/100, Best RMSE: 4.547885377580273\n",
      "Generation 37/100, Best RMSE: 4.547885377580273\n",
      "Generation 38/100, Best RMSE: 4.547885377580273\n",
      "Generation 39/100, Best RMSE: 4.547885377580273\n",
      "Generation 40/100, Best RMSE: 4.547885377580273\n",
      "Generation 41/100, Best RMSE: 4.547885377580273\n",
      "Generation 42/100, Best RMSE: 4.547885377580273\n",
      "Generation 43/100, Best RMSE: 4.547885377580273\n",
      "Generation 44/100, Best RMSE: 4.547885377580273\n",
      "Generation 45/100, Best RMSE: 4.547885377580273\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./ga_검증_w2_2\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# 저장할 경로를 지정\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# validate_ga 함수 실행하여 결과 가져오기\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m overall_rmse_list, ga_time_list, \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_ga\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpopulation_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmutation_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.03\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[31], line 19\u001b[0m, in \u001b[0;36mvalidate_ga\u001b[1;34m(input_directory, population_size, generations, mutation_rate, output_dir)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m month \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m12\u001b[39m):\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# 검증 데이터를 통해 GA 가중치 구하기\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     model_predictions, true_values \u001b[38;5;241m=\u001b[39m load_and_process_validation_data(input_directory, month)  \u001b[38;5;66;03m# 월별로 검증 데이터 로드\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m     optimal_weights, ga_time \u001b[38;5;241m=\u001b[39m \u001b[43mrun_ga_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpopulation_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmutation_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# 테스트 데이터를 로드하여 최적 가중치로 예측 및 RMSE 계산\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     test_predictions, test_true_values \u001b[38;5;241m=\u001b[39m load_and_process_test_data(input_directory, month)  \u001b[38;5;66;03m# 월별로 테스트 데이터 로드\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[27], line 10\u001b[0m, in \u001b[0;36mrun_ga_experiment\u001b[1;34m(model_predictions, true_values, population_size, generations, mutation_rate, seed)\u001b[0m\n\u001b[0;32m      6\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(seed)  \u001b[38;5;66;03m# seed 설정\u001b[39;00m\n\u001b[0;32m      8\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 10\u001b[0m optimal_weights \u001b[38;5;241m=\u001b[39m \u001b[43mgenetic_algorithm_with_elitism\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mpopulation_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpopulation_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mgenerations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmutation_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmutation_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m ga_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# 앙상블 예측\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[26], line 45\u001b[0m, in \u001b[0;36mgenetic_algorithm_with_elitism\u001b[1;34m(model_predictions, true_values, population_size, generations, mutation_rate, seed)\u001b[0m\n\u001b[0;32m     43\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(seed \u001b[38;5;241m+\u001b[39m generation \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# 세대마다 다른 시드 적용\u001b[39;00m\n\u001b[0;32m     44\u001b[0m crossover_point \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1\u001b[39m, num_models)\n\u001b[1;32m---> 45\u001b[0m child \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent1\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mcrossover_point\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent2\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcrossover_point\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# 돌연변이\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand() \u001b[38;5;241m<\u001b[39m mutation_rate:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 실험에 사용할 입력 데이터 디렉토리 경로를 지정\n",
    "input_directory = \"./ga_w2\"  # 데이터가 저장된 디렉토리 경로로 수정해주세요.\n",
    "# validate_ga 함수 호출\n",
    "# 실행 후 파일을 저장할 디렉토리 지정\n",
    "output_dir = \"./ga_검증_w2_2\"  # 저장할 경로를 지정\n",
    "\n",
    "# validate_ga 함수 실행하여 결과 가져오기\n",
    "overall_rmse_list, ga_time_list, = validate_ga(input_directory, population_size=100, generations=100, mutation_rate=0.03, output_dir=output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "최종 평균 RMSE\n",
      "전체 앙상블 평균 RMSE: 3.142510850439882\n",
      "GA 평균 계산 시간: 1.362541737095002\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n최종 평균 RMSE\")\n",
    "print(f\"전체 앙상블 평균 RMSE: {np.mean(overall_rmse_list)}\")\n",
    "print(f\"GA 평균 계산 시간: {np.mean(ga_time_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
