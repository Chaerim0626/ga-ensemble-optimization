{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GA RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def roulette_wheel_selection(population, fitness_scores):\n",
    "    \"\"\"\n",
    "    ë£°ë › íœ  ì„ íƒ ë°©ì‹ìœ¼ë¡œ ë¶€ëª¨ ê°œì²´ë¥¼ ì„ íƒ\n",
    "    Args:\n",
    "        population: í˜„ì¬ ê°œì²´êµ° (ê°€ì¤‘ì¹˜ ë°°ì—´)\n",
    "        fitness_scores: ê° ê°œì²´ì˜ RMSE (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)\n",
    "    Returns:\n",
    "        ì„ íƒëœ ë¶€ëª¨ ê°œì²´\n",
    "    \"\"\"\n",
    "    fitness_list = []\n",
    "    max_fitness = max(fitness_scores)\n",
    "    min_fitness = min(fitness_scores)\n",
    "    adjustment = (max_fitness - min_fitness) / 2 if max_fitness != min_fitness else 1  # ì¡°ì • ê°’\n",
    "\n",
    "    for m in range(len(fitness_scores)):\n",
    "        # fitness ê³„ì‚°\n",
    "        fitness = max_fitness - fitness_scores[m] + adjustment\n",
    "        fitness_list.append(fitness)\n",
    "\n",
    "    fitness_list = np.array(fitness_list)\n",
    "    total_fitness = np.sum(fitness_list)\n",
    "\n",
    "    # total_fitnessê°€ 0ì¸ ê²½ìš° ì˜ˆì™¸ ì²˜ë¦¬\n",
    "    if total_fitness == 0:\n",
    "        raise ValueError(\"Total fitness is 0, cannot calculate probabilities.\")\n",
    "\n",
    "    probabilities = fitness_list / total_fitness\n",
    "\n",
    "    # ë£°ë › íœ  ë°©ì‹ìœ¼ë¡œ ë¶€ëª¨ ì„ íƒ\n",
    "    selected_index = np.random.choice(len(population), p=probabilities)\n",
    "    return population[selected_index]\n",
    "\n",
    "\n",
    "def genetic_algorithm_with_elitism(model_predictions, true_values, population_size=100, generations=100, mutation_rate=0.03):\n",
    "    \"\"\"\n",
    "    GAë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœì ì˜ ê°€ì¤‘ì¹˜ ì°¾ê¸°\n",
    "    Args:\n",
    "        model_predictions: (n_samples, models, time_window, 2) í˜•íƒœì˜ ëª¨ë¸ ì˜ˆì¸¡ê°’\n",
    "        true_values: (n_samples, time_window, 2) í˜•íƒœì˜ ì‹¤ì œê°’\n",
    "        population_size: ì´ˆê¸° ê°œì²´êµ° í¬ê¸°\n",
    "        generations: ì„¸ëŒ€ ìˆ˜\n",
    "        mutation_rate: ëŒì—°ë³€ì´ í™•ë¥ \n",
    "    Returns:\n",
    "        ìµœì  ê°€ì¤‘ì¹˜ ë°°ì—´\n",
    "    \"\"\"\n",
    "    num_models = model_predictions.shape[1]  # ëª¨ë¸ ìˆ˜\n",
    "    population = np.random.dirichlet(np.ones(num_models), size=population_size)  # ì´ˆê¸° ê°€ì¤‘ì¹˜ ê°œì²´êµ°\n",
    "\n",
    "    for generation in range(generations):\n",
    "        fitness_scores = []\n",
    "\n",
    "        # í˜„ì¬ populationì˜ fitness (RMSE) ê³„ì‚°\n",
    "        for individual in population:\n",
    "            ensemble_prediction = np.sum(\n",
    "                [weight * model_predictions[:, i, :, :] for i, weight in enumerate(individual)],\n",
    "                axis=0\n",
    "            )\n",
    "            rmse = np.sqrt(np.mean((true_values - ensemble_prediction) ** 2))\n",
    "            fitness_scores.append(rmse)\n",
    "        \n",
    "        fitness_scores = np.array(fitness_scores)\n",
    "\n",
    "        # ìƒˆë¡œìš´ population ìƒì„±\n",
    "        new_population = []\n",
    "        while len(new_population) < population_size:\n",
    "            # ë¶€ëª¨ ì„ íƒ\n",
    "            parent1 = roulette_wheel_selection(population, fitness_scores)\n",
    "            parent2 = roulette_wheel_selection(population, fitness_scores)\n",
    "\n",
    "            # êµì°¨ ì—°ì‚°\n",
    "            crossover_point = np.random.randint(1, num_models)\n",
    "            child = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))\n",
    "\n",
    "            # ëŒì—°ë³€ì´\n",
    "            if np.random.rand() < mutation_rate:\n",
    "                mutation_vector = np.random.normal(0, 0.1, size=num_models)\n",
    "                child = np.clip(child + mutation_vector, 0, 1)\n",
    "\n",
    "            # ì •ê·œí™”\n",
    "            child = child / np.sum(child)\n",
    "            new_population.append(child)\n",
    "        \n",
    "        new_population = np.array(new_population)\n",
    "\n",
    "        # ì—˜ë¦¬í‹°ì¦˜ ì ìš©\n",
    "        combined_population = np.vstack((population, new_population))\n",
    "        combined_fitness = np.concatenate((fitness_scores, np.zeros(len(new_population))))\n",
    "\n",
    "        for idx, individual in enumerate(new_population):\n",
    "            ensemble_prediction = np.sum(\n",
    "                [weight * model_predictions[:, i, :, :] for i, weight in enumerate(individual)],\n",
    "                axis=0\n",
    "            )\n",
    "            combined_fitness[len(fitness_scores) + idx] = np.sqrt(np.mean((true_values - ensemble_prediction) ** 2))\n",
    "\n",
    "        sorted_indices = np.argsort(combined_fitness)\n",
    "        population = combined_population[sorted_indices][:population_size]\n",
    "\n",
    "        print(f\"Generation {generation + 1}/{generations}, Best RMSE: {combined_fitness[sorted_indices][0]}\")\n",
    "\n",
    "    # ìµœì  ê°œì²´ ë°˜í™˜\n",
    "    best_weights = population[0]\n",
    "    print(f\"Optimal Weights: {best_weights}\")\n",
    "    return best_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def load_and_process_validation_data(input_directory, month, models=5, time_window=48):\n",
    "    model_predictions = []  # ê° ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ ì €ì¥\n",
    "\n",
    "    for model_idx in range(1, models + 1):\n",
    "        model_dir = os.path.join(input_directory, f\"model{model_idx}\")\n",
    "        file_path = os.path.join(model_dir, f'val_month_{month}_model_{model_idx}_results.csv')\n",
    "\n",
    "        # ğŸ” íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"CSV íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {file_path}, ì˜¤ë¥˜: {e}\")\n",
    "            continue\n",
    "\n",
    "        # ğŸ” ì»¬ëŸ¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸\n",
    "        pred_u_col = f\"Model {model_idx} Val Pred U\"\n",
    "        pred_v_col = f\"Model {model_idx} Val Pred V\"\n",
    "\n",
    "        if pred_u_col not in df.columns or pred_v_col not in df.columns:\n",
    "            print(f\"ì˜ˆì¸¡ ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {pred_u_col}, {pred_v_col}\")\n",
    "            continue\n",
    "\n",
    "        pred_u = df[pred_u_col].values\n",
    "        pred_v = df[pred_v_col].values\n",
    "\n",
    "        # True ê°’ì€ ëª¨ë¸ 1ì—ì„œë§Œ ì¶”ì¶œ\n",
    "        if model_idx == 1:\n",
    "            if \"True U\" not in df.columns or \"True V\" not in df.columns:\n",
    "                print(f\"True ê°’ ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "                continue\n",
    "\n",
    "            true_u = df[\"True U\"].values\n",
    "            true_v = df[\"True V\"].values\n",
    "\n",
    "        # ğŸ” ë°ì´í„° ê¸¸ì´ í™•ì¸ ë° ì˜ˆì™¸ ì²˜ë¦¬\n",
    "        n_samples = len(pred_u) // time_window\n",
    "        if n_samples == 0:\n",
    "            print(f\"{file_path}: ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. (ë°ì´í„° ê¸¸ì´: {len(pred_u)})\")\n",
    "            continue\n",
    "\n",
    "        pred_u = np.array(pred_u[:n_samples * time_window]).reshape(n_samples, time_window, 1)\n",
    "        pred_v = np.array(pred_v[:n_samples * time_window]).reshape(n_samples, time_window, 1)\n",
    "        model_predictions.append(np.concatenate([pred_u, pred_v], axis=2))  # (n_samples, 48, 2)\n",
    "\n",
    "        # True ê°’ ë³‘í•© (í•œ ë²ˆë§Œ ì‹¤í–‰)\n",
    "        if model_idx == 1:\n",
    "            true_u = np.array(true_u[:n_samples * time_window]).reshape(n_samples, time_window, 1)\n",
    "            true_v = np.array(true_v[:n_samples * time_window]).reshape(n_samples, time_window, 1)\n",
    "            true_values = np.concatenate([true_u, true_v], axis=2)  # (n_samples, 48, 2)\n",
    "\n",
    "    # ğŸ” ì˜ˆì¸¡ê°’ì´ ì—†ëŠ” ê²½ìš° ì˜ˆì™¸ ì²˜ë¦¬\n",
    "    if not model_predictions:\n",
    "        print(f\"{month}ì›”: ëª¨ë¸ ì˜ˆì¸¡ê°’ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return np.array([]), np.array([])\n",
    "\n",
    "    # ğŸ” ëª¨ë¸ ì˜ˆì¸¡ê°’ í˜•íƒœ ë³€í™˜: (n_samples, models, 48, 2)\n",
    "    try:\n",
    "        model_predictions = np.stack(model_predictions, axis=1)\n",
    "    except ValueError as e:\n",
    "        print(f\"ëª¨ë¸ ì˜ˆì¸¡ê°’ ë³‘í•© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        return np.array([]), np.array([])\n",
    "\n",
    "    return model_predictions, true_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 5, 48, 2) (28, 48, 2)\n",
      "Generation 1/100, Best RMSE: 2.4892451847932526\n",
      "Generation 2/100, Best RMSE: 2.4892451847932526\n",
      "Generation 3/100, Best RMSE: 2.4840025743603382\n",
      "Generation 4/100, Best RMSE: 2.477932539573514\n",
      "Generation 5/100, Best RMSE: 2.477932539573514\n",
      "Generation 6/100, Best RMSE: 2.4769732789217427\n",
      "Generation 7/100, Best RMSE: 2.476595650542298\n",
      "Generation 8/100, Best RMSE: 2.476223955025573\n",
      "Generation 9/100, Best RMSE: 2.4760774585222434\n",
      "Generation 10/100, Best RMSE: 2.4759646732103877\n",
      "Generation 11/100, Best RMSE: 2.4759512277440296\n",
      "Generation 12/100, Best RMSE: 2.475949648856288\n",
      "Generation 13/100, Best RMSE: 2.4759248460555208\n",
      "Generation 14/100, Best RMSE: 2.4759248460555208\n",
      "Generation 15/100, Best RMSE: 2.475903775145306\n",
      "Generation 16/100, Best RMSE: 2.475902058888825\n",
      "Generation 17/100, Best RMSE: 2.475902058888825\n",
      "Generation 18/100, Best RMSE: 2.475902058888825\n",
      "Generation 19/100, Best RMSE: 2.475902058888825\n",
      "Generation 20/100, Best RMSE: 2.475902058888825\n",
      "Generation 21/100, Best RMSE: 2.475902058888825\n",
      "Generation 22/100, Best RMSE: 2.475902055355553\n",
      "Generation 23/100, Best RMSE: 2.4759020092137667\n",
      "Generation 24/100, Best RMSE: 2.4759020092137667\n",
      "Generation 25/100, Best RMSE: 2.475902005516422\n",
      "Generation 26/100, Best RMSE: 2.475901994495269\n",
      "Generation 27/100, Best RMSE: 2.475901990402292\n",
      "Generation 28/100, Best RMSE: 2.47590198169704\n",
      "Generation 29/100, Best RMSE: 2.475901976175956\n",
      "Generation 30/100, Best RMSE: 2.4759019746655664\n",
      "Generation 31/100, Best RMSE: 2.4759019746655664\n",
      "Generation 32/100, Best RMSE: 2.4759019741893034\n",
      "Generation 33/100, Best RMSE: 2.4759019735935652\n",
      "Generation 34/100, Best RMSE: 2.4759019735935652\n",
      "Generation 35/100, Best RMSE: 2.475901973369689\n",
      "Generation 36/100, Best RMSE: 2.4759019732068817\n",
      "Generation 37/100, Best RMSE: 2.4759019715230663\n",
      "Generation 38/100, Best RMSE: 2.475901970855492\n",
      "Generation 39/100, Best RMSE: 2.475901970855492\n",
      "Generation 40/100, Best RMSE: 2.475901970855492\n",
      "Generation 41/100, Best RMSE: 2.4759019708477092\n",
      "Generation 42/100, Best RMSE: 2.4759019707232928\n",
      "Generation 43/100, Best RMSE: 2.4759019706921572\n",
      "Generation 44/100, Best RMSE: 2.4759019706616994\n",
      "Generation 45/100, Best RMSE: 2.47590197061471\n",
      "Generation 46/100, Best RMSE: 2.47590197059182\n",
      "Generation 47/100, Best RMSE: 2.4759019705826333\n",
      "Generation 48/100, Best RMSE: 2.475901970541247\n",
      "Generation 49/100, Best RMSE: 2.4759019705009204\n",
      "Generation 50/100, Best RMSE: 2.475901970467246\n",
      "Generation 51/100, Best RMSE: 2.475901970438436\n",
      "Generation 52/100, Best RMSE: 2.4759019704374876\n",
      "Generation 53/100, Best RMSE: 2.475901970403064\n",
      "Generation 54/100, Best RMSE: 2.475901970403064\n",
      "Generation 55/100, Best RMSE: 2.475901970403064\n",
      "Generation 56/100, Best RMSE: 2.4759019704008045\n",
      "Generation 57/100, Best RMSE: 2.475901970387341\n",
      "Generation 58/100, Best RMSE: 2.475901970387341\n",
      "Generation 59/100, Best RMSE: 2.475901970387341\n",
      "Generation 60/100, Best RMSE: 2.475901970382844\n",
      "Generation 61/100, Best RMSE: 2.475901970381812\n",
      "Generation 62/100, Best RMSE: 2.4759019703784646\n",
      "Generation 63/100, Best RMSE: 2.4759019703784646\n",
      "Generation 64/100, Best RMSE: 2.4759019703770067\n",
      "Generation 65/100, Best RMSE: 2.4759019703752614\n",
      "Generation 66/100, Best RMSE: 2.475901970374736\n",
      "Generation 67/100, Best RMSE: 2.475901970374736\n",
      "Generation 68/100, Best RMSE: 2.4759019703729352\n",
      "Generation 69/100, Best RMSE: 2.4759019703729352\n",
      "Generation 70/100, Best RMSE: 2.4759019703720644\n",
      "Generation 71/100, Best RMSE: 2.4759019703718415\n",
      "Generation 72/100, Best RMSE: 2.4759019703717398\n",
      "Generation 73/100, Best RMSE: 2.475901970371328\n",
      "Generation 74/100, Best RMSE: 2.475901970371066\n",
      "Generation 75/100, Best RMSE: 2.475901970371054\n",
      "Generation 76/100, Best RMSE: 2.475901970370668\n",
      "Generation 77/100, Best RMSE: 2.475901970370614\n",
      "Generation 78/100, Best RMSE: 2.475901970370466\n",
      "Generation 79/100, Best RMSE: 2.4759019703704084\n",
      "Generation 80/100, Best RMSE: 2.4759019703703147\n",
      "Generation 81/100, Best RMSE: 2.4759019703702982\n",
      "Generation 82/100, Best RMSE: 2.4759019703702707\n",
      "Generation 83/100, Best RMSE: 2.475901970370208\n",
      "Generation 84/100, Best RMSE: 2.4759019703701894\n",
      "Generation 85/100, Best RMSE: 2.4759019703701894\n",
      "Generation 86/100, Best RMSE: 2.475901970370184\n",
      "Generation 87/100, Best RMSE: 2.4759019703701792\n",
      "Generation 88/100, Best RMSE: 2.4759019703701792\n",
      "Generation 89/100, Best RMSE: 2.4759019703701766\n",
      "Generation 90/100, Best RMSE: 2.47590197037016\n",
      "Generation 91/100, Best RMSE: 2.47590197037016\n",
      "Generation 92/100, Best RMSE: 2.4759019703701464\n",
      "Generation 93/100, Best RMSE: 2.4759019703701464\n",
      "Generation 94/100, Best RMSE: 2.4759019703701464\n",
      "Generation 95/100, Best RMSE: 2.4759019703701464\n",
      "Generation 96/100, Best RMSE: 2.475901970370146\n",
      "Generation 97/100, Best RMSE: 2.475901970370145\n",
      "Generation 98/100, Best RMSE: 2.4759019703701446\n",
      "Generation 99/100, Best RMSE: 2.475901970370144\n",
      "Generation 100/100, Best RMSE: 2.4759019703701433\n",
      "Optimal Weights: [0.51842763 0.03934001 0.37414119 0.         0.06809118]\n",
      "(31, 5, 48, 2) (31, 48, 2)\n",
      "Generation 1/100, Best RMSE: 2.5701735151522405\n",
      "Generation 2/100, Best RMSE: 2.5653790846142934\n",
      "Generation 3/100, Best RMSE: 2.5653790846142934\n",
      "Generation 4/100, Best RMSE: 2.5651457020151742\n",
      "Generation 5/100, Best RMSE: 2.565069716783168\n",
      "Generation 6/100, Best RMSE: 2.565022734633937\n",
      "Generation 7/100, Best RMSE: 2.5644669278694354\n",
      "Generation 8/100, Best RMSE: 2.564410347344593\n",
      "Generation 9/100, Best RMSE: 2.564346396994637\n",
      "Generation 10/100, Best RMSE: 2.564346396994637\n",
      "Generation 11/100, Best RMSE: 2.564346396994637\n",
      "Generation 12/100, Best RMSE: 2.5643437873592623\n",
      "Generation 13/100, Best RMSE: 2.564343044811643\n",
      "Generation 14/100, Best RMSE: 2.564343044811643\n",
      "Generation 15/100, Best RMSE: 2.56434293706841\n",
      "Generation 16/100, Best RMSE: 2.5643420597729456\n",
      "Generation 17/100, Best RMSE: 2.564341900680357\n",
      "Generation 18/100, Best RMSE: 2.5643412908621666\n",
      "Generation 19/100, Best RMSE: 2.5643410544586\n",
      "Generation 20/100, Best RMSE: 2.564340957308297\n",
      "Generation 21/100, Best RMSE: 2.5643407493272057\n",
      "Generation 22/100, Best RMSE: 2.5643405610016945\n",
      "Generation 23/100, Best RMSE: 2.5643405610016945\n",
      "Generation 24/100, Best RMSE: 2.564340450366108\n",
      "Generation 25/100, Best RMSE: 2.564340450366108\n",
      "Generation 26/100, Best RMSE: 2.564340442402464\n",
      "Generation 27/100, Best RMSE: 2.564340400960759\n",
      "Generation 28/100, Best RMSE: 2.564340400960759\n",
      "Generation 29/100, Best RMSE: 2.5643403700014153\n",
      "Generation 30/100, Best RMSE: 2.5643403700014153\n",
      "Generation 31/100, Best RMSE: 2.5643403651681376\n",
      "Generation 32/100, Best RMSE: 2.5643403572930494\n",
      "Generation 33/100, Best RMSE: 2.5643403539544978\n",
      "Generation 34/100, Best RMSE: 2.5643403517848204\n",
      "Generation 35/100, Best RMSE: 2.5643403517848204\n",
      "Generation 36/100, Best RMSE: 2.5643403514053014\n",
      "Generation 37/100, Best RMSE: 2.5643403503058972\n",
      "Generation 38/100, Best RMSE: 2.5643403461805505\n",
      "Generation 39/100, Best RMSE: 2.5643403461805505\n",
      "Generation 40/100, Best RMSE: 2.5643403450383913\n",
      "Generation 41/100, Best RMSE: 2.5643403440428876\n",
      "Generation 42/100, Best RMSE: 2.564340343383314\n",
      "Generation 43/100, Best RMSE: 2.5643403428561595\n",
      "Generation 44/100, Best RMSE: 2.5643403413111128\n",
      "Generation 45/100, Best RMSE: 2.564340340646838\n",
      "Generation 46/100, Best RMSE: 2.564340340646838\n",
      "Generation 47/100, Best RMSE: 2.564340340646838\n",
      "Generation 48/100, Best RMSE: 2.564340340517225\n",
      "Generation 49/100, Best RMSE: 2.564340340194854\n",
      "Generation 50/100, Best RMSE: 2.5643403399239157\n",
      "Generation 51/100, Best RMSE: 2.564340339850568\n",
      "Generation 52/100, Best RMSE: 2.5643403398347804\n",
      "Generation 53/100, Best RMSE: 2.5643403398347804\n",
      "Generation 54/100, Best RMSE: 2.5643403398347804\n",
      "Generation 55/100, Best RMSE: 2.5643403397967823\n",
      "Generation 56/100, Best RMSE: 2.5643403397205398\n",
      "Generation 57/100, Best RMSE: 2.5643403397205398\n",
      "Generation 58/100, Best RMSE: 2.5643403397203004\n",
      "Generation 59/100, Best RMSE: 2.564340339684286\n",
      "Generation 60/100, Best RMSE: 2.564340339663282\n",
      "Generation 61/100, Best RMSE: 2.5643403396555007\n",
      "Generation 62/100, Best RMSE: 2.564340339633327\n",
      "Generation 63/100, Best RMSE: 2.564340339615375\n",
      "Generation 64/100, Best RMSE: 2.5643403395892084\n",
      "Generation 65/100, Best RMSE: 2.5643403395892084\n",
      "Generation 66/100, Best RMSE: 2.564340339586796\n",
      "Generation 67/100, Best RMSE: 2.56434033956399\n",
      "Generation 68/100, Best RMSE: 2.56434033956399\n",
      "Generation 69/100, Best RMSE: 2.5643403395581745\n",
      "Generation 70/100, Best RMSE: 2.564340339555946\n",
      "Generation 71/100, Best RMSE: 2.5643403395429982\n",
      "Generation 72/100, Best RMSE: 2.564340339541952\n",
      "Generation 73/100, Best RMSE: 2.564340339532831\n",
      "Generation 74/100, Best RMSE: 2.5643403395322553\n",
      "Generation 75/100, Best RMSE: 2.5643403395316584\n",
      "Generation 76/100, Best RMSE: 2.564340339528253\n",
      "Generation 77/100, Best RMSE: 2.5643403395281457\n",
      "Generation 78/100, Best RMSE: 2.564340339524451\n",
      "Generation 79/100, Best RMSE: 2.5643403395234503\n",
      "Generation 80/100, Best RMSE: 2.56434033952217\n",
      "Generation 81/100, Best RMSE: 2.5643403395209337\n",
      "Generation 82/100, Best RMSE: 2.5643403395206184\n",
      "Generation 83/100, Best RMSE: 2.5643403395206184\n",
      "Generation 84/100, Best RMSE: 2.564340339520054\n",
      "Generation 85/100, Best RMSE: 2.5643403395188047\n",
      "Generation 86/100, Best RMSE: 2.5643403395186453\n",
      "Generation 87/100, Best RMSE: 2.564340339517907\n",
      "Generation 88/100, Best RMSE: 2.5643403395172624\n",
      "Generation 89/100, Best RMSE: 2.5643403395170954\n",
      "Generation 90/100, Best RMSE: 2.564340339516633\n",
      "Generation 91/100, Best RMSE: 2.5643403395159416\n",
      "Generation 92/100, Best RMSE: 2.5643403395159416\n",
      "Generation 93/100, Best RMSE: 2.5643403395159416\n",
      "Generation 94/100, Best RMSE: 2.5643403395157165\n",
      "Generation 95/100, Best RMSE: 2.564340339515379\n",
      "Generation 96/100, Best RMSE: 2.5643403395152733\n",
      "Generation 97/100, Best RMSE: 2.5643403395149127\n",
      "Generation 98/100, Best RMSE: 2.5643403395147617\n",
      "Generation 99/100, Best RMSE: 2.564340339514627\n",
      "Generation 100/100, Best RMSE: 2.5643403395143216\n",
      "Optimal Weights: [0.38389873 0.13705036 0.08239942 0.         0.39665149]\n",
      "(30, 5, 48, 2) (30, 48, 2)\n",
      "Generation 1/100, Best RMSE: 3.853196478886592\n",
      "Generation 2/100, Best RMSE: 3.85229724004458\n",
      "Generation 3/100, Best RMSE: 3.850282635540399\n",
      "Generation 4/100, Best RMSE: 3.850282635540399\n",
      "Generation 5/100, Best RMSE: 3.850282635540399\n",
      "Generation 6/100, Best RMSE: 3.8491346974892036\n",
      "Generation 7/100, Best RMSE: 3.848735199131522\n",
      "Generation 8/100, Best RMSE: 3.848735199131522\n",
      "Generation 9/100, Best RMSE: 3.8487043863536408\n",
      "Generation 10/100, Best RMSE: 3.8483599823415235\n",
      "Generation 11/100, Best RMSE: 3.8483006923985403\n",
      "Generation 12/100, Best RMSE: 3.848178878075974\n",
      "Generation 13/100, Best RMSE: 3.8481643249420423\n",
      "Generation 14/100, Best RMSE: 3.8481583303052473\n",
      "Generation 15/100, Best RMSE: 3.8481583303052473\n",
      "Generation 16/100, Best RMSE: 3.8479773938957975\n",
      "Generation 17/100, Best RMSE: 3.847970983284408\n",
      "Generation 18/100, Best RMSE: 3.847969664973389\n",
      "Generation 19/100, Best RMSE: 3.847969664973389\n",
      "Generation 20/100, Best RMSE: 3.8479684694269576\n",
      "Generation 21/100, Best RMSE: 3.8479682602851497\n",
      "Generation 22/100, Best RMSE: 3.8479681839107944\n",
      "Generation 23/100, Best RMSE: 3.8479681750290142\n",
      "Generation 24/100, Best RMSE: 3.8479681750290142\n",
      "Generation 25/100, Best RMSE: 3.8479680140546737\n",
      "Generation 26/100, Best RMSE: 3.8479680140546737\n",
      "Generation 27/100, Best RMSE: 3.8479680140546737\n",
      "Generation 28/100, Best RMSE: 3.8479680140546737\n",
      "Generation 29/100, Best RMSE: 3.847967977615031\n",
      "Generation 30/100, Best RMSE: 3.8479679409577554\n",
      "Generation 31/100, Best RMSE: 3.8479679400231404\n",
      "Generation 32/100, Best RMSE: 3.84796793907125\n",
      "Generation 33/100, Best RMSE: 3.84796793907125\n",
      "Generation 34/100, Best RMSE: 3.847967938431262\n",
      "Generation 35/100, Best RMSE: 3.847967938431262\n",
      "Generation 36/100, Best RMSE: 3.847967938431262\n",
      "Generation 37/100, Best RMSE: 3.8479679383919665\n",
      "Generation 38/100, Best RMSE: 3.8479679383919665\n",
      "Generation 39/100, Best RMSE: 3.84796793822492\n",
      "Generation 40/100, Best RMSE: 3.84796793822492\n",
      "Generation 41/100, Best RMSE: 3.84796793822492\n",
      "Generation 42/100, Best RMSE: 3.84796793822492\n",
      "Generation 43/100, Best RMSE: 3.8479679382025136\n",
      "Generation 44/100, Best RMSE: 3.8479679381920193\n",
      "Generation 45/100, Best RMSE: 3.8479679381920193\n",
      "Generation 46/100, Best RMSE: 3.847967938188484\n",
      "Generation 47/100, Best RMSE: 3.847967938173165\n",
      "Generation 48/100, Best RMSE: 3.847967938167872\n",
      "Generation 49/100, Best RMSE: 3.8479679381577143\n",
      "Generation 50/100, Best RMSE: 3.8479679381572263\n",
      "Generation 51/100, Best RMSE: 3.847967938154312\n",
      "Generation 52/100, Best RMSE: 3.847967938145133\n",
      "Generation 53/100, Best RMSE: 3.8479679381367653\n",
      "Generation 54/100, Best RMSE: 3.8479679381325496\n",
      "Generation 55/100, Best RMSE: 3.847967938127478\n",
      "Generation 56/100, Best RMSE: 3.847967938127478\n",
      "Generation 57/100, Best RMSE: 3.8479679381273435\n",
      "Generation 58/100, Best RMSE: 3.8479679381260024\n",
      "Generation 59/100, Best RMSE: 3.8479679381253695\n",
      "Generation 60/100, Best RMSE: 3.8479679381233525\n",
      "Generation 61/100, Best RMSE: 3.8479679381224785\n",
      "Generation 62/100, Best RMSE: 3.847967938121566\n",
      "Generation 63/100, Best RMSE: 3.8479679381212915\n",
      "Generation 64/100, Best RMSE: 3.8479679381208967\n",
      "Generation 65/100, Best RMSE: 3.847967938119794\n",
      "Generation 66/100, Best RMSE: 3.847967938119794\n",
      "Generation 67/100, Best RMSE: 3.8479679381195617\n",
      "Generation 68/100, Best RMSE: 3.847967938118896\n",
      "Generation 69/100, Best RMSE: 3.847967938118879\n",
      "Generation 70/100, Best RMSE: 3.8479679381180882\n",
      "Generation 71/100, Best RMSE: 3.8479679381180882\n",
      "Generation 72/100, Best RMSE: 3.8479679381178142\n",
      "Generation 73/100, Best RMSE: 3.847967938117596\n",
      "Generation 74/100, Best RMSE: 3.8479679381173097\n",
      "Generation 75/100, Best RMSE: 3.8479679381173097\n",
      "Generation 76/100, Best RMSE: 3.8479679381171117\n",
      "Generation 77/100, Best RMSE: 3.847967938117004\n",
      "Generation 78/100, Best RMSE: 3.847967938116905\n",
      "Generation 79/100, Best RMSE: 3.847967938116836\n",
      "Generation 80/100, Best RMSE: 3.847967938116826\n",
      "Generation 81/100, Best RMSE: 3.847967938116754\n",
      "Generation 82/100, Best RMSE: 3.8479679381165757\n",
      "Generation 83/100, Best RMSE: 3.8479679381165757\n",
      "Generation 84/100, Best RMSE: 3.8479679381165623\n",
      "Generation 85/100, Best RMSE: 3.8479679381165237\n",
      "Generation 86/100, Best RMSE: 3.8479679381165015\n",
      "Generation 87/100, Best RMSE: 3.8479679381164384\n",
      "Generation 88/100, Best RMSE: 3.8479679381164384\n",
      "Generation 89/100, Best RMSE: 3.847967938116396\n",
      "Generation 90/100, Best RMSE: 3.847967938116364\n",
      "Generation 91/100, Best RMSE: 3.847967938116332\n",
      "Generation 92/100, Best RMSE: 3.847967938116332\n",
      "Generation 93/100, Best RMSE: 3.847967938116323\n",
      "Generation 94/100, Best RMSE: 3.8479679381163083\n",
      "Generation 95/100, Best RMSE: 3.8479679381163083\n",
      "Generation 96/100, Best RMSE: 3.8479679381162923\n",
      "Generation 97/100, Best RMSE: 3.8479679381162777\n",
      "Generation 98/100, Best RMSE: 3.8479679381162546\n",
      "Generation 99/100, Best RMSE: 3.847967938116245\n",
      "Generation 100/100, Best RMSE: 3.847967938116222\n",
      "Optimal Weights: [0.         0.02975621 0.31423977 0.39087923 0.26512478]\n",
      "(27, 5, 48, 2) (27, 48, 2)\n",
      "Generation 1/100, Best RMSE: 5.3931221690795725\n",
      "Generation 2/100, Best RMSE: 5.3931221690795725\n",
      "Generation 3/100, Best RMSE: 5.354405587047089\n",
      "Generation 4/100, Best RMSE: 5.329595124785625\n",
      "Generation 5/100, Best RMSE: 5.314455216144154\n",
      "Generation 6/100, Best RMSE: 5.290837775468357\n",
      "Generation 7/100, Best RMSE: 5.290837775468357\n",
      "Generation 8/100, Best RMSE: 5.269254002892545\n",
      "Generation 9/100, Best RMSE: 5.268146188109213\n",
      "Generation 10/100, Best RMSE: 5.256327653671634\n",
      "Generation 11/100, Best RMSE: 5.256327653671634\n",
      "Generation 12/100, Best RMSE: 5.249452300218392\n",
      "Generation 13/100, Best RMSE: 5.2459949666275\n",
      "Generation 14/100, Best RMSE: 5.2393353013855\n",
      "Generation 15/100, Best RMSE: 5.2393353013855\n",
      "Generation 16/100, Best RMSE: 5.2393353013855\n",
      "Generation 17/100, Best RMSE: 5.2393353013855\n",
      "Generation 18/100, Best RMSE: 5.2393353013855\n",
      "Generation 19/100, Best RMSE: 5.2393353013855\n",
      "Generation 20/100, Best RMSE: 5.2393353013855\n",
      "Generation 21/100, Best RMSE: 5.2393353013855\n",
      "Generation 22/100, Best RMSE: 5.2393353013855\n",
      "Generation 23/100, Best RMSE: 5.2393353013855\n",
      "Generation 24/100, Best RMSE: 5.2393353013855\n",
      "Generation 25/100, Best RMSE: 5.2393353013855\n",
      "Generation 26/100, Best RMSE: 5.2393353013855\n",
      "Generation 27/100, Best RMSE: 5.2393353013855\n",
      "Generation 28/100, Best RMSE: 5.2393353013855\n",
      "Generation 29/100, Best RMSE: 5.2393353013855\n",
      "Generation 30/100, Best RMSE: 5.2393353013855\n",
      "Generation 31/100, Best RMSE: 5.2393353013855\n",
      "Generation 32/100, Best RMSE: 5.2393353013855\n",
      "Generation 33/100, Best RMSE: 5.2393353013855\n",
      "Generation 34/100, Best RMSE: 5.2393353013855\n",
      "Generation 35/100, Best RMSE: 5.2393353013855\n",
      "Generation 36/100, Best RMSE: 5.2393353013855\n",
      "Generation 37/100, Best RMSE: 5.2393353013855\n",
      "Generation 38/100, Best RMSE: 5.2393353013855\n",
      "Generation 39/100, Best RMSE: 5.2393353013855\n",
      "Generation 40/100, Best RMSE: 5.2393353013855\n",
      "Generation 41/100, Best RMSE: 5.2393353013855\n",
      "Generation 42/100, Best RMSE: 5.2393353013855\n",
      "Generation 43/100, Best RMSE: 5.2393353013855\n",
      "Generation 44/100, Best RMSE: 5.2393353013855\n",
      "Generation 45/100, Best RMSE: 5.2393353013855\n",
      "Generation 46/100, Best RMSE: 5.2393353013855\n",
      "Generation 47/100, Best RMSE: 5.2393353013855\n",
      "Generation 48/100, Best RMSE: 5.2393353013855\n",
      "Generation 49/100, Best RMSE: 5.2393353013855\n",
      "Generation 50/100, Best RMSE: 5.2393353013855\n",
      "Generation 51/100, Best RMSE: 5.2393353013855\n",
      "Generation 52/100, Best RMSE: 5.2393353013855\n",
      "Generation 53/100, Best RMSE: 5.2393353013855\n",
      "Generation 54/100, Best RMSE: 5.2393353013855\n",
      "Generation 55/100, Best RMSE: 5.2393353013855\n",
      "Generation 56/100, Best RMSE: 5.2393353013855\n",
      "Generation 57/100, Best RMSE: 5.2393353013855\n",
      "Generation 58/100, Best RMSE: 5.2393353013855\n",
      "Generation 59/100, Best RMSE: 5.2393353013855\n",
      "Generation 60/100, Best RMSE: 5.2393353013855\n",
      "Generation 61/100, Best RMSE: 5.2393353013855\n",
      "Generation 62/100, Best RMSE: 5.2393353013855\n",
      "Generation 63/100, Best RMSE: 5.2393353013855\n",
      "Generation 64/100, Best RMSE: 5.2393353013855\n",
      "Generation 65/100, Best RMSE: 5.2393353013855\n",
      "Generation 66/100, Best RMSE: 5.2393353013855\n",
      "Generation 67/100, Best RMSE: 5.2393353013855\n",
      "Generation 68/100, Best RMSE: 5.2393353013855\n",
      "Generation 69/100, Best RMSE: 5.2393353013855\n",
      "Generation 70/100, Best RMSE: 5.2393353013855\n",
      "Generation 71/100, Best RMSE: 5.2393353013855\n",
      "Generation 72/100, Best RMSE: 5.2393353013855\n",
      "Generation 73/100, Best RMSE: 5.2393353013855\n",
      "Generation 74/100, Best RMSE: 5.2393353013855\n",
      "Generation 75/100, Best RMSE: 5.2393353013855\n",
      "Generation 76/100, Best RMSE: 5.2393353013855\n",
      "Generation 77/100, Best RMSE: 5.2393353013855\n",
      "Generation 78/100, Best RMSE: 5.2393353013855\n",
      "Generation 79/100, Best RMSE: 5.2393353013855\n",
      "Generation 80/100, Best RMSE: 5.2393353013855\n",
      "Generation 81/100, Best RMSE: 5.2393353013855\n",
      "Generation 82/100, Best RMSE: 5.2393353013855\n",
      "Generation 83/100, Best RMSE: 5.2393353013855\n",
      "Generation 84/100, Best RMSE: 5.2393353013855\n",
      "Generation 85/100, Best RMSE: 5.2393353013855\n",
      "Generation 86/100, Best RMSE: 5.2393353013855\n",
      "Generation 87/100, Best RMSE: 5.2393353013855\n",
      "Generation 88/100, Best RMSE: 5.2393353013855\n",
      "Generation 89/100, Best RMSE: 5.2393353013855\n",
      "Generation 90/100, Best RMSE: 5.2393353013855\n",
      "Generation 91/100, Best RMSE: 5.2393353013855\n",
      "Generation 92/100, Best RMSE: 5.2393353013855\n",
      "Generation 93/100, Best RMSE: 5.2393353013855\n",
      "Generation 94/100, Best RMSE: 5.2393353013855\n",
      "Generation 95/100, Best RMSE: 5.2393353013855\n",
      "Generation 96/100, Best RMSE: 5.2393353013855\n",
      "Generation 97/100, Best RMSE: 5.2393353013855\n",
      "Generation 98/100, Best RMSE: 5.2393353013855\n",
      "Generation 99/100, Best RMSE: 5.2393353013855\n",
      "Generation 100/100, Best RMSE: 5.2393353013855\n",
      "Optimal Weights: [0. 0. 0. 1. 0.]\n",
      "(24, 5, 48, 2) (24, 48, 2)\n",
      "Generation 1/100, Best RMSE: 1.9963199562328116\n",
      "Generation 2/100, Best RMSE: 1.9929366075644368\n",
      "Generation 3/100, Best RMSE: 1.9921688408385632\n",
      "Generation 4/100, Best RMSE: 1.9920414777773234\n",
      "Generation 5/100, Best RMSE: 1.9917465471049725\n",
      "Generation 6/100, Best RMSE: 1.9915627594611054\n",
      "Generation 7/100, Best RMSE: 1.9915273838886633\n",
      "Generation 8/100, Best RMSE: 1.99137008068581\n",
      "Generation 9/100, Best RMSE: 1.9913483029541272\n",
      "Generation 10/100, Best RMSE: 1.9913061729484924\n",
      "Generation 11/100, Best RMSE: 1.9913061729484924\n",
      "Generation 12/100, Best RMSE: 1.9913061729484924\n",
      "Generation 13/100, Best RMSE: 1.9913056304568935\n",
      "Generation 14/100, Best RMSE: 1.9913045492208445\n",
      "Generation 15/100, Best RMSE: 1.9913042706344912\n",
      "Generation 16/100, Best RMSE: 1.9913035189058788\n",
      "Generation 17/100, Best RMSE: 1.9913032731429192\n",
      "Generation 18/100, Best RMSE: 1.9913030049229736\n",
      "Generation 19/100, Best RMSE: 1.9913029037400094\n",
      "Generation 20/100, Best RMSE: 1.9913029023660271\n",
      "Generation 21/100, Best RMSE: 1.9913028905391736\n",
      "Generation 22/100, Best RMSE: 1.9913028794705434\n",
      "Generation 23/100, Best RMSE: 1.9913028770878642\n",
      "Generation 24/100, Best RMSE: 1.9913028770878642\n",
      "Generation 25/100, Best RMSE: 1.9913028770878642\n",
      "Generation 26/100, Best RMSE: 1.9913028767275112\n",
      "Generation 27/100, Best RMSE: 1.9913028764487095\n",
      "Generation 28/100, Best RMSE: 1.991302876419549\n",
      "Generation 29/100, Best RMSE: 1.9913028763408585\n",
      "Generation 30/100, Best RMSE: 1.9913028763294813\n",
      "Generation 31/100, Best RMSE: 1.9913028763212923\n",
      "Generation 32/100, Best RMSE: 1.9913028763103706\n",
      "Generation 33/100, Best RMSE: 1.99130287629013\n",
      "Generation 34/100, Best RMSE: 1.9913028762867007\n",
      "Generation 35/100, Best RMSE: 1.9913028762830876\n",
      "Generation 36/100, Best RMSE: 1.9913028762751497\n",
      "Generation 37/100, Best RMSE: 1.9913028762725367\n",
      "Generation 38/100, Best RMSE: 1.9913028762705818\n",
      "Generation 39/100, Best RMSE: 1.9913028762705818\n",
      "Generation 40/100, Best RMSE: 1.991302876269941\n",
      "Generation 41/100, Best RMSE: 1.991302876269941\n",
      "Generation 42/100, Best RMSE: 1.9913028762679394\n",
      "Generation 43/100, Best RMSE: 1.9913028762679394\n",
      "Generation 44/100, Best RMSE: 1.991302876267938\n",
      "Generation 45/100, Best RMSE: 1.9913028762671716\n",
      "Generation 46/100, Best RMSE: 1.9913028762670928\n",
      "Generation 47/100, Best RMSE: 1.9913028762670928\n",
      "Generation 48/100, Best RMSE: 1.9913028762670915\n",
      "Generation 49/100, Best RMSE: 1.9913028762669072\n",
      "Generation 50/100, Best RMSE: 1.9913028762668536\n",
      "Generation 51/100, Best RMSE: 1.9913028762668359\n",
      "Generation 52/100, Best RMSE: 1.9913028762667513\n",
      "Generation 53/100, Best RMSE: 1.9913028762666234\n",
      "Generation 54/100, Best RMSE: 1.991302876266535\n",
      "Generation 55/100, Best RMSE: 1.991302876266532\n",
      "Generation 56/100, Best RMSE: 1.9913028762664395\n",
      "Generation 57/100, Best RMSE: 1.9913028762664167\n",
      "Generation 58/100, Best RMSE: 1.9913028762664156\n",
      "Generation 59/100, Best RMSE: 1.9913028762664016\n",
      "Generation 60/100, Best RMSE: 1.9913028762663334\n",
      "Generation 61/100, Best RMSE: 1.9913028762663256\n",
      "Generation 62/100, Best RMSE: 1.991302876266317\n",
      "Generation 63/100, Best RMSE: 1.9913028762663076\n",
      "Generation 64/100, Best RMSE: 1.9913028762662928\n",
      "Generation 65/100, Best RMSE: 1.991302876266281\n",
      "Generation 66/100, Best RMSE: 1.9913028762662472\n",
      "Generation 67/100, Best RMSE: 1.9913028762662457\n",
      "Generation 68/100, Best RMSE: 1.9913028762662388\n",
      "Generation 69/100, Best RMSE: 1.9913028762662357\n",
      "Generation 70/100, Best RMSE: 1.9913028762662248\n",
      "Generation 71/100, Best RMSE: 1.991302876266215\n",
      "Generation 72/100, Best RMSE: 1.9913028762662066\n",
      "Generation 73/100, Best RMSE: 1.9913028762662066\n",
      "Generation 74/100, Best RMSE: 1.991302876266192\n",
      "Generation 75/100, Best RMSE: 1.9913028762661904\n",
      "Generation 76/100, Best RMSE: 1.9913028762661886\n",
      "Generation 77/100, Best RMSE: 1.9913028762661833\n",
      "Generation 78/100, Best RMSE: 1.9913028762661822\n",
      "Generation 79/100, Best RMSE: 1.9913028762661813\n",
      "Generation 80/100, Best RMSE: 1.9913028762661673\n",
      "Generation 81/100, Best RMSE: 1.9913028762661669\n",
      "Generation 82/100, Best RMSE: 1.991302876266164\n",
      "Generation 83/100, Best RMSE: 1.9913028762661624\n",
      "Generation 84/100, Best RMSE: 1.9913028762661615\n",
      "Generation 85/100, Best RMSE: 1.9913028762661584\n",
      "Generation 86/100, Best RMSE: 1.9913028762661569\n",
      "Generation 87/100, Best RMSE: 1.991302876266154\n",
      "Generation 88/100, Best RMSE: 1.9913028762661527\n",
      "Generation 89/100, Best RMSE: 1.9913028762661524\n",
      "Generation 90/100, Best RMSE: 1.9913028762661489\n",
      "Generation 91/100, Best RMSE: 1.9913028762661469\n",
      "Generation 92/100, Best RMSE: 1.991302876266146\n",
      "Generation 93/100, Best RMSE: 1.991302876266146\n",
      "Generation 94/100, Best RMSE: 1.9913028762661449\n",
      "Generation 95/100, Best RMSE: 1.9913028762661424\n",
      "Generation 96/100, Best RMSE: 1.991302876266142\n",
      "Generation 97/100, Best RMSE: 1.9913028762661389\n",
      "Generation 98/100, Best RMSE: 1.9913028762661389\n",
      "Generation 99/100, Best RMSE: 1.9913028762661376\n",
      "Generation 100/100, Best RMSE: 1.9913028762661376\n",
      "Optimal Weights: [0.45259968 0.02216514 0.30682226 0.         0.21841293]\n",
      "(16, 5, 48, 2) (16, 48, 2)\n",
      "Generation 1/100, Best RMSE: 2.5577290712802476\n",
      "Generation 2/100, Best RMSE: 2.5495803760326226\n",
      "Generation 3/100, Best RMSE: 2.5495803760326226\n",
      "Generation 4/100, Best RMSE: 2.5495803760326226\n",
      "Generation 5/100, Best RMSE: 2.548832017883402\n",
      "Generation 6/100, Best RMSE: 2.548832017883402\n",
      "Generation 7/100, Best RMSE: 2.548720386728976\n",
      "Generation 8/100, Best RMSE: 2.548720386728976\n",
      "Generation 9/100, Best RMSE: 2.548720386728976\n",
      "Generation 10/100, Best RMSE: 2.548667654549595\n",
      "Generation 11/100, Best RMSE: 2.54863527937241\n",
      "Generation 12/100, Best RMSE: 2.54863527937241\n",
      "Generation 13/100, Best RMSE: 2.54862350340711\n",
      "Generation 14/100, Best RMSE: 2.548616370015721\n",
      "Generation 15/100, Best RMSE: 2.548616370015721\n",
      "Generation 16/100, Best RMSE: 2.548610954110315\n",
      "Generation 17/100, Best RMSE: 2.548610954110315\n",
      "Generation 18/100, Best RMSE: 2.5486102661747116\n",
      "Generation 19/100, Best RMSE: 2.5486102491167237\n",
      "Generation 20/100, Best RMSE: 2.548609960380535\n",
      "Generation 21/100, Best RMSE: 2.5486095486278084\n",
      "Generation 22/100, Best RMSE: 2.5486093399009158\n",
      "Generation 23/100, Best RMSE: 2.548609070054669\n",
      "Generation 24/100, Best RMSE: 2.5486089313995297\n",
      "Generation 25/100, Best RMSE: 2.5486085582792994\n",
      "Generation 26/100, Best RMSE: 2.5486084797175614\n",
      "Generation 27/100, Best RMSE: 2.5486084797175614\n",
      "Generation 28/100, Best RMSE: 2.5486084458157827\n",
      "Generation 29/100, Best RMSE: 2.5486083049704344\n",
      "Generation 30/100, Best RMSE: 2.5486083049704344\n",
      "Generation 31/100, Best RMSE: 2.548608277653652\n",
      "Generation 32/100, Best RMSE: 2.5486082581252476\n",
      "Generation 33/100, Best RMSE: 2.5486081953756368\n",
      "Generation 34/100, Best RMSE: 2.5486081704391865\n",
      "Generation 35/100, Best RMSE: 2.54860814651417\n",
      "Generation 36/100, Best RMSE: 2.54860814651417\n",
      "Generation 37/100, Best RMSE: 2.5486081287553417\n",
      "Generation 38/100, Best RMSE: 2.54860811325857\n",
      "Generation 39/100, Best RMSE: 2.54860807510417\n",
      "Generation 40/100, Best RMSE: 2.5486080684252843\n",
      "Generation 41/100, Best RMSE: 2.548608047456944\n",
      "Generation 42/100, Best RMSE: 2.5486080319194966\n",
      "Generation 43/100, Best RMSE: 2.5486080319194966\n",
      "Generation 44/100, Best RMSE: 2.5486080319194966\n",
      "Generation 45/100, Best RMSE: 2.548608029875313\n",
      "Generation 46/100, Best RMSE: 2.5486080176457033\n",
      "Generation 47/100, Best RMSE: 2.5486080176457033\n",
      "Generation 48/100, Best RMSE: 2.548608014956989\n",
      "Generation 49/100, Best RMSE: 2.5486080144677614\n",
      "Generation 50/100, Best RMSE: 2.548608008431634\n",
      "Generation 51/100, Best RMSE: 2.548608007935756\n",
      "Generation 52/100, Best RMSE: 2.548608007740267\n",
      "Generation 53/100, Best RMSE: 2.5486080015826373\n",
      "Generation 54/100, Best RMSE: 2.5486079984144214\n",
      "Generation 55/100, Best RMSE: 2.5486079982128684\n",
      "Generation 56/100, Best RMSE: 2.5486079973102695\n",
      "Generation 57/100, Best RMSE: 2.5486079952154865\n",
      "Generation 58/100, Best RMSE: 2.5486079949864764\n",
      "Generation 59/100, Best RMSE: 2.548607993893309\n",
      "Generation 60/100, Best RMSE: 2.5486079915227684\n",
      "Generation 61/100, Best RMSE: 2.5486079887905153\n",
      "Generation 62/100, Best RMSE: 2.548607987993313\n",
      "Generation 63/100, Best RMSE: 2.5486079879783525\n",
      "Generation 64/100, Best RMSE: 2.548607987324025\n",
      "Generation 65/100, Best RMSE: 2.5486079830291706\n",
      "Generation 66/100, Best RMSE: 2.5486079830291706\n",
      "Generation 67/100, Best RMSE: 2.5486079830291706\n",
      "Generation 68/100, Best RMSE: 2.5486079823347807\n",
      "Generation 69/100, Best RMSE: 2.5486079823347807\n",
      "Generation 70/100, Best RMSE: 2.5486079821375953\n",
      "Generation 71/100, Best RMSE: 2.5486079805425597\n",
      "Generation 72/100, Best RMSE: 2.548607980097995\n",
      "Generation 73/100, Best RMSE: 2.5486079798094208\n",
      "Generation 74/100, Best RMSE: 2.54860797875229\n",
      "Generation 75/100, Best RMSE: 2.548607978725632\n",
      "Generation 76/100, Best RMSE: 2.548607978725632\n",
      "Generation 77/100, Best RMSE: 2.548607977830498\n",
      "Generation 78/100, Best RMSE: 2.548607977432158\n",
      "Generation 79/100, Best RMSE: 2.548607977432158\n",
      "Generation 80/100, Best RMSE: 2.548607977043111\n",
      "Generation 81/100, Best RMSE: 2.5486079768260055\n",
      "Generation 82/100, Best RMSE: 2.5486079768260055\n",
      "Generation 83/100, Best RMSE: 2.548607976506524\n",
      "Generation 84/100, Best RMSE: 2.548607976358784\n",
      "Generation 85/100, Best RMSE: 2.5486079761343206\n",
      "Generation 86/100, Best RMSE: 2.5486079761343206\n",
      "Generation 87/100, Best RMSE: 2.5486079758285856\n",
      "Generation 88/100, Best RMSE: 2.5486079757594755\n",
      "Generation 89/100, Best RMSE: 2.548607975686093\n",
      "Generation 90/100, Best RMSE: 2.548607975583178\n",
      "Generation 91/100, Best RMSE: 2.5486079753181237\n",
      "Generation 92/100, Best RMSE: 2.5486079753181237\n",
      "Generation 93/100, Best RMSE: 2.5486079752714517\n",
      "Generation 94/100, Best RMSE: 2.5486079751064583\n",
      "Generation 95/100, Best RMSE: 2.548607975106339\n",
      "Generation 96/100, Best RMSE: 2.5486079749817483\n",
      "Generation 97/100, Best RMSE: 2.548607974902853\n",
      "Generation 98/100, Best RMSE: 2.548607974865035\n",
      "Generation 99/100, Best RMSE: 2.548607974817235\n",
      "Generation 100/100, Best RMSE: 2.548607974791514\n",
      "Optimal Weights: [0.02991626 0.         0.50781986 0.         0.46226387]\n",
      "(16, 5, 48, 2) (16, 48, 2)\n",
      "Generation 1/100, Best RMSE: 2.4801269622695146\n",
      "Generation 2/100, Best RMSE: 2.4770763154592994\n",
      "Generation 3/100, Best RMSE: 2.4749435495617718\n",
      "Generation 4/100, Best RMSE: 2.471836515290301\n",
      "Generation 5/100, Best RMSE: 2.46988417098049\n",
      "Generation 6/100, Best RMSE: 2.4697523778573407\n",
      "Generation 7/100, Best RMSE: 2.467879010749939\n",
      "Generation 8/100, Best RMSE: 2.4671846077115154\n",
      "Generation 9/100, Best RMSE: 2.4666999398721\n",
      "Generation 10/100, Best RMSE: 2.4666999398721\n",
      "Generation 11/100, Best RMSE: 2.466622304621899\n",
      "Generation 12/100, Best RMSE: 2.466622304621899\n",
      "Generation 13/100, Best RMSE: 2.4662582072914745\n",
      "Generation 14/100, Best RMSE: 2.4662489938355234\n",
      "Generation 15/100, Best RMSE: 2.4662052836871866\n",
      "Generation 16/100, Best RMSE: 2.4662052836871866\n",
      "Generation 17/100, Best RMSE: 2.4661952451523153\n",
      "Generation 18/100, Best RMSE: 2.466193615930922\n",
      "Generation 19/100, Best RMSE: 2.4661929472603434\n",
      "Generation 20/100, Best RMSE: 2.4661924716496473\n",
      "Generation 21/100, Best RMSE: 2.4661924713769965\n",
      "Generation 22/100, Best RMSE: 2.4661924713769965\n",
      "Generation 23/100, Best RMSE: 2.4661924710767384\n",
      "Generation 24/100, Best RMSE: 2.466192316749873\n",
      "Generation 25/100, Best RMSE: 2.466192138913186\n",
      "Generation 26/100, Best RMSE: 2.466192127993994\n",
      "Generation 27/100, Best RMSE: 2.466192101453938\n",
      "Generation 28/100, Best RMSE: 2.466192093473832\n",
      "Generation 29/100, Best RMSE: 2.4661920912777218\n",
      "Generation 30/100, Best RMSE: 2.4661920905575174\n",
      "Generation 31/100, Best RMSE: 2.4661920559316544\n",
      "Generation 32/100, Best RMSE: 2.4661920553085994\n",
      "Generation 33/100, Best RMSE: 2.4661920553085994\n",
      "Generation 34/100, Best RMSE: 2.4661920385585034\n",
      "Generation 35/100, Best RMSE: 2.4661920324415236\n",
      "Generation 36/100, Best RMSE: 2.4661920248937648\n",
      "Generation 37/100, Best RMSE: 2.4661920202332857\n",
      "Generation 38/100, Best RMSE: 2.4661920091267917\n",
      "Generation 39/100, Best RMSE: 2.4661920070195973\n",
      "Generation 40/100, Best RMSE: 2.4661920005285007\n",
      "Generation 41/100, Best RMSE: 2.4661919901992113\n",
      "Generation 42/100, Best RMSE: 2.4661919823019933\n",
      "Generation 43/100, Best RMSE: 2.4661919823019933\n",
      "Generation 44/100, Best RMSE: 2.466191979272495\n",
      "Generation 45/100, Best RMSE: 2.4661919749943872\n",
      "Generation 46/100, Best RMSE: 2.4661919713520897\n",
      "Generation 47/100, Best RMSE: 2.4661919654278575\n",
      "Generation 48/100, Best RMSE: 2.4661919643173174\n",
      "Generation 49/100, Best RMSE: 2.466191959966457\n",
      "Generation 50/100, Best RMSE: 2.466191954814386\n",
      "Generation 51/100, Best RMSE: 2.466191954234377\n",
      "Generation 52/100, Best RMSE: 2.466191952497839\n",
      "Generation 53/100, Best RMSE: 2.466191949725551\n",
      "Generation 54/100, Best RMSE: 2.466191943673308\n",
      "Generation 55/100, Best RMSE: 2.4661919398886822\n",
      "Generation 56/100, Best RMSE: 2.466191938104981\n",
      "Generation 57/100, Best RMSE: 2.4661919340013734\n",
      "Generation 58/100, Best RMSE: 2.4661919269603123\n",
      "Generation 59/100, Best RMSE: 2.4661919266587065\n",
      "Generation 60/100, Best RMSE: 2.4661919266587065\n",
      "Generation 61/100, Best RMSE: 2.4661919226894677\n",
      "Generation 62/100, Best RMSE: 2.4661919223456237\n",
      "Generation 63/100, Best RMSE: 2.4661919219376056\n",
      "Generation 64/100, Best RMSE: 2.466191921211072\n",
      "Generation 65/100, Best RMSE: 2.4661919205923755\n",
      "Generation 66/100, Best RMSE: 2.466191920115385\n",
      "Generation 67/100, Best RMSE: 2.4661919193993773\n",
      "Generation 68/100, Best RMSE: 2.466191919103147\n",
      "Generation 69/100, Best RMSE: 2.466191918974536\n",
      "Generation 70/100, Best RMSE: 2.466191918392551\n",
      "Generation 71/100, Best RMSE: 2.466191918220307\n",
      "Generation 72/100, Best RMSE: 2.466191917416206\n",
      "Generation 73/100, Best RMSE: 2.4661919167520585\n",
      "Generation 74/100, Best RMSE: 2.4661919165239605\n",
      "Generation 75/100, Best RMSE: 2.466191916029766\n",
      "Generation 76/100, Best RMSE: 2.466191915902874\n",
      "Generation 77/100, Best RMSE: 2.4661919153529337\n",
      "Generation 78/100, Best RMSE: 2.466191914883942\n",
      "Generation 79/100, Best RMSE: 2.4661919146318505\n",
      "Generation 80/100, Best RMSE: 2.4661919145259183\n",
      "Generation 81/100, Best RMSE: 2.466191914271916\n",
      "Generation 82/100, Best RMSE: 2.466191913853812\n",
      "Generation 83/100, Best RMSE: 2.4661919135729633\n",
      "Generation 84/100, Best RMSE: 2.4661919130886285\n",
      "Generation 85/100, Best RMSE: 2.466191912786159\n",
      "Generation 86/100, Best RMSE: 2.4661919127437546\n",
      "Generation 87/100, Best RMSE: 2.466191912735989\n",
      "Generation 88/100, Best RMSE: 2.4661919124156686\n",
      "Generation 89/100, Best RMSE: 2.466191912339401\n",
      "Generation 90/100, Best RMSE: 2.4661919119543243\n",
      "Generation 91/100, Best RMSE: 2.466191911694548\n",
      "Generation 92/100, Best RMSE: 2.466191911458736\n",
      "Generation 93/100, Best RMSE: 2.466191911295089\n",
      "Generation 94/100, Best RMSE: 2.466191911252744\n",
      "Generation 95/100, Best RMSE: 2.4661919111432047\n",
      "Generation 96/100, Best RMSE: 2.466191910942038\n",
      "Generation 97/100, Best RMSE: 2.4661919109279222\n",
      "Generation 98/100, Best RMSE: 2.46619191077991\n",
      "Generation 99/100, Best RMSE: 2.466191910676428\n",
      "Generation 100/100, Best RMSE: 2.4661919105190506\n",
      "Optimal Weights: [0.11257954 0.         0.         0.30544933 0.58197113]\n",
      "(27, 5, 48, 2) (27, 48, 2)\n",
      "Generation 1/100, Best RMSE: 2.6639561885931715\n",
      "Generation 2/100, Best RMSE: 2.6617258325924733\n",
      "Generation 3/100, Best RMSE: 2.656579823050835\n",
      "Generation 4/100, Best RMSE: 2.6536528643871438\n",
      "Generation 5/100, Best RMSE: 2.6531292119875363\n",
      "Generation 6/100, Best RMSE: 2.652757268771032\n",
      "Generation 7/100, Best RMSE: 2.652757268771032\n",
      "Generation 8/100, Best RMSE: 2.6512863683768058\n",
      "Generation 9/100, Best RMSE: 2.6512863683768058\n",
      "Generation 10/100, Best RMSE: 2.6512863683768058\n",
      "Generation 11/100, Best RMSE: 2.6512190880302984\n",
      "Generation 12/100, Best RMSE: 2.651067480074951\n",
      "Generation 13/100, Best RMSE: 2.6510667857715444\n",
      "Generation 14/100, Best RMSE: 2.6510030208899185\n",
      "Generation 15/100, Best RMSE: 2.6510014430028077\n",
      "Generation 16/100, Best RMSE: 2.6509936582359748\n",
      "Generation 17/100, Best RMSE: 2.6509760192090503\n",
      "Generation 18/100, Best RMSE: 2.6509687368390615\n",
      "Generation 19/100, Best RMSE: 2.65096577539653\n",
      "Generation 20/100, Best RMSE: 2.650956709667063\n",
      "Generation 21/100, Best RMSE: 2.6509537138377164\n",
      "Generation 22/100, Best RMSE: 2.650950400143772\n",
      "Generation 23/100, Best RMSE: 2.6509494011803345\n",
      "Generation 24/100, Best RMSE: 2.6509494011803345\n",
      "Generation 25/100, Best RMSE: 2.6509494011803345\n",
      "Generation 26/100, Best RMSE: 2.650949315597581\n",
      "Generation 27/100, Best RMSE: 2.650949315597581\n",
      "Generation 28/100, Best RMSE: 2.650949315597581\n",
      "Generation 29/100, Best RMSE: 2.6509490616945244\n",
      "Generation 30/100, Best RMSE: 2.650948699612491\n",
      "Generation 31/100, Best RMSE: 2.650948699612491\n",
      "Generation 32/100, Best RMSE: 2.6509486854090674\n",
      "Generation 33/100, Best RMSE: 2.6509486328535625\n",
      "Generation 34/100, Best RMSE: 2.6509485892054574\n",
      "Generation 35/100, Best RMSE: 2.6509485892054574\n",
      "Generation 36/100, Best RMSE: 2.6509485853544055\n",
      "Generation 37/100, Best RMSE: 2.6509485333953586\n",
      "Generation 38/100, Best RMSE: 2.6509485333953586\n",
      "Generation 39/100, Best RMSE: 2.6509485313450503\n",
      "Generation 40/100, Best RMSE: 2.6509485241839728\n",
      "Generation 41/100, Best RMSE: 2.650948519506804\n",
      "Generation 42/100, Best RMSE: 2.650948519506804\n",
      "Generation 43/100, Best RMSE: 2.6509484901486426\n",
      "Generation 44/100, Best RMSE: 2.6509484901486426\n",
      "Generation 45/100, Best RMSE: 2.6509484901486426\n",
      "Generation 46/100, Best RMSE: 2.6509484901486426\n",
      "Generation 47/100, Best RMSE: 2.650948481205658\n",
      "Generation 48/100, Best RMSE: 2.650948481205658\n",
      "Generation 49/100, Best RMSE: 2.65094848104169\n",
      "Generation 50/100, Best RMSE: 2.6509484769531313\n",
      "Generation 51/100, Best RMSE: 2.650948472930289\n",
      "Generation 52/100, Best RMSE: 2.6509484689197653\n",
      "Generation 53/100, Best RMSE: 2.650948468147836\n",
      "Generation 54/100, Best RMSE: 2.6509484653859943\n",
      "Generation 55/100, Best RMSE: 2.6509484642073944\n",
      "Generation 56/100, Best RMSE: 2.650948460942945\n",
      "Generation 57/100, Best RMSE: 2.650948459403629\n",
      "Generation 58/100, Best RMSE: 2.6509484551268723\n",
      "Generation 59/100, Best RMSE: 2.6509484503004708\n",
      "Generation 60/100, Best RMSE: 2.650948449951029\n",
      "Generation 61/100, Best RMSE: 2.650948449951029\n",
      "Generation 62/100, Best RMSE: 2.6509484482227563\n",
      "Generation 63/100, Best RMSE: 2.650948447534252\n",
      "Generation 64/100, Best RMSE: 2.650948447534252\n",
      "Generation 65/100, Best RMSE: 2.6509484442364175\n",
      "Generation 66/100, Best RMSE: 2.650948444134526\n",
      "Generation 67/100, Best RMSE: 2.6509484434891446\n",
      "Generation 68/100, Best RMSE: 2.6509484434891446\n",
      "Generation 69/100, Best RMSE: 2.6509484434891446\n",
      "Generation 70/100, Best RMSE: 2.6509484429077084\n",
      "Generation 71/100, Best RMSE: 2.6509484429077084\n",
      "Generation 72/100, Best RMSE: 2.6509484427546104\n",
      "Generation 73/100, Best RMSE: 2.650948442145658\n",
      "Generation 74/100, Best RMSE: 2.6509484417237\n",
      "Generation 75/100, Best RMSE: 2.6509484417237\n",
      "Generation 76/100, Best RMSE: 2.6509484417237\n",
      "Generation 77/100, Best RMSE: 2.6509484415746782\n",
      "Generation 78/100, Best RMSE: 2.6509484413008075\n",
      "Generation 79/100, Best RMSE: 2.650948440992276\n",
      "Generation 80/100, Best RMSE: 2.6509484405848984\n",
      "Generation 81/100, Best RMSE: 2.650948440124131\n",
      "Generation 82/100, Best RMSE: 2.650948440066633\n",
      "Generation 83/100, Best RMSE: 2.6509484399105028\n",
      "Generation 84/100, Best RMSE: 2.6509484398363155\n",
      "Generation 85/100, Best RMSE: 2.6509484397681695\n",
      "Generation 86/100, Best RMSE: 2.650948439511138\n",
      "Generation 87/100, Best RMSE: 2.650948439511138\n",
      "Generation 88/100, Best RMSE: 2.650948439511138\n",
      "Generation 89/100, Best RMSE: 2.6509484392811675\n",
      "Generation 90/100, Best RMSE: 2.6509484392811675\n",
      "Generation 91/100, Best RMSE: 2.6509484392811675\n",
      "Generation 92/100, Best RMSE: 2.650948439214319\n",
      "Generation 93/100, Best RMSE: 2.650948439214319\n",
      "Generation 94/100, Best RMSE: 2.650948439214319\n",
      "Generation 95/100, Best RMSE: 2.6509484392068914\n",
      "Generation 96/100, Best RMSE: 2.6509484391092113\n",
      "Generation 97/100, Best RMSE: 2.6509484391092113\n",
      "Generation 98/100, Best RMSE: 2.6509484391092113\n",
      "Generation 99/100, Best RMSE: 2.6509484390532663\n",
      "Generation 100/100, Best RMSE: 2.6509484390405733\n",
      "Optimal Weights: [0.         0.19879487 0.05556217 0.21745841 0.52818455]\n",
      "(31, 5, 48, 2) (31, 48, 2)\n",
      "Generation 1/100, Best RMSE: 2.538221097389674\n",
      "Generation 2/100, Best RMSE: 2.538221097389674\n",
      "Generation 3/100, Best RMSE: 2.533866427798325\n",
      "Generation 4/100, Best RMSE: 2.533866427798325\n",
      "Generation 5/100, Best RMSE: 2.5334072417871534\n",
      "Generation 6/100, Best RMSE: 2.53325621164058\n",
      "Generation 7/100, Best RMSE: 2.5325417573081053\n",
      "Generation 8/100, Best RMSE: 2.5324015121750563\n",
      "Generation 9/100, Best RMSE: 2.5320621394458342\n",
      "Generation 10/100, Best RMSE: 2.5320621394458342\n",
      "Generation 11/100, Best RMSE: 2.531842628805149\n",
      "Generation 12/100, Best RMSE: 2.5316589153357\n",
      "Generation 13/100, Best RMSE: 2.531606901676391\n",
      "Generation 14/100, Best RMSE: 2.531323830158278\n",
      "Generation 15/100, Best RMSE: 2.531319770025233\n",
      "Generation 16/100, Best RMSE: 2.5313189932794544\n",
      "Generation 17/100, Best RMSE: 2.5313177958410065\n",
      "Generation 18/100, Best RMSE: 2.5313177958410065\n",
      "Generation 19/100, Best RMSE: 2.5313177808793834\n",
      "Generation 20/100, Best RMSE: 2.5313174358858666\n",
      "Generation 21/100, Best RMSE: 2.5313173825194313\n",
      "Generation 22/100, Best RMSE: 2.5313173594229896\n",
      "Generation 23/100, Best RMSE: 2.5313173594229896\n",
      "Generation 24/100, Best RMSE: 2.5313173534043436\n",
      "Generation 25/100, Best RMSE: 2.5313173532485824\n",
      "Generation 26/100, Best RMSE: 2.5313173532485824\n",
      "Generation 27/100, Best RMSE: 2.5313173531975024\n",
      "Generation 28/100, Best RMSE: 2.5313173529415716\n",
      "Generation 29/100, Best RMSE: 2.5313173529324815\n",
      "Generation 30/100, Best RMSE: 2.531317352924039\n",
      "Generation 31/100, Best RMSE: 2.531317352924039\n",
      "Generation 32/100, Best RMSE: 2.531317352924039\n",
      "Generation 33/100, Best RMSE: 2.531317352923252\n",
      "Generation 34/100, Best RMSE: 2.531317352923252\n",
      "Generation 35/100, Best RMSE: 2.5313173529230335\n",
      "Generation 36/100, Best RMSE: 2.5313173529230175\n",
      "Generation 37/100, Best RMSE: 2.531317352923009\n",
      "Generation 38/100, Best RMSE: 2.531317352923009\n",
      "Generation 39/100, Best RMSE: 2.531317352923009\n",
      "Generation 40/100, Best RMSE: 2.531317352923009\n",
      "Generation 41/100, Best RMSE: 2.531317352923008\n",
      "Generation 42/100, Best RMSE: 2.531317352923008\n",
      "Generation 43/100, Best RMSE: 2.531317352923008\n",
      "Generation 44/100, Best RMSE: 2.531317352923008\n",
      "Generation 45/100, Best RMSE: 2.531317352923008\n",
      "Generation 46/100, Best RMSE: 2.531317352923008\n",
      "Generation 47/100, Best RMSE: 2.531317352923008\n",
      "Generation 48/100, Best RMSE: 2.531317352923008\n",
      "Generation 49/100, Best RMSE: 2.531317352923008\n",
      "Generation 50/100, Best RMSE: 2.531317352923008\n",
      "Generation 51/100, Best RMSE: 2.531317352923008\n",
      "Generation 52/100, Best RMSE: 2.531317352923008\n",
      "Generation 53/100, Best RMSE: 2.531317352923008\n",
      "Generation 54/100, Best RMSE: 2.5313173529230077\n",
      "Generation 55/100, Best RMSE: 2.5313173529230077\n",
      "Generation 56/100, Best RMSE: 2.5313173529230077\n",
      "Generation 57/100, Best RMSE: 2.5313173529230077\n",
      "Generation 58/100, Best RMSE: 2.5313173529230077\n",
      "Generation 59/100, Best RMSE: 2.5313173529230077\n",
      "Generation 60/100, Best RMSE: 2.5313173529230077\n",
      "Generation 61/100, Best RMSE: 2.5313173529230077\n",
      "Generation 62/100, Best RMSE: 2.5313173529230077\n",
      "Generation 63/100, Best RMSE: 2.5313173529230077\n",
      "Generation 64/100, Best RMSE: 2.5313173529230077\n",
      "Generation 65/100, Best RMSE: 2.5313173529230077\n",
      "Generation 66/100, Best RMSE: 2.5313173529230077\n",
      "Generation 67/100, Best RMSE: 2.5313173529230077\n",
      "Generation 68/100, Best RMSE: 2.5313173529230077\n",
      "Generation 69/100, Best RMSE: 2.5313173529230077\n",
      "Generation 70/100, Best RMSE: 2.5313173529230077\n",
      "Generation 71/100, Best RMSE: 2.5313173529230077\n",
      "Generation 72/100, Best RMSE: 2.5313173529230077\n",
      "Generation 73/100, Best RMSE: 2.5313173529230077\n",
      "Generation 74/100, Best RMSE: 2.5313173529230077\n",
      "Generation 75/100, Best RMSE: 2.5313173529230077\n",
      "Generation 76/100, Best RMSE: 2.5313173529230077\n",
      "Generation 77/100, Best RMSE: 2.5313173529230077\n",
      "Generation 78/100, Best RMSE: 2.5313173529230077\n",
      "Generation 79/100, Best RMSE: 2.5313173529230077\n",
      "Generation 80/100, Best RMSE: 2.5313173529230077\n",
      "Generation 81/100, Best RMSE: 2.5313173529230077\n",
      "Generation 82/100, Best RMSE: 2.5313173529230077\n",
      "Generation 83/100, Best RMSE: 2.5313173529230077\n",
      "Generation 84/100, Best RMSE: 2.5313173529230077\n",
      "Generation 85/100, Best RMSE: 2.5313173529230077\n",
      "Generation 86/100, Best RMSE: 2.5313173529230077\n",
      "Generation 87/100, Best RMSE: 2.5313173529230077\n",
      "Generation 88/100, Best RMSE: 2.5313173529230077\n",
      "Generation 89/100, Best RMSE: 2.5313173529230077\n",
      "Generation 90/100, Best RMSE: 2.5313173529230077\n",
      "Generation 91/100, Best RMSE: 2.5313173529230077\n",
      "Generation 92/100, Best RMSE: 2.5313173529230077\n",
      "Generation 93/100, Best RMSE: 2.5313173529230077\n",
      "Generation 94/100, Best RMSE: 2.5313173529230077\n",
      "Generation 95/100, Best RMSE: 2.5313173529230077\n",
      "Generation 96/100, Best RMSE: 2.5313173529230077\n",
      "Generation 97/100, Best RMSE: 2.5313173529230077\n",
      "Generation 98/100, Best RMSE: 2.5313173529230077\n",
      "Generation 99/100, Best RMSE: 2.5313173529230077\n",
      "Generation 100/100, Best RMSE: 2.5313173529230077\n",
      "Optimal Weights: [0.3674709  0.         0.10396985 0.         0.52855925]\n",
      "(24, 5, 48, 2) (24, 48, 2)\n",
      "Generation 1/100, Best RMSE: 2.692405804689651\n",
      "Generation 2/100, Best RMSE: 2.692405804689651\n",
      "Generation 3/100, Best RMSE: 2.6808044006940097\n",
      "Generation 4/100, Best RMSE: 2.6808044006940097\n",
      "Generation 5/100, Best RMSE: 2.677754842861866\n",
      "Generation 6/100, Best RMSE: 2.6774259485872522\n",
      "Generation 7/100, Best RMSE: 2.6773869936732275\n",
      "Generation 8/100, Best RMSE: 2.6773869936732275\n",
      "Generation 9/100, Best RMSE: 2.6773869936732275\n",
      "Generation 10/100, Best RMSE: 2.6773755328686253\n",
      "Generation 11/100, Best RMSE: 2.6773686167021475\n",
      "Generation 12/100, Best RMSE: 2.6773664473302254\n",
      "Generation 13/100, Best RMSE: 2.677366194227811\n",
      "Generation 14/100, Best RMSE: 2.677366194227811\n",
      "Generation 15/100, Best RMSE: 2.677365941809802\n",
      "Generation 16/100, Best RMSE: 2.677365924358064\n",
      "Generation 17/100, Best RMSE: 2.6773659019776677\n",
      "Generation 18/100, Best RMSE: 2.6773659019776677\n",
      "Generation 19/100, Best RMSE: 2.677365870032346\n",
      "Generation 20/100, Best RMSE: 2.677365870032346\n",
      "Generation 21/100, Best RMSE: 2.677365870032346\n",
      "Generation 22/100, Best RMSE: 2.677365870032346\n",
      "Generation 23/100, Best RMSE: 2.677365856427572\n",
      "Generation 24/100, Best RMSE: 2.677365856427572\n",
      "Generation 25/100, Best RMSE: 2.677365856427572\n",
      "Generation 26/100, Best RMSE: 2.677365850460105\n",
      "Generation 27/100, Best RMSE: 2.677365850460105\n",
      "Generation 28/100, Best RMSE: 2.6773658493786616\n",
      "Generation 29/100, Best RMSE: 2.677365849151822\n",
      "Generation 30/100, Best RMSE: 2.677365848426432\n",
      "Generation 31/100, Best RMSE: 2.677365847959551\n",
      "Generation 32/100, Best RMSE: 2.6773658479253877\n",
      "Generation 33/100, Best RMSE: 2.6773658479253877\n",
      "Generation 34/100, Best RMSE: 2.6773658472544777\n",
      "Generation 35/100, Best RMSE: 2.6773658472528084\n",
      "Generation 36/100, Best RMSE: 2.677365847244919\n",
      "Generation 37/100, Best RMSE: 2.677365846925927\n",
      "Generation 38/100, Best RMSE: 2.677365846847724\n",
      "Generation 39/100, Best RMSE: 2.6773658468300234\n",
      "Generation 40/100, Best RMSE: 2.6773658467159143\n",
      "Generation 41/100, Best RMSE: 2.6773658466649066\n",
      "Generation 42/100, Best RMSE: 2.6773658465927457\n",
      "Generation 43/100, Best RMSE: 2.677365846499198\n",
      "Generation 44/100, Best RMSE: 2.6773658464982466\n",
      "Generation 45/100, Best RMSE: 2.677365846425543\n",
      "Generation 46/100, Best RMSE: 2.677365846425543\n",
      "Generation 47/100, Best RMSE: 2.6773658463659182\n",
      "Generation 48/100, Best RMSE: 2.6773658463659182\n",
      "Generation 49/100, Best RMSE: 2.6773658463260332\n",
      "Generation 50/100, Best RMSE: 2.6773658463253023\n",
      "Generation 51/100, Best RMSE: 2.677365846295771\n",
      "Generation 52/100, Best RMSE: 2.677365846295771\n",
      "Generation 53/100, Best RMSE: 2.677365846290179\n",
      "Generation 54/100, Best RMSE: 2.6773658462891605\n",
      "Generation 55/100, Best RMSE: 2.677365846282625\n",
      "Generation 56/100, Best RMSE: 2.6773658462707575\n",
      "Generation 57/100, Best RMSE: 2.6773658462679775\n",
      "Generation 58/100, Best RMSE: 2.6773658462623513\n",
      "Generation 59/100, Best RMSE: 2.6773658462504613\n",
      "Generation 60/100, Best RMSE: 2.6773658462493923\n",
      "Generation 61/100, Best RMSE: 2.6773658462416323\n",
      "Generation 62/100, Best RMSE: 2.6773658462415586\n",
      "Generation 63/100, Best RMSE: 2.677365846241474\n",
      "Generation 64/100, Best RMSE: 2.677365846238413\n",
      "Generation 65/100, Best RMSE: 2.6773658462378815\n",
      "Generation 66/100, Best RMSE: 2.6773658462372154\n",
      "Generation 67/100, Best RMSE: 2.6773658462364622\n",
      "Generation 68/100, Best RMSE: 2.6773658462352636\n",
      "Generation 69/100, Best RMSE: 2.67736584623339\n",
      "Generation 70/100, Best RMSE: 2.67736584623255\n",
      "Generation 71/100, Best RMSE: 2.6773658462325307\n",
      "Generation 72/100, Best RMSE: 2.677365846232023\n",
      "Generation 73/100, Best RMSE: 2.6773658462314276\n",
      "Generation 74/100, Best RMSE: 2.677365846231033\n",
      "Generation 75/100, Best RMSE: 2.6773658462302676\n",
      "Generation 76/100, Best RMSE: 2.6773658462302676\n",
      "Generation 77/100, Best RMSE: 2.6773658462302676\n",
      "Generation 78/100, Best RMSE: 2.6773658462302676\n",
      "Generation 79/100, Best RMSE: 2.6773658462300087\n",
      "Generation 80/100, Best RMSE: 2.677365846229989\n",
      "Generation 81/100, Best RMSE: 2.6773658462298537\n",
      "Generation 82/100, Best RMSE: 2.6773658462298537\n",
      "Generation 83/100, Best RMSE: 2.6773658462296925\n",
      "Generation 84/100, Best RMSE: 2.6773658462296925\n",
      "Generation 85/100, Best RMSE: 2.677365846229688\n",
      "Generation 86/100, Best RMSE: 2.677365846229637\n",
      "Generation 87/100, Best RMSE: 2.6773658462294243\n",
      "Generation 88/100, Best RMSE: 2.6773658462294225\n",
      "Generation 89/100, Best RMSE: 2.677365846229412\n",
      "Generation 90/100, Best RMSE: 2.67736584622935\n",
      "Generation 91/100, Best RMSE: 2.67736584622935\n",
      "Generation 92/100, Best RMSE: 2.6773658462293413\n",
      "Generation 93/100, Best RMSE: 2.6773658462293306\n",
      "Generation 94/100, Best RMSE: 2.6773658462293115\n",
      "Generation 95/100, Best RMSE: 2.6773658462293066\n",
      "Generation 96/100, Best RMSE: 2.6773658462292937\n",
      "Generation 97/100, Best RMSE: 2.67736584622929\n",
      "Generation 98/100, Best RMSE: 2.6773658462292698\n",
      "Generation 99/100, Best RMSE: 2.6773658462292658\n",
      "Generation 100/100, Best RMSE: 2.677365846229264\n",
      "Optimal Weights: [0.64270542 0.06810121 0.         0.         0.28919337]\n",
      "(25, 5, 48, 2) (25, 48, 2)\n",
      "Generation 1/100, Best RMSE: 2.475999674318466\n",
      "Generation 2/100, Best RMSE: 2.4285330644744145\n",
      "Generation 3/100, Best RMSE: 2.4285330644744145\n",
      "Generation 4/100, Best RMSE: 2.4285330644744145\n",
      "Generation 5/100, Best RMSE: 2.410943776952027\n",
      "Generation 6/100, Best RMSE: 2.402265361172251\n",
      "Generation 7/100, Best RMSE: 2.389302479487173\n",
      "Generation 8/100, Best RMSE: 2.389302479487173\n",
      "Generation 9/100, Best RMSE: 2.389302479487173\n",
      "Generation 10/100, Best RMSE: 2.3877901539013267\n",
      "Generation 11/100, Best RMSE: 2.3877901539013267\n",
      "Generation 12/100, Best RMSE: 2.3877901539013267\n",
      "Generation 13/100, Best RMSE: 2.3877901539013267\n",
      "Generation 14/100, Best RMSE: 2.3877901539013267\n",
      "Generation 15/100, Best RMSE: 2.3877872743369983\n",
      "Generation 16/100, Best RMSE: 2.3877872743369983\n",
      "Generation 17/100, Best RMSE: 2.38777286402861\n",
      "Generation 18/100, Best RMSE: 2.387759664704638\n",
      "Generation 19/100, Best RMSE: 2.3877475643971846\n",
      "Generation 20/100, Best RMSE: 2.387736463156062\n",
      "Generation 21/100, Best RMSE: 2.387736463156062\n",
      "Generation 22/100, Best RMSE: 2.387736463156062\n",
      "Generation 23/100, Best RMSE: 2.387736463156062\n",
      "Generation 24/100, Best RMSE: 2.387736463156062\n",
      "Generation 25/100, Best RMSE: 2.387736463156062\n",
      "Generation 26/100, Best RMSE: 2.387736463156062\n",
      "Generation 27/100, Best RMSE: 2.387736463156062\n",
      "Generation 28/100, Best RMSE: 2.387736463156062\n",
      "Generation 29/100, Best RMSE: 2.387736463156062\n",
      "Generation 30/100, Best RMSE: 2.387736463156062\n",
      "Generation 31/100, Best RMSE: 2.387736463156062\n",
      "Generation 32/100, Best RMSE: 2.387736463156062\n",
      "Generation 33/100, Best RMSE: 2.387736463156062\n",
      "Generation 34/100, Best RMSE: 2.387736463156062\n",
      "Generation 35/100, Best RMSE: 2.387736463156062\n",
      "Generation 36/100, Best RMSE: 2.387736463156062\n",
      "Generation 37/100, Best RMSE: 2.387736463156062\n",
      "Generation 38/100, Best RMSE: 2.3876421124302887\n",
      "Generation 39/100, Best RMSE: 2.3876421124302887\n",
      "Generation 40/100, Best RMSE: 2.3876421124302887\n",
      "Generation 41/100, Best RMSE: 2.3876421124302887\n",
      "Generation 42/100, Best RMSE: 2.3876421124302887\n",
      "Generation 43/100, Best RMSE: 2.3876421124302887\n",
      "Generation 44/100, Best RMSE: 2.3876421124302887\n",
      "Generation 45/100, Best RMSE: 2.3876421124302887\n",
      "Generation 46/100, Best RMSE: 2.3876421124302887\n",
      "Generation 47/100, Best RMSE: 2.3876421124302887\n",
      "Generation 48/100, Best RMSE: 2.3876421124302887\n",
      "Generation 49/100, Best RMSE: 2.3876421124302887\n",
      "Generation 50/100, Best RMSE: 2.3876421124302887\n",
      "Generation 51/100, Best RMSE: 2.3876421124302887\n",
      "Generation 52/100, Best RMSE: 2.3876421124302887\n",
      "Generation 53/100, Best RMSE: 2.3876421124302887\n",
      "Generation 54/100, Best RMSE: 2.3876421124302887\n",
      "Generation 55/100, Best RMSE: 2.3876421124302887\n",
      "Generation 56/100, Best RMSE: 2.3876421124302887\n",
      "Generation 57/100, Best RMSE: 2.3876421124302887\n",
      "Generation 58/100, Best RMSE: 2.3876421124302887\n",
      "Generation 59/100, Best RMSE: 2.3876421124302887\n",
      "Generation 60/100, Best RMSE: 2.3876421124302887\n",
      "Generation 61/100, Best RMSE: 2.3876421124302887\n",
      "Generation 62/100, Best RMSE: 2.3876421124302887\n",
      "Generation 63/100, Best RMSE: 2.3876421124302887\n",
      "Generation 64/100, Best RMSE: 2.3876421124302887\n",
      "Generation 65/100, Best RMSE: 2.3876421124302887\n",
      "Generation 66/100, Best RMSE: 2.3876421124302882\n",
      "Generation 67/100, Best RMSE: 2.3876421124302882\n",
      "Generation 68/100, Best RMSE: 2.3876421124302882\n",
      "Generation 69/100, Best RMSE: 2.3876421124302882\n",
      "Generation 70/100, Best RMSE: 2.3876421124302882\n",
      "Generation 71/100, Best RMSE: 2.3876421124302882\n",
      "Generation 72/100, Best RMSE: 2.3876421124302882\n",
      "Generation 73/100, Best RMSE: 2.3876421124302882\n",
      "Generation 74/100, Best RMSE: 2.3876421124302882\n",
      "Generation 75/100, Best RMSE: 2.3876421124302882\n",
      "Generation 76/100, Best RMSE: 2.3876421124302882\n",
      "Generation 77/100, Best RMSE: 2.3876421124302882\n",
      "Generation 78/100, Best RMSE: 2.3876421124302882\n",
      "Generation 79/100, Best RMSE: 2.3876421124302882\n",
      "Generation 80/100, Best RMSE: 2.3876421124302882\n",
      "Generation 81/100, Best RMSE: 2.3876421124302882\n",
      "Generation 82/100, Best RMSE: 2.3876421124302882\n",
      "Generation 83/100, Best RMSE: 2.3876421124302882\n",
      "Generation 84/100, Best RMSE: 2.3876421124302882\n",
      "Generation 85/100, Best RMSE: 2.3876421124302882\n",
      "Generation 86/100, Best RMSE: 2.3876421124302882\n",
      "Generation 87/100, Best RMSE: 2.3876421124302882\n",
      "Generation 88/100, Best RMSE: 2.3876421124302882\n",
      "Generation 89/100, Best RMSE: 2.3876421124302882\n",
      "Generation 90/100, Best RMSE: 2.3876421124302882\n",
      "Generation 91/100, Best RMSE: 2.3876421124302882\n",
      "Generation 92/100, Best RMSE: 2.3876421124302882\n",
      "Generation 93/100, Best RMSE: 2.3876421124302882\n",
      "Generation 94/100, Best RMSE: 2.3876421124302882\n",
      "Generation 95/100, Best RMSE: 2.3876421124302882\n",
      "Generation 96/100, Best RMSE: 2.3876421124302882\n",
      "Generation 97/100, Best RMSE: 2.3876421124302882\n",
      "Generation 98/100, Best RMSE: 2.3876421124302882\n",
      "Generation 99/100, Best RMSE: 2.3876421124302882\n",
      "Generation 100/100, Best RMSE: 2.3876421124302882\n",
      "Optimal Weights: [0.01527766 0.         0.         0.         0.98472234]\n",
      "(28, 5, 48, 2) (28, 48, 2)\n",
      "Generation 1/100, Best RMSE: 2.423599796620295\n",
      "Generation 2/100, Best RMSE: 2.423599796620295\n",
      "Generation 3/100, Best RMSE: 2.423599796620295\n",
      "Generation 4/100, Best RMSE: 2.423005734473843\n",
      "Generation 5/100, Best RMSE: 2.423005734473843\n",
      "Generation 6/100, Best RMSE: 2.4214115364927933\n",
      "Generation 7/100, Best RMSE: 2.421296010907467\n",
      "Generation 8/100, Best RMSE: 2.4202002728348733\n",
      "Generation 9/100, Best RMSE: 2.419707621240856\n",
      "Generation 10/100, Best RMSE: 2.419386875704292\n",
      "Generation 11/100, Best RMSE: 2.4193824165284523\n",
      "Generation 12/100, Best RMSE: 2.4193774871250535\n",
      "Generation 13/100, Best RMSE: 2.4193774871250535\n",
      "Generation 14/100, Best RMSE: 2.419373354388223\n",
      "Generation 15/100, Best RMSE: 2.419371912625763\n",
      "Generation 16/100, Best RMSE: 2.419371912625763\n",
      "Generation 17/100, Best RMSE: 2.4193718038845367\n",
      "Generation 18/100, Best RMSE: 2.4193715595865224\n",
      "Generation 19/100, Best RMSE: 2.4193715595865224\n",
      "Generation 20/100, Best RMSE: 2.4193715595865224\n",
      "Generation 21/100, Best RMSE: 2.419371428761433\n",
      "Generation 22/100, Best RMSE: 2.419371428761433\n",
      "Generation 23/100, Best RMSE: 2.419371428761433\n",
      "Generation 24/100, Best RMSE: 2.4193714149106973\n",
      "Generation 25/100, Best RMSE: 2.419371412310468\n",
      "Generation 26/100, Best RMSE: 2.419371412310468\n",
      "Generation 27/100, Best RMSE: 2.4193714117455056\n",
      "Generation 28/100, Best RMSE: 2.419371411693419\n",
      "Generation 29/100, Best RMSE: 2.4193714103387682\n",
      "Generation 30/100, Best RMSE: 2.41937140845863\n",
      "Generation 31/100, Best RMSE: 2.41937140845863\n",
      "Generation 32/100, Best RMSE: 2.419371408100425\n",
      "Generation 33/100, Best RMSE: 2.419371408100425\n",
      "Generation 34/100, Best RMSE: 2.419371408100425\n",
      "Generation 35/100, Best RMSE: 2.4193714080174376\n",
      "Generation 36/100, Best RMSE: 2.4193714076617923\n",
      "Generation 37/100, Best RMSE: 2.4193714076617923\n",
      "Generation 38/100, Best RMSE: 2.4193714075462203\n",
      "Generation 39/100, Best RMSE: 2.4193714075462203\n",
      "Generation 40/100, Best RMSE: 2.4193714074761488\n",
      "Generation 41/100, Best RMSE: 2.4193714074723554\n",
      "Generation 42/100, Best RMSE: 2.419371407452133\n",
      "Generation 43/100, Best RMSE: 2.4193714073546437\n",
      "Generation 44/100, Best RMSE: 2.4193714073546437\n",
      "Generation 45/100, Best RMSE: 2.4193714073229238\n",
      "Generation 46/100, Best RMSE: 2.419371407320913\n",
      "Generation 47/100, Best RMSE: 2.419371407306648\n",
      "Generation 48/100, Best RMSE: 2.4193714072820893\n",
      "Generation 49/100, Best RMSE: 2.4193714072601757\n",
      "Generation 50/100, Best RMSE: 2.4193714072601757\n",
      "Generation 51/100, Best RMSE: 2.4193714072362122\n",
      "Generation 52/100, Best RMSE: 2.4193714072294936\n",
      "Generation 53/100, Best RMSE: 2.4193714072094434\n",
      "Generation 54/100, Best RMSE: 2.419371407202678\n",
      "Generation 55/100, Best RMSE: 2.41937140719381\n",
      "Generation 56/100, Best RMSE: 2.4193714071794563\n",
      "Generation 57/100, Best RMSE: 2.4193714071734314\n",
      "Generation 58/100, Best RMSE: 2.4193714071661905\n",
      "Generation 59/100, Best RMSE: 2.4193714071661905\n",
      "Generation 60/100, Best RMSE: 2.4193714071616066\n",
      "Generation 61/100, Best RMSE: 2.4193714071616066\n",
      "Generation 62/100, Best RMSE: 2.419371407158535\n",
      "Generation 63/100, Best RMSE: 2.419371407157296\n",
      "Generation 64/100, Best RMSE: 2.4193714071565178\n",
      "Generation 65/100, Best RMSE: 2.4193714071563233\n",
      "Generation 66/100, Best RMSE: 2.4193714071550967\n",
      "Generation 67/100, Best RMSE: 2.419371407152291\n",
      "Generation 68/100, Best RMSE: 2.4193714071507504\n",
      "Generation 69/100, Best RMSE: 2.419371407150612\n",
      "Generation 70/100, Best RMSE: 2.419371407150253\n",
      "Generation 71/100, Best RMSE: 2.419371407150253\n",
      "Generation 72/100, Best RMSE: 2.4193714071501446\n",
      "Generation 73/100, Best RMSE: 2.4193714071496992\n",
      "Generation 74/100, Best RMSE: 2.4193714071493795\n",
      "Generation 75/100, Best RMSE: 2.4193714071493244\n",
      "Generation 76/100, Best RMSE: 2.4193714071490557\n",
      "Generation 77/100, Best RMSE: 2.419371407149024\n",
      "Generation 78/100, Best RMSE: 2.419371407148933\n",
      "Generation 79/100, Best RMSE: 2.4193714071482404\n",
      "Generation 80/100, Best RMSE: 2.4193714071480965\n",
      "Generation 81/100, Best RMSE: 2.419371407147504\n",
      "Generation 82/100, Best RMSE: 2.419371407147301\n",
      "Generation 83/100, Best RMSE: 2.419371407147089\n",
      "Generation 84/100, Best RMSE: 2.419371407146665\n",
      "Generation 85/100, Best RMSE: 2.4193714071462518\n",
      "Generation 86/100, Best RMSE: 2.419371407146168\n",
      "Generation 87/100, Best RMSE: 2.4193714071459644\n",
      "Generation 88/100, Best RMSE: 2.419371407145542\n",
      "Generation 89/100, Best RMSE: 2.419371407145392\n",
      "Generation 90/100, Best RMSE: 2.4193714071450736\n",
      "Generation 91/100, Best RMSE: 2.419371407144981\n",
      "Generation 92/100, Best RMSE: 2.419371407144981\n",
      "Generation 93/100, Best RMSE: 2.4193714071447605\n",
      "Generation 94/100, Best RMSE: 2.41937140714453\n",
      "Generation 95/100, Best RMSE: 2.4193714071443853\n",
      "Generation 96/100, Best RMSE: 2.4193714071443586\n",
      "Generation 97/100, Best RMSE: 2.4193714071441854\n",
      "Generation 98/100, Best RMSE: 2.4193714071439825\n",
      "Generation 99/100, Best RMSE: 2.4193714071439123\n",
      "Generation 100/100, Best RMSE: 2.419371407143743\n",
      "Optimal Weights: [0.56332574 0.11808843 0.08211074 0.         0.23647509]\n"
     ]
    }
   ],
   "source": [
    "# ìƒˆë¡œìš´ ë¸”ë¡: GA ì‹¤í–‰ ë° ìµœì  ê°€ì¤‘ì¹˜ ì°¾ê¸°\n",
    "input_directory = 'ga_e2'\n",
    "optimal_weights_list=[]\n",
    "for month in range(1, 13):\n",
    "    try:\n",
    "\n",
    "        model_predictions, true_values = load_and_process_validation_data(input_directory, month)\n",
    "        print(model_predictions.shape, true_values.shape)\n",
    "        if len(model_predictions) == 0 or len(true_values) == 0:\n",
    "            print(f\"{month}ì›”: ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "            continue\n",
    "\n",
    "        # GA ì‹¤í–‰í•˜ì—¬ ìµœì  ê°€ì¤‘ì¹˜ ì°¾ê¸°\n",
    "        optimal_weights = genetic_algorithm_with_elitism(\n",
    "            model_predictions, true_values, population_size=100, generations=100, mutation_rate=0.03\n",
    "        )\n",
    "        optimal_weights_list.append(optimal_weights)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"{month}ì›” ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.51842763 0.03934001 0.37414119 0.         0.06809118]\n",
      "[0.38389873 0.13705036 0.08239942 0.         0.39665149]\n",
      "[0.         0.02975621 0.31423977 0.39087923 0.26512478]\n",
      "[0. 0. 0. 1. 0.]\n",
      "[0.45259968 0.02216514 0.30682226 0.         0.21841293]\n",
      "[0.02991626 0.         0.50781986 0.         0.46226387]\n",
      "[0.11257954 0.         0.         0.30544933 0.58197113]\n",
      "[0.         0.19879487 0.05556217 0.21745841 0.52818455]\n",
      "[0.3674709  0.         0.10396985 0.         0.52855925]\n",
      "[0.64270542 0.06810121 0.         0.         0.28919337]\n",
      "[0.01527766 0.         0.         0.         0.98472234]\n",
      "[0.56332574 0.11808843 0.08211074 0.         0.23647509]\n"
     ]
    }
   ],
   "source": [
    "for i in optimal_weights_list:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_test_data(input_directory, month, models=4, time_window=48):\n",
    "    \"\"\"\n",
    "    Test ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³ , ëª¨ë¸ ì˜ˆì¸¡ê°’ê³¼ True ê°’ì„ ì¶”ì¶œí•´ ì‹œê°„ ë‹¨ìœ„ë¡œ ì´ì–´ë¶™ì´ê¸°ê¸°\n",
    "\n",
    "    Args:\n",
    "        input_directory (str): ëª¨ë¸ë³„ test ë°ì´í„°ê°€ ìˆëŠ” ë””ë ‰í† ë¦¬\n",
    "        models (int): ëª¨ë¸ ê°œìˆ˜ (default=5)\n",
    "        time_window (int): ìƒ˜í”Œë‹¹ ì‹œê°„ ì°½ (default=48)\n",
    "\n",
    "    Returns:\n",
    "        model_predictions (np.ndarray): (n_samples, models, time_window, 2)\n",
    "        true_values (np.ndarray): (n_samples, time_window, 2)\n",
    "    \"\"\"\n",
    "    model_predictions = []  # ëª¨ë¸ë³„ ì˜ˆì¸¡ê°’ ì €ì¥\n",
    "    true_values_list = []  # True U, True V ì €ì¥\n",
    "\n",
    "    for model_idx in range(1,6):\n",
    "        model_dir = os.path.join(input_directory, f\"model{model_idx}\")\n",
    "        \n",
    "        model_data_list = []\n",
    "\n",
    "        file_path = os.path.join(model_dir, f'test_month_{month}_model_{model_idx}_results.csv')\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # ëª¨ë¸ ì˜ˆì¸¡ê°’ ì¶”ì¶œ\n",
    "        pred_u = df[f\"Model {model_idx} Test Pred U\"].values\n",
    "        pred_v = df[f\"Model {model_idx} Test Pred V\"].values\n",
    "\n",
    "        # 48ì‹œê°„ ë‹¨ìœ„ë¡œ ìë¥´ê¸°\n",
    "        n_samples = len(pred_u) // time_window\n",
    "        pred_u = pred_u[:n_samples * time_window].reshape(n_samples, time_window, 1)\n",
    "        pred_v = pred_v[:n_samples * time_window].reshape(n_samples, time_window, 1)\n",
    "\n",
    "        model_data = np.concatenate([pred_u, pred_v], axis=2)  # (n_samples, 48, 2)\n",
    "        model_data_list.append(model_data)\n",
    "\n",
    "        # True Uì™€ True V ì¶”ì¶œ (ì²« ë²ˆì§¸ ëª¨ë¸ íŒŒì¼ì—ì„œë§Œ ì²˜ë¦¬)\n",
    "        if model_idx == 1:\n",
    "            true_u = df[\"True U\"].values[:n_samples * time_window].reshape(n_samples, time_window, 1)\n",
    "            true_v = df[\"True V\"].values[:n_samples * time_window].reshape(n_samples, time_window, 1)\n",
    "            true_values_sample = np.concatenate([true_u, true_v], axis=2)\n",
    "            true_values_list.append(true_values_sample)\n",
    "\n",
    "        # ëª¨ë¸ë³„ ë°ì´í„° ë³‘í•©\n",
    "        model_predictions.append(np.concatenate(model_data_list, axis=0))  # (total_samples, 48, 2)\n",
    "\n",
    "    # ëª¨ë¸ ì˜ˆì¸¡ê°’ í˜•íƒœ ë³€í™˜: (n_samples, models, 48, 2)\n",
    "    model_predictions = np.stack(model_predictions, axis=1)\n",
    "\n",
    "    # True Values ë³‘í•©: (n_samples, 48, 2)\n",
    "    true_values = np.concatenate(true_values_list, axis=0)\n",
    "\n",
    "    return model_predictions, true_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def calculate_ensemble_rmse(model_predictions, true_values, weights, output_steps):\n",
    "    \"\"\"\n",
    "    ìµœì  ê°€ì¤‘ì¹˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì•™ìƒë¸” ì˜ˆì¸¡ê°’ì„ ì €ì¥í•˜ê³  ë‚˜ì¤‘ì— RMSEë¥¼ ê³„ì‚°\n",
    "\n",
    "    Args:\n",
    "        model_predictions (np.ndarray): ëª¨ë¸ ì˜ˆì¸¡ê°’ (n_samples, models, time_window, 2)\n",
    "        true_values (np.ndarray): ì‹¤ì œ ê°’ (n_samples, time_window, 2)\n",
    "        weights (np.ndarray): ìµœì  ê°€ì¤‘ì¹˜ (models,)\n",
    "        output_steps (int): ì˜ˆì¸¡ íƒ€ì„ìŠ¤í… ìˆ˜\n",
    "\n",
    "    Returns:\n",
    "        results_dict (dict): ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ ì €ì¥ ë”•ì…”ë„ˆë¦¬\n",
    "        overall_rmse (float): ì „ì²´ í‰ê·  RMSE\n",
    "    \"\"\"\n",
    "    # ì…ë ¥ ë°ì´í„° í˜•íƒœ ê²€ì¦\n",
    "    if model_predictions.ndim != 4 or true_values.ndim != 3:\n",
    "        raise ValueError(\"ì…ë ¥ ë°ì´í„°ì˜ í˜•íƒœê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. \"\n",
    "                         \"model_predictionsëŠ” (n_samples, models, time_window, 2) í˜•íƒœì—¬ì•¼ í•˜ê³ , \"\n",
    "                         \"true_valuesëŠ” (n_samples, time_window, 2) í˜•íƒœì—¬ì•¼ í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "    n_samples, n_models, time_window, _ = model_predictions.shape\n",
    "\n",
    "    # ë””ë²„ê¹… ì¶œë ¥\n",
    "    print(f\"model_predictions.shape: {model_predictions.shape}\")\n",
    "    print(f\"true_values.shape: {true_values.shape}\")\n",
    "    print(f\"weights.shape: {weights.shape}\")\n",
    "    print(f\"weights: {weights}\")\n",
    "    print(f\"time_window: {time_window}, output_steps: {output_steps}\")\n",
    "\n",
    "    # weights í¬ê¸° ê²€ì¦\n",
    "    if len(weights) != n_models:\n",
    "        raise ValueError(f\"weights ê¸¸ì´({len(weights)})ê°€ ëª¨ë¸ ê°œìˆ˜({n_models})ì™€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    # weights í•© ê²€ì¦\n",
    "    if not np.isclose(np.sum(weights), 1.0):\n",
    "        raise ValueError(f\"weightsì˜ í•©({np.sum(weights)})ì´ 1ì´ ì•„ë‹™ë‹ˆë‹¤. ì•™ìƒë¸” ê²°ê³¼ê°€ ì™œê³¡ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    # ì•™ìƒë¸” ì˜ˆì¸¡ê°’ ê³„ì‚° (ê°€ì¤‘ì¹˜ ì ìš©)\n",
    "    ensemble_predictions = np.tensordot(model_predictions, weights, axes=(1, 0))  # (n_samples, time_window, 2)\n",
    "\n",
    "    # ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì„ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬ ì´ˆê¸°í™”\n",
    "    results_dict = {i: {'predictions': [], 'true_values': []} for i in range(time_window)}\n",
    "\n",
    "    # ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ ì €ì¥\n",
    "    # ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ ì €ì¥\n",
    "    for i in range(time_window):  # ì „ì²´ time_windowë§Œí¼ ë°˜ë³µ\n",
    "        results_dict[i]['predictions'].extend(ensemble_predictions[:, i, :].tolist())\n",
    "        results_dict[i]['true_values'].extend(true_values[:, i, :].tolist())\n",
    "\n",
    "    # ì „ì²´ RMSE ê³„ì‚°\n",
    "    all_predictions = np.concatenate(\n",
    "        [np.array(results_dict[i]['predictions']) for i in range(time_window)], axis=0\n",
    "    )\n",
    "    all_true_values = np.concatenate(\n",
    "        [np.array(results_dict[i]['true_values']) for i in range(time_window)], axis=0\n",
    "    )\n",
    "    mse = mean_squared_error(all_true_values, all_predictions, multioutput=\"uniform_average\")\n",
    "    overall_rmse = np.sqrt(mse)\n",
    "\n",
    "\n",
    "    return results_dict, round(overall_rmse, 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Predictions Shape: (28, 48, 2)\n",
      "Ensemble Predictions Shape: (28, 48, 2)\n",
      "Ensemble Predictions Shape: (31, 48, 2)\n",
      "Ensemble Predictions Shape: (30, 48, 2)\n",
      "Ensemble Predictions Shape: (27, 48, 2)\n",
      "Ensemble Predictions Shape: (24, 48, 2)\n",
      "Ensemble Predictions Shape: (16, 48, 2)\n",
      "Ensemble Predictions Shape: (16, 48, 2)\n",
      "Ensemble Predictions Shape: (27, 48, 2)\n",
      "Ensemble Predictions Shape: (31, 48, 2)\n",
      "Ensemble Predictions Shape: (24, 48, 2)\n",
      "Ensemble Predictions Shape: (25, 48, 2)\n",
      "\n",
      "ì‹œê°„ë³„ í‰ê·  RMSE:\n",
      "ì‹œê°„ 0: 1.9308347952351925\n",
      "ì‹œê°„ 1: 2.1503399695049765\n",
      "ì‹œê°„ 2: 2.347095677139922\n",
      "ì‹œê°„ 3: 2.4523212845911746\n",
      "ì‹œê°„ 4: 2.489561923998185\n",
      "ì‹œê°„ 5: 2.697231415458439\n",
      "ì‹œê°„ 6: 2.837455448676082\n",
      "ì‹œê°„ 7: 2.8396478438079833\n",
      "ì‹œê°„ 8: 2.8384387769672785\n",
      "ì‹œê°„ 9: 2.9070910378414982\n",
      "ì‹œê°„ 10: 2.8615164801799557\n",
      "ì‹œê°„ 11: 2.795142005307776\n",
      "ì‹œê°„ 12: 2.836459119208539\n",
      "ì‹œê°„ 13: 2.812351267079061\n",
      "ì‹œê°„ 14: 2.833644151841366\n",
      "ì‹œê°„ 15: 2.7713266899508295\n",
      "ì‹œê°„ 16: 2.8061837330292954\n",
      "ì‹œê°„ 17: 2.834737727195998\n",
      "ì‹œê°„ 18: 2.9207619274804837\n",
      "ì‹œê°„ 19: 2.865423438395594\n",
      "ì‹œê°„ 20: 2.821491257904729\n",
      "ì‹œê°„ 21: 2.776110563228355\n",
      "ì‹œê°„ 22: 2.893676705794238\n",
      "ì‹œê°„ 23: 2.90966871335303\n",
      "ì‹œê°„ 24: 3.0643628982036173\n",
      "ì‹œê°„ 25: 3.1981612905290047\n",
      "ì‹œê°„ 26: 3.241839074343685\n",
      "ì‹œê°„ 27: 3.229930425635844\n",
      "ì‹œê°„ 28: 3.141395750892053\n",
      "ì‹œê°„ 29: 3.219042240499517\n",
      "ì‹œê°„ 30: 3.2880385014692624\n",
      "ì‹œê°„ 31: 3.349406251740548\n",
      "ì‹œê°„ 32: 3.3628798901183234\n",
      "ì‹œê°„ 33: 3.3458303127724434\n",
      "ì‹œê°„ 34: 3.2143933872487462\n",
      "ì‹œê°„ 35: 3.0525031510380978\n",
      "ì‹œê°„ 36: 3.0523673798547275\n",
      "ì‹œê°„ 37: 2.987767876131341\n",
      "ì‹œê°„ 38: 2.933566876696476\n",
      "ì‹œê°„ 39: 2.8877406171161852\n",
      "ì‹œê°„ 40: 2.9131447537054087\n",
      "ì‹œê°„ 41: 2.947776501017461\n",
      "ì‹œê°„ 42: 3.061482898057337\n",
      "ì‹œê°„ 43: 3.0248518354782203\n",
      "ì‹œê°„ 44: 3.0312257922511976\n",
      "ì‹œê°„ 45: 3.1130231605219216\n",
      "ì‹œê°„ 46: 3.3097638577115123\n",
      "ì‹œê°„ 47: 3.3826983970973057\n",
      "\n",
      "ì „ì²´ í‰ê·  RMSE:\n",
      "ì›”ë³„ ì „ì²´ í‰ê·  RMSE: 2.962122800224259\n",
      "ê·¸ë£¹ë³„ ì „ì²´ í‰ê·  RMSE: 2.928785522360421\n"
     ]
    }
   ],
   "source": [
    "def calculate_uniform_ensemble_rmse(model_predictions, true_values):\n",
    "    n_samples, n_models, time_window, n_features = model_predictions.shape\n",
    "\n",
    "    # ë™ì¼ ê°€ì¤‘ì¹˜ ì„¤ì •\n",
    "    weights = np.array([1.0 / n_models] * n_models).reshape(1, -1, 1, 1)\n",
    "    ensemble_predictions = np.sum(model_predictions * weights, axis=1)\n",
    "\n",
    "    print(f\"Ensemble Predictions Shape: {ensemble_predictions.shape}\")\n",
    "\n",
    "    results_dict = {i: [] for i in range(time_window)}\n",
    "\n",
    "    for i in range(time_window):\n",
    "        predictions_sample = ensemble_predictions[:, i, :]\n",
    "        true_values_sample = true_values[:, i, :]\n",
    "\n",
    "        mse = mean_squared_error(true_values_sample, predictions_sample, multioutput='uniform_average')\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        results_dict[i].append(rmse)\n",
    "\n",
    "    all_predictions = ensemble_predictions.reshape(-1, n_features)\n",
    "    all_true_values = true_values.reshape(-1, n_features)\n",
    "\n",
    "    overall_mse = mean_squared_error(all_true_values, all_predictions, multioutput='uniform_average')\n",
    "    overall_rmse = np.sqrt(overall_mse)\n",
    "\n",
    "    return results_dict, overall_rmse\n",
    "\n",
    "\n",
    "def calculate_groupwise_rmse(all_results):\n",
    "    time_window = len(all_results[0])\n",
    "    average_rmse = {i: [] for i in range(time_window)}\n",
    "\n",
    "    for month_results in all_results:\n",
    "        for key, rmse_list in month_results.items():\n",
    "            average_rmse[key].extend(rmse_list)\n",
    "\n",
    "    groupwise_rmse = {key: np.mean(rmse_list) for key, rmse_list in average_rmse.items()}\n",
    "    overall_rmse = np.mean(list(groupwise_rmse.values()))\n",
    "\n",
    "    return groupwise_rmse, overall_rmse\n",
    "\n",
    "\n",
    "def main():\n",
    "    input_directory = \"./ga_e2\"\n",
    "    all_results = []\n",
    "    overall_rmse_list = []\n",
    "\n",
    "    for month in range(1, 13):\n",
    "        model_predictions, true_values = load_and_process_test_data(input_directory, month)\n",
    "        results_dict, overall_rmse = calculate_uniform_ensemble_rmse(model_predictions, true_values)\n",
    "\n",
    "        all_results.append(results_dict)\n",
    "        overall_rmse_list.append(overall_rmse)\n",
    "\n",
    "    groupwise_rmse, overall_rmse = calculate_groupwise_rmse(all_results)\n",
    "\n",
    "    print(\"\\nì‹œê°„ë³„ í‰ê·  RMSE:\")\n",
    "    for time, rmse in groupwise_rmse.items():\n",
    "        print(f\"ì‹œê°„ {time}: {rmse}\")\n",
    "\n",
    "    print(\"\\nì „ì²´ í‰ê·  RMSE:\")\n",
    "    print(f\"ì›”ë³„ ì „ì²´ í‰ê·  RMSE: {np.mean(overall_rmse_list)}\")\n",
    "    print(f\"ê·¸ë£¹ë³„ ì „ì²´ í‰ê·  RMSE: {overall_rmse}\")\n",
    "\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Predictions Shape: (28, 48, 2)\n",
      "Ensemble Predictions Shape: (28, 48, 2)\n",
      "Ensemble Predictions Shape: (31, 48, 2)\n",
      "Ensemble Predictions Shape: (30, 48, 2)\n",
      "Ensemble Predictions Shape: (27, 48, 2)\n",
      "Ensemble Predictions Shape: (24, 48, 2)\n",
      "Ensemble Predictions Shape: (16, 48, 2)\n",
      "Ensemble Predictions Shape: (16, 48, 2)\n",
      "Ensemble Predictions Shape: (27, 48, 2)\n",
      "Ensemble Predictions Shape: (31, 48, 2)\n",
      "Ensemble Predictions Shape: (24, 48, 2)\n",
      "Ensemble Predictions Shape: (25, 48, 2)\n",
      "\n",
      "ì‹œê°„ë³„ í‰ê·  RMSE:\n",
      "ì‹œê°„ 0: 1.908914416627704\n",
      "ì‹œê°„ 1: 2.1584899597522575\n",
      "ì‹œê°„ 2: 2.3767879925564808\n",
      "ì‹œê°„ 3: 2.5005901845987775\n",
      "ì‹œê°„ 4: 2.516683930915962\n",
      "ì‹œê°„ 5: 2.726301665568105\n",
      "ì‹œê°„ 6: 2.861749174238957\n",
      "ì‹œê°„ 7: 2.842491294672113\n",
      "ì‹œê°„ 8: 2.7931412841194057\n",
      "ì‹œê°„ 9: 2.8590432379168136\n",
      "ì‹œê°„ 10: 2.829547431126821\n",
      "ì‹œê°„ 11: 2.777772945234856\n",
      "ì‹œê°„ 12: 2.842217522356167\n",
      "ì‹œê°„ 13: 2.820359131996589\n",
      "ì‹œê°„ 14: 2.848363485329614\n",
      "ì‹œê°„ 15: 2.75257727220497\n",
      "ì‹œê°„ 16: 2.8001892821403875\n",
      "ì‹œê°„ 17: 2.861815149817567\n",
      "ì‹œê°„ 18: 2.9527291871678316\n",
      "ì‹œê°„ 19: 2.888670616764003\n",
      "ì‹œê°„ 20: 2.8241486141320045\n",
      "ì‹œê°„ 21: 2.7727642148449543\n",
      "ì‹œê°„ 22: 2.8759938205233078\n",
      "ì‹œê°„ 23: 2.88435093428656\n",
      "ì‹œê°„ 24: 3.0419692656502644\n",
      "ì‹œê°„ 25: 3.1659527738223967\n",
      "ì‹œê°„ 26: 3.205888987383331\n",
      "ì‹œê°„ 27: 3.2026138893852356\n",
      "ì‹œê°„ 28: 3.1218801062729113\n",
      "ì‹œê°„ 29: 3.207866780043407\n",
      "ì‹œê°„ 30: 3.2797750076115295\n",
      "ì‹œê°„ 31: 3.3308330966867037\n",
      "ì‹œê°„ 32: 3.304687641936367\n",
      "ì‹œê°„ 33: 3.28802722897989\n",
      "ì‹œê°„ 34: 3.1872158444310332\n",
      "ì‹œê°„ 35: 3.0419344615573203\n",
      "ì‹œê°„ 36: 3.0605992937548\n",
      "ì‹œê°„ 37: 2.999381677656237\n",
      "ì‹œê°„ 38: 2.9552073356644617\n",
      "ì‹œê°„ 39: 2.912891328184557\n",
      "ì‹œê°„ 40: 2.9151569071143464\n",
      "ì‹œê°„ 41: 2.959214659952803\n",
      "ì‹œê°„ 42: 3.04544747511665\n",
      "ì‹œê°„ 43: 3.0457114566144288\n",
      "ì‹œê°„ 44: 3.0581967885646875\n",
      "ì‹œê°„ 45: 3.1019729222428434\n",
      "ì‹œê°„ 46: 3.288656735389258\n",
      "ì‹œê°„ 47: 3.3645858397552293\n",
      "\n",
      "ì „ì²´ í‰ê·  RMSE:\n",
      "ì›”ë³„ ì „ì²´ í‰ê·  RMSE: 2.957734948024624\n",
      "ê·¸ë£¹ë³„ ì „ì²´ í‰ê·  RMSE: 2.9241950052638104\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# ê¸°ì¡´ optimal_weights_list ì‚¬ìš©\n",
    "def calculate_ga_ensemble_rmse(model_predictions, true_values, weights):\n",
    "    n_samples, n_models, time_window, n_features = model_predictions.shape\n",
    "\n",
    "    # GA ê¸°ë°˜ ê°€ì¤‘ì¹˜ë¥¼ ì ìš©í•œ ì•™ìƒë¸” ì˜ˆì¸¡ê°’ ê³„ì‚°\n",
    "    weights = np.array(weights).reshape(1, -1, 1, 1)\n",
    "    ensemble_predictions = np.sum(model_predictions * weights, axis=1)\n",
    "\n",
    "    print(f\"Ensemble Predictions Shape: {ensemble_predictions.shape}\")\n",
    "\n",
    "    results_dict = {i: [] for i in range(time_window)}\n",
    "\n",
    "    for i in range(time_window):\n",
    "        predictions_sample = ensemble_predictions[:, i, :]\n",
    "        true_values_sample = true_values[:, i, :]\n",
    "\n",
    "        mse = mean_squared_error(true_values_sample, predictions_sample, multioutput='uniform_average')\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        results_dict[i].append(rmse)\n",
    "\n",
    "    all_predictions = ensemble_predictions.reshape(-1, n_features)\n",
    "    all_true_values = true_values.reshape(-1, n_features)\n",
    "\n",
    "    overall_mse = mean_squared_error(all_true_values, all_predictions, multioutput='uniform_average')\n",
    "    overall_rmse = np.sqrt(overall_mse)\n",
    "\n",
    "    return results_dict, overall_rmse\n",
    "\n",
    "\n",
    "def calculate_groupwise_rmse(all_results):\n",
    "    time_window = len(all_results[0])\n",
    "    average_rmse = {i: [] for i in range(time_window)}\n",
    "\n",
    "    for month_results in all_results:\n",
    "        for key, rmse_list in month_results.items():\n",
    "            average_rmse[key].extend(rmse_list)\n",
    "\n",
    "    groupwise_rmse = {key: np.mean(rmse_list) for key, rmse_list in average_rmse.items()}\n",
    "    overall_rmse = np.mean(list(groupwise_rmse.values()))\n",
    "\n",
    "    return groupwise_rmse, overall_rmse\n",
    "\n",
    "\n",
    "def main():\n",
    "    input_directory = \"./ga_e2\"\n",
    "    all_results = []\n",
    "    overall_rmse_list = []\n",
    "\n",
    "    for month in range(1, 13):\n",
    "        model_predictions, true_values = load_and_process_test_data(input_directory, month)\n",
    "        month_weights = optimal_weights_list[month - 1]\n",
    "\n",
    "        results_dict, overall_rmse = calculate_ga_ensemble_rmse(model_predictions, true_values, month_weights)\n",
    "\n",
    "        all_results.append(results_dict)\n",
    "        overall_rmse_list.append(overall_rmse)\n",
    "\n",
    "    groupwise_rmse, overall_rmse = calculate_groupwise_rmse(all_results)\n",
    "\n",
    "    print(\"\\nì‹œê°„ë³„ í‰ê·  RMSE:\")\n",
    "    for time, rmse in groupwise_rmse.items():\n",
    "        print(f\"ì‹œê°„ {time}: {rmse}\")\n",
    "\n",
    "    print(\"\\nì „ì²´ í‰ê·  RMSE:\")\n",
    "    print(f\"ì›”ë³„ ì „ì²´ í‰ê·  RMSE: {np.mean(overall_rmse_list)}\")\n",
    "    print(f\"ê·¸ë£¹ë³„ ì „ì²´ í‰ê·  RMSE: {overall_rmse}\")\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Model Predictions Shape: (28, 48, 2)\n",
      "Selected Model Predictions Shape: (28, 48, 2)\n",
      "Selected Model Predictions Shape: (31, 48, 2)\n",
      "Selected Model Predictions Shape: (30, 48, 2)\n",
      "Selected Model Predictions Shape: (27, 48, 2)\n",
      "Selected Model Predictions Shape: (24, 48, 2)\n",
      "Selected Model Predictions Shape: (16, 48, 2)\n",
      "Selected Model Predictions Shape: (16, 48, 2)\n",
      "Selected Model Predictions Shape: (27, 48, 2)\n",
      "Selected Model Predictions Shape: (31, 48, 2)\n",
      "Selected Model Predictions Shape: (24, 48, 2)\n",
      "Selected Model Predictions Shape: (25, 48, 2)\n",
      "\n",
      "ì‹œê°„ë³„ í‰ê·  RMSE:\n",
      "ì‹œê°„ 0: 1.984331658647621\n",
      "ì‹œê°„ 1: 2.2221129423938786\n",
      "ì‹œê°„ 2: 2.4336507532445735\n",
      "ì‹œê°„ 3: 2.5562521253112425\n",
      "ì‹œê°„ 4: 2.575441727389952\n",
      "ì‹œê°„ 5: 2.8009970386971887\n",
      "ì‹œê°„ 6: 2.905611658022128\n",
      "ì‹œê°„ 7: 2.9048699122973005\n",
      "ì‹œê°„ 8: 2.869018171060301\n",
      "ì‹œê°„ 9: 2.9350392016772453\n",
      "ì‹œê°„ 10: 2.9461819449577376\n",
      "ì‹œê°„ 11: 2.8668743590699375\n",
      "ì‹œê°„ 12: 2.882881690991066\n",
      "ì‹œê°„ 13: 2.863726172037571\n",
      "ì‹œê°„ 14: 2.8613816125251894\n",
      "ì‹œê°„ 15: 2.787707456042242\n",
      "ì‹œê°„ 16: 2.8071839594062173\n",
      "ì‹œê°„ 17: 2.8666571183782916\n",
      "ì‹œê°„ 18: 2.94594243077668\n",
      "ì‹œê°„ 19: 2.883465982361764\n",
      "ì‹œê°„ 20: 2.821123001213071\n",
      "ì‹œê°„ 21: 2.77834356906316\n",
      "ì‹œê°„ 22: 2.885246012315116\n",
      "ì‹œê°„ 23: 2.930673274164791\n",
      "ì‹œê°„ 24: 3.093481723491781\n",
      "ì‹œê°„ 25: 3.227775649741654\n",
      "ì‹œê°„ 26: 3.274974222532532\n",
      "ì‹œê°„ 27: 3.218811762818356\n",
      "ì‹œê°„ 28: 3.141403223874924\n",
      "ì‹œê°„ 29: 3.2354274976327275\n",
      "ì‹œê°„ 30: 3.2962735086343895\n",
      "ì‹œê°„ 31: 3.327063106561892\n",
      "ì‹œê°„ 32: 3.302423879984222\n",
      "ì‹œê°„ 33: 3.3027033932552103\n",
      "ì‹œê°„ 34: 3.1915614221062456\n",
      "ì‹œê°„ 35: 3.055903022226328\n",
      "ì‹œê°„ 36: 3.04319352595078\n",
      "ì‹œê°„ 37: 2.971066701566657\n",
      "ì‹œê°„ 38: 2.9161106257867426\n",
      "ì‹œê°„ 39: 2.8816168260247874\n",
      "ì‹œê°„ 40: 2.865819482578644\n",
      "ì‹œê°„ 41: 2.8924833366607925\n",
      "ì‹œê°„ 42: 2.976455779560698\n",
      "ì‹œê°„ 43: 2.96210872607036\n",
      "ì‹œê°„ 44: 2.9598433740289227\n",
      "ì‹œê°„ 45: 2.9952365665543503\n",
      "ì‹œê°„ 46: 3.2207790740890787\n",
      "ì‹œê°„ 47: 3.316512063161005\n",
      "\n",
      "ì „ì²´ í‰ê·  RMSE:\n",
      "ì›”ë³„ ì „ì²´ í‰ê·  RMSE: 2.9677224219570584\n",
      "ê·¸ë£¹ë³„ ì „ì²´ í‰ê·  RMSE: 2.9371612972278616\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def calculate_model_rmse(model_predictions, true_values, model_index):\n",
    "    \"\"\"\n",
    "    íŠ¹ì • ëª¨ë¸ì˜ RMSEë¥¼ ê³„ì‚°\n",
    "    Args:\n",
    "        model_predictions: (n_samples, models, time_window, n_features) í˜•íƒœì˜ ëª¨ë¸ ì˜ˆì¸¡ê°’\n",
    "        true_values: (n_samples, time_window, n_features) í˜•íƒœì˜ ì‹¤ì œê°’\n",
    "        model_index: ê³„ì‚°í•˜ë ¤ëŠ” ëª¨ë¸ì˜ ì¸ë±ìŠ¤\n",
    "    Returns:\n",
    "        ì‹œê°„ë³„ RMSE ë”•ì…”ë„ˆë¦¬ì™€ ì „ì²´ RMSE\n",
    "    \"\"\"\n",
    "    n_samples, n_models, time_window, n_features = model_predictions.shape\n",
    "\n",
    "    # íŠ¹ì • ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ ì„ íƒ\n",
    "    selected_model_predictions = model_predictions[:, model_index, :, :]\n",
    "\n",
    "    print(f\"Selected Model Predictions Shape: {selected_model_predictions.shape}\")\n",
    "\n",
    "    results_dict = {i: [] for i in range(time_window)}\n",
    "\n",
    "    for i in range(time_window):\n",
    "        predictions_sample = selected_model_predictions[:, i, :]\n",
    "        true_values_sample = true_values[:, i, :]\n",
    "\n",
    "        mse = mean_squared_error(true_values_sample, predictions_sample, multioutput='uniform_average')\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        results_dict[i].append(rmse)\n",
    "\n",
    "    all_predictions = selected_model_predictions.reshape(-1, n_features)\n",
    "    all_true_values = true_values.reshape(-1, n_features)\n",
    "\n",
    "    overall_mse = mean_squared_error(all_true_values, all_predictions, multioutput='uniform_average')\n",
    "    overall_rmse = np.sqrt(overall_mse)\n",
    "\n",
    "    return results_dict, overall_rmse\n",
    "\n",
    "def calculate_groupwise_rmse(all_results):\n",
    "    time_window = len(all_results[0])\n",
    "    average_rmse = {i: [] for i in range(time_window)}\n",
    "\n",
    "    for month_results in all_results:\n",
    "        for key, rmse_list in month_results.items():\n",
    "            average_rmse[key].extend(rmse_list)\n",
    "\n",
    "    groupwise_rmse = {key: np.mean(rmse_list) for key, rmse_list in average_rmse.items()}\n",
    "    overall_rmse = np.mean(list(groupwise_rmse.values()))\n",
    "\n",
    "    return groupwise_rmse, overall_rmse\n",
    "\n",
    "def main():\n",
    "    input_directory = \"./ga_e2\"\n",
    "    all_results = []\n",
    "    overall_rmse_list = []\n",
    "\n",
    "    # ëª¨ë¸ ì¸ë±ìŠ¤\n",
    "    model_index = 4\n",
    "\n",
    "    for month in range(1, 13):\n",
    "        model_predictions, true_values = load_and_process_test_data(input_directory, month)\n",
    "\n",
    "        # ëª¨ë¸ 2ì˜ RMSE ê³„ì‚°\n",
    "        results_dict, overall_rmse = calculate_model_rmse(model_predictions, true_values, model_index)\n",
    "\n",
    "        all_results.append(results_dict)\n",
    "        overall_rmse_list.append(overall_rmse)\n",
    "\n",
    "    groupwise_rmse, overall_rmse = calculate_groupwise_rmse(all_results)\n",
    "\n",
    "    print(\"\\nì‹œê°„ë³„ í‰ê·  RMSE:\")\n",
    "    for time, rmse in groupwise_rmse.items():\n",
    "        print(f\"ì‹œê°„ {time}: {rmse}\")\n",
    "\n",
    "    print(\"\\nì „ì²´ í‰ê·  RMSE:\")\n",
    "    print(f\"ì›”ë³„ ì „ì²´ í‰ê·  RMSE: {np.mean(overall_rmse_list)}\")\n",
    "    print(f\"ê·¸ë£¹ë³„ ì „ì²´ í‰ê·  RMSE: {overall_rmse}\")\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GA, Uniform í‰ê· "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1ì›” ê°€ì¤‘ì¹˜: [0.5000817 0.3067802 0.        0.        0.1931381]\n",
      "model_predictions.shape: (31, 5, 48, 2)\n",
      "true_values.shape: (31, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.5000817 0.3067802 0.        0.        0.1931381]\n",
      "time_window: 48, output_steps: 2\n",
      "1ì›” ì˜ˆì¸¡ê°’: (31, 5, 48, 2), ì‹¤ì œê°’: (31, 48, 2), ê°€ì¤‘ì¹˜: [0.5000817 0.3067802 0.        0.        0.1931381]\n",
      "Ensemble Predictions Shape: (31, 48, 2)\n",
      "\n",
      "1ì›” ì „ì²´ ì•™ìƒë¸” í‰ê·  RMSE: 2.3333\n",
      "\n",
      "1ì›” ì „ì²´ Uniform ì•™ìƒë¸” í‰ê·  RMSE: 2.3300964159450963\n",
      "2ì›” ê°€ì¤‘ì¹˜: [0.29596147 0.1418722  0.16408054 0.         0.39808579]\n",
      "model_predictions.shape: (28, 5, 48, 2)\n",
      "true_values.shape: (28, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.29596147 0.1418722  0.16408054 0.         0.39808579]\n",
      "time_window: 48, output_steps: 2\n",
      "2ì›” ì˜ˆì¸¡ê°’: (28, 5, 48, 2), ì‹¤ì œê°’: (28, 48, 2), ê°€ì¤‘ì¹˜: [0.29596147 0.1418722  0.16408054 0.         0.39808579]\n",
      "Ensemble Predictions Shape: (28, 48, 2)\n",
      "\n",
      "2ì›” ì „ì²´ ì•™ìƒë¸” í‰ê·  RMSE: 2.6354\n",
      "\n",
      "2ì›” ì „ì²´ Uniform ì•™ìƒë¸” í‰ê·  RMSE: 2.664461904475412\n",
      "3ì›” ê°€ì¤‘ì¹˜: [0.35246473 0.         0.         0.25453205 0.39300322]\n",
      "model_predictions.shape: (29, 5, 48, 2)\n",
      "true_values.shape: (29, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.35246473 0.         0.         0.25453205 0.39300322]\n",
      "time_window: 48, output_steps: 2\n",
      "3ì›” ì˜ˆì¸¡ê°’: (29, 5, 48, 2), ì‹¤ì œê°’: (29, 48, 2), ê°€ì¤‘ì¹˜: [0.35246473 0.         0.         0.25453205 0.39300322]\n",
      "Ensemble Predictions Shape: (29, 48, 2)\n",
      "\n",
      "3ì›” ì „ì²´ ì•™ìƒë¸” í‰ê·  RMSE: 2.5035\n",
      "\n",
      "3ì›” ì „ì²´ Uniform ì•™ìƒë¸” í‰ê·  RMSE: 2.553024963147584\n",
      "4ì›” ê°€ì¤‘ì¹˜: [0. 0. 0. 1. 0.]\n",
      "model_predictions.shape: (29, 5, 48, 2)\n",
      "true_values.shape: (29, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0. 0. 0. 1. 0.]\n",
      "time_window: 48, output_steps: 2\n",
      "4ì›” ì˜ˆì¸¡ê°’: (29, 5, 48, 2), ì‹¤ì œê°’: (29, 48, 2), ê°€ì¤‘ì¹˜: [0. 0. 0. 1. 0.]\n",
      "Ensemble Predictions Shape: (29, 48, 2)\n",
      "\n",
      "4ì›” ì „ì²´ ì•™ìƒë¸” í‰ê·  RMSE: 4.2844\n",
      "\n",
      "4ì›” ì „ì²´ Uniform ì•™ìƒë¸” í‰ê·  RMSE: 4.117869544705043\n",
      "5ì›” ê°€ì¤‘ì¹˜: [0.51310989 0.         0.         0.03079107 0.45609904]\n",
      "model_predictions.shape: (27, 5, 48, 2)\n",
      "true_values.shape: (27, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.51310989 0.         0.         0.03079107 0.45609904]\n",
      "time_window: 48, output_steps: 2\n",
      "5ì›” ì˜ˆì¸¡ê°’: (27, 5, 48, 2), ì‹¤ì œê°’: (27, 48, 2), ê°€ì¤‘ì¹˜: [0.51310989 0.         0.         0.03079107 0.45609904]\n",
      "Ensemble Predictions Shape: (27, 48, 2)\n",
      "\n",
      "5ì›” ì „ì²´ ì•™ìƒë¸” í‰ê·  RMSE: 5.2274\n",
      "\n",
      "5ì›” ì „ì²´ Uniform ì•™ìƒë¸” í‰ê·  RMSE: 5.113014326085761\n",
      "6ì›” ê°€ì¤‘ì¹˜: [0.01769239 0.14774915 0.13385553 0.03646775 0.66423518]\n",
      "model_predictions.shape: (14, 5, 48, 2)\n",
      "true_values.shape: (14, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.01769239 0.14774915 0.13385553 0.03646775 0.66423518]\n",
      "time_window: 48, output_steps: 2\n",
      "6ì›” ì˜ˆì¸¡ê°’: (14, 5, 48, 2), ì‹¤ì œê°’: (14, 48, 2), ê°€ì¤‘ì¹˜: [0.01769239 0.14774915 0.13385553 0.03646775 0.66423518]\n",
      "Ensemble Predictions Shape: (14, 48, 2)\n",
      "\n",
      "6ì›” ì „ì²´ ì•™ìƒë¸” í‰ê·  RMSE: 2.7014\n",
      "\n",
      "6ì›” ì „ì²´ Uniform ì•™ìƒë¸” í‰ê·  RMSE: 2.8941050410873275\n",
      "7ì›” ê°€ì¤‘ì¹˜: [0.39083857 0.         0.10155258 0.37433248 0.13327637]\n",
      "model_predictions.shape: (17, 5, 48, 2)\n",
      "true_values.shape: (17, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.39083857 0.         0.10155258 0.37433248 0.13327637]\n",
      "time_window: 48, output_steps: 2\n",
      "7ì›” ì˜ˆì¸¡ê°’: (17, 5, 48, 2), ì‹¤ì œê°’: (17, 48, 2), ê°€ì¤‘ì¹˜: [0.39083857 0.         0.10155258 0.37433248 0.13327637]\n",
      "Ensemble Predictions Shape: (17, 48, 2)\n",
      "\n",
      "7ì›” ì „ì²´ ì•™ìƒë¸” í‰ê·  RMSE: 2.6119\n",
      "\n",
      "7ì›” ì „ì²´ Uniform ì•™ìƒë¸” í‰ê·  RMSE: 2.661392138759049\n",
      "8ì›” ê°€ì¤‘ì¹˜: [0.07853944 0.16892469 0.00805325 0.31325654 0.43122608]\n",
      "model_predictions.shape: (14, 5, 48, 2)\n",
      "true_values.shape: (14, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.07853944 0.16892469 0.00805325 0.31325654 0.43122608]\n",
      "time_window: 48, output_steps: 2\n",
      "8ì›” ì˜ˆì¸¡ê°’: (14, 5, 48, 2), ì‹¤ì œê°’: (14, 48, 2), ê°€ì¤‘ì¹˜: [0.07853944 0.16892469 0.00805325 0.31325654 0.43122608]\n",
      "Ensemble Predictions Shape: (14, 48, 2)\n",
      "\n",
      "8ì›” ì „ì²´ ì•™ìƒë¸” í‰ê·  RMSE: 2.4975\n",
      "\n",
      "8ì›” ì „ì²´ Uniform ì•™ìƒë¸” í‰ê·  RMSE: 2.5799959049603363\n",
      "9ì›” ê°€ì¤‘ì¹˜: [0.43920469 0.0366207  0.1641563  0.         0.36001831]\n",
      "model_predictions.shape: (21, 5, 48, 2)\n",
      "true_values.shape: (21, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.43920469 0.0366207  0.1641563  0.         0.36001831]\n",
      "time_window: 48, output_steps: 2\n",
      "9ì›” ì˜ˆì¸¡ê°’: (21, 5, 48, 2), ì‹¤ì œê°’: (21, 48, 2), ê°€ì¤‘ì¹˜: [0.43920469 0.0366207  0.1641563  0.         0.36001831]\n",
      "Ensemble Predictions Shape: (21, 48, 2)\n",
      "\n",
      "9ì›” ì „ì²´ ì•™ìƒë¸” í‰ê·  RMSE: 2.4493\n",
      "\n",
      "9ì›” ì „ì²´ Uniform ì•™ìƒë¸” í‰ê·  RMSE: 2.3279227335370365\n",
      "10ì›” ê°€ì¤‘ì¹˜: [0.62670923 0.         0.02065075 0.         0.35264002]\n",
      "model_predictions.shape: (27, 5, 48, 2)\n",
      "true_values.shape: (27, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.62670923 0.         0.02065075 0.         0.35264002]\n",
      "time_window: 48, output_steps: 2\n",
      "10ì›” ì˜ˆì¸¡ê°’: (27, 5, 48, 2), ì‹¤ì œê°’: (27, 48, 2), ê°€ì¤‘ì¹˜: [0.62670923 0.         0.02065075 0.         0.35264002]\n",
      "Ensemble Predictions Shape: (27, 48, 2)\n",
      "\n",
      "10ì›” ì „ì²´ ì•™ìƒë¸” í‰ê·  RMSE: 3.2618\n",
      "\n",
      "10ì›” ì „ì²´ Uniform ì•™ìƒë¸” í‰ê·  RMSE: 3.2344861197750676\n",
      "11ì›” ê°€ì¤‘ì¹˜: [0.4905564  0.06569518 0.         0.         0.44374842]\n",
      "model_predictions.shape: (26, 5, 48, 2)\n",
      "true_values.shape: (26, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.4905564  0.06569518 0.         0.         0.44374842]\n",
      "time_window: 48, output_steps: 2\n",
      "11ì›” ì˜ˆì¸¡ê°’: (26, 5, 48, 2), ì‹¤ì œê°’: (26, 48, 2), ê°€ì¤‘ì¹˜: [0.4905564  0.06569518 0.         0.         0.44374842]\n",
      "Ensemble Predictions Shape: (26, 48, 2)\n",
      "\n",
      "11ì›” ì „ì²´ ì•™ìƒë¸” í‰ê·  RMSE: 2.6216\n",
      "\n",
      "11ì›” ì „ì²´ Uniform ì•™ìƒë¸” í‰ê·  RMSE: 2.772242016988633\n",
      "12ì›” ê°€ì¤‘ì¹˜: [0.32626231 0.         0.         0.         0.67373769]\n",
      "model_predictions.shape: (28, 5, 48, 2)\n",
      "true_values.shape: (28, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.32626231 0.         0.         0.         0.67373769]\n",
      "time_window: 48, output_steps: 2\n",
      "12ì›” ì˜ˆì¸¡ê°’: (28, 5, 48, 2), ì‹¤ì œê°’: (28, 48, 2), ê°€ì¤‘ì¹˜: [0.32626231 0.         0.         0.         0.67373769]\n",
      "Ensemble Predictions Shape: (28, 48, 2)\n",
      "\n",
      "12ì›” ì „ì²´ ì•™ìƒë¸” í‰ê·  RMSE: 2.2347\n",
      "\n",
      "12ì›” ì „ì²´ Uniform ì•™ìƒë¸” í‰ê·  RMSE: 2.4921078193156276\n",
      "\n",
      "ì „ì²´ ì›” í‰ê·  ì•™ìƒë¸” RMSE:  2.94685\n",
      "\n",
      "ì „ì²´ ì›” í‰ê·  Uniform ì•™ìƒë¸” RMSE:  2.9783932440651646\n"
     ]
    }
   ],
   "source": [
    "overall_rmse_list = []\n",
    "uniform_overall_rmse_list = []\n",
    "\n",
    "for month in range(1, 13):  # 1ì›”ë¶€í„° 12ì›”ê¹Œì§€ ë°˜ë³µ\n",
    "    try:\n",
    "        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ë° ì²˜ë¦¬\n",
    "        model_predictions, true_values = load_and_process_test_data(input_directory, month)\n",
    "\n",
    "        # ì›”ë³„ optimal_weights í™•ì¸\n",
    "        if isinstance(optimal_weights_list, list):\n",
    "            month_weights = optimal_weights_list[month - 1]\n",
    "        else:\n",
    "            raise ValueError(\"optimal_weights_listê°€ ì›”ë³„ ê°€ì¤‘ì¹˜ë¥¼ í¬í•¨í•œ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹™ë‹ˆë‹¤.\")\n",
    "\n",
    "        print(f\"{month}ì›” ê°€ì¤‘ì¹˜: {month_weights}\")\n",
    "\n",
    "        # ì•™ìƒë¸” RMSE ê³„ì‚°\n",
    "        ensemble_rmse, overall_rmse = calculate_ensemble_rmse(model_predictions, true_values, month_weights, 2)\n",
    "        print(f\"{month}ì›” ì˜ˆì¸¡ê°’: {model_predictions.shape}, ì‹¤ì œê°’: {true_values.shape}, ê°€ì¤‘ì¹˜: {month_weights}\")\n",
    "\n",
    "        overall_rmse_list.append(overall_rmse)\n",
    "\n",
    "        # Uniform ê°€ì¤‘ì¹˜ ê³„ì‚°\n",
    "        uniform_ensemble_rmse_dict, uniform_overall_rmse = calculate_uniform_ensemble_rmse(model_predictions, true_values)\n",
    "        uniform_overall_rmse_list.append(uniform_overall_rmse)\n",
    "\n",
    "        # ê²°ê³¼ ì¶œë ¥\n",
    "        print(f\"\\n{month}ì›” ì „ì²´ ì•™ìƒë¸” í‰ê·  RMSE: {overall_rmse}\")\n",
    "        print(f\"\\n{month}ì›” ì „ì²´ Uniform ì•™ìƒë¸” í‰ê·  RMSE: {uniform_overall_rmse}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"{month}ì›” ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# ìµœì¢… í‰ê·  RMSE ì¶œë ¥\n",
    "if overall_rmse_list:\n",
    "    print(\"\\nì „ì²´ ì›” í‰ê·  ì•™ìƒë¸” RMSE: \", np.mean(overall_rmse_list))\n",
    "else:\n",
    "    print(\"\\nì•™ìƒë¸” RMSE ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "if uniform_overall_rmse_list:\n",
    "    print(\"\\nì „ì²´ ì›” í‰ê·  Uniform ì•™ìƒë¸” RMSE: \", np.mean(uniform_overall_rmse_list))\n",
    "else:\n",
    "    print(\"\\nUniform ì•™ìƒë¸” RMSE ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1ì›” ê°€ì¤‘ì¹˜: [0.5000817 0.3067802 0.        0.        0.1931381]\n",
      "1ì›” ê°œë³„ ëª¨ë¸ RMSE: [2.7992562017232707, 3.435724146217819, 2.9091694143373332, 3.1523000372899177, 2.2812916653281783]\n",
      "1ì›” ê°œë³„ ëª¨ë¸ 0~24 ì‹œê°„ í‰ê·  RMSE: [2.7113599895250564, 3.7549890097987966, 2.528991058192812, 3.03571091226746, 2.1059543190391694]\n",
      "1ì›” ê°œë³„ ëª¨ë¸ 25~47 ì‹œê°„ í‰ê·  RMSE: [2.8338674417916825, 2.9842861730224763, 3.2344797520361475, 3.263720778720573, 2.4422898468569874]\n",
      "model_predictions.shape: (31, 5, 48, 2)\n",
      "true_values.shape: (31, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.5000817 0.3067802 0.        0.        0.1931381]\n",
      "time_window: 48, output_steps: 48\n",
      "1ì›” ì˜ˆì¸¡ê°’: (31, 5, 48, 2), ì‹¤ì œê°’: (31, 48, 2), ê°€ì¤‘ì¹˜: [0.5000817 0.3067802 0.        0.        0.1931381]\n",
      "1ì›” ì•™ìƒë¸” 0~24 ì‹œê°„ í‰ê·  RMSE: 2.225072495661352\n",
      "1ì›” ì•™ìƒë¸” 25~47 ì‹œê°„ í‰ê·  RMSE: 2.412914148086691\n",
      "2ì›” ê°€ì¤‘ì¹˜: [0.29596147 0.1418722  0.16408054 0.         0.39808579]\n",
      "2ì›” ê°œë³„ ëª¨ë¸ RMSE: [3.0268099734978446, 3.099785845142844, 2.849123445790035, 3.1678682796686743, 2.721757194512857]\n",
      "2ì›” ê°œë³„ ëª¨ë¸ 0~24 ì‹œê°„ í‰ê·  RMSE: [2.9028742489818398, 2.8277906097205143, 2.628325985196125, 3.021098791798282, 2.4985661891411777]\n",
      "2ì›” ê°œë³„ ëª¨ë¸ 25~47 ì‹œê°„ í‰ê·  RMSE: [3.118568547365874, 3.3431991978036923, 3.0225549867268473, 3.3009052478569454, 2.9064260190846007]\n",
      "model_predictions.shape: (28, 5, 48, 2)\n",
      "true_values.shape: (28, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.29596147 0.1418722  0.16408054 0.         0.39808579]\n",
      "time_window: 48, output_steps: 48\n",
      "2ì›” ì˜ˆì¸¡ê°’: (28, 5, 48, 2), ì‹¤ì œê°’: (28, 48, 2), ê°€ì¤‘ì¹˜: [0.29596147 0.1418722  0.16408054 0.         0.39808579]\n",
      "2ì›” ì•™ìƒë¸” 0~24 ì‹œê°„ í‰ê·  RMSE: 2.418934759700756\n",
      "2ì›” ì•™ìƒë¸” 25~47 ì‹œê°„ í‰ê·  RMSE: 2.8173521221003206\n",
      "3ì›” ê°€ì¤‘ì¹˜: [0.35246473 0.         0.         0.25453205 0.39300322]\n",
      "3ì›” ê°œë³„ ëª¨ë¸ RMSE: [2.67642271488374, 3.5023000004897504, 2.763364444418859, 3.0782404553389857, 2.540349029085225]\n",
      "3ì›” ê°œë³„ ëª¨ë¸ 0~24 ì‹œê°„ í‰ê·  RMSE: [2.4158035145123433, 3.401225158860928, 2.412401703024746, 2.9269529892859505, 2.373126525342367]\n",
      "3ì›” ê°œë³„ ëª¨ë¸ 25~47 ì‹œê°„ í‰ê·  RMSE: [2.9028204924454677, 3.5862371469698253, 3.050572482313062, 3.217040836762408, 2.6822527494297135]\n",
      "model_predictions.shape: (29, 5, 48, 2)\n",
      "true_values.shape: (29, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.35246473 0.         0.         0.25453205 0.39300322]\n",
      "time_window: 48, output_steps: 48\n",
      "3ì›” ì˜ˆì¸¡ê°’: (29, 5, 48, 2), ì‹¤ì œê°’: (29, 48, 2), ê°€ì¤‘ì¹˜: [0.35246473 0.         0.         0.25453205 0.39300322]\n",
      "3ì›” ì•™ìƒë¸” 0~24 ì‹œê°„ í‰ê·  RMSE: 2.2965963043874655\n",
      "3ì›” ì•™ìƒë¸” 25~47 ì‹œê°„ í‰ê·  RMSE: 2.6846949406945693\n",
      "4ì›” ê°€ì¤‘ì¹˜: [0. 0. 0. 1. 0.]\n",
      "4ì›” ê°œë³„ ëª¨ë¸ RMSE: [4.250000084865319, 4.984789153268684, 4.2596671982591845, 4.28439052190512, 4.3940264615868685]\n",
      "4ì›” ê°œë³„ ëª¨ë¸ 0~24 ì‹œê°„ í‰ê·  RMSE: [3.837797397091262, 4.437174672451323, 3.9269774356581975, 4.165092116368467, 4.153054151911194]\n",
      "4ì›” ê°œë³„ ëª¨ë¸ 25~47 ì‹œê°„ í‰ê·  RMSE: [4.594165605060698, 5.492902924600419, 4.500444127106979, 4.387119978899296, 4.595316515980451]\n",
      "model_predictions.shape: (29, 5, 48, 2)\n",
      "true_values.shape: (29, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0. 0. 0. 1. 0.]\n",
      "time_window: 48, output_steps: 48\n",
      "4ì›” ì˜ˆì¸¡ê°’: (29, 5, 48, 2), ì‹¤ì œê°’: (29, 48, 2), ê°€ì¤‘ì¹˜: [0. 0. 0. 1. 0.]\n",
      "4ì›” ì•™ìƒë¸” 0~24 ì‹œê°„ í‰ê·  RMSE: 4.165092116368467\n",
      "4ì›” ì•™ìƒë¸” 25~47 ì‹œê°„ í‰ê·  RMSE: 4.387119978899296\n",
      "5ì›” ê°€ì¤‘ì¹˜: [0.51310989 0.         0.         0.03079107 0.45609904]\n",
      "5ì›” ê°œë³„ ëª¨ë¸ RMSE: [5.413165666826279, 5.8124029557369274, 5.657787431244488, 4.605612400701194, 5.354962348503337]\n",
      "5ì›” ê°œë³„ ëª¨ë¸ 0~24 ì‹œê°„ í‰ê·  RMSE: [5.015933872271337, 5.836072575097241, 5.181724393175715, 4.511973497751534, 5.031639664125183]\n",
      "5ì›” ê°œë³„ ëª¨ë¸ 25~47 ì‹œê°„ í‰ê·  RMSE: [5.76263467620908, 5.770471261534222, 6.077988577565351, 4.692982163170572, 5.655712146335214]\n",
      "model_predictions.shape: (27, 5, 48, 2)\n",
      "true_values.shape: (27, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.51310989 0.         0.         0.03079107 0.45609904]\n",
      "time_window: 48, output_steps: 48\n",
      "5ì›” ì˜ˆì¸¡ê°’: (27, 5, 48, 2), ì‹¤ì œê°’: (27, 48, 2), ê°€ì¤‘ì¹˜: [0.51310989 0.         0.         0.03079107 0.45609904]\n",
      "5ì›” ì•™ìƒë¸” 0~24 ì‹œê°„ í‰ê·  RMSE: 4.89221841022308\n",
      "5ì›” ì•™ìƒë¸” 25~47 ì‹œê°„ í‰ê·  RMSE: 5.533779997011514\n",
      "6ì›” ê°€ì¤‘ì¹˜: [0.01769239 0.14774915 0.13385553 0.03646775 0.66423518]\n",
      "6ì›” ê°œë³„ ëª¨ë¸ RMSE: [3.2081062521515094, 2.869904777461093, 3.162297001434166, 4.270121263393588, 2.7454660217007993]\n",
      "6ì›” ê°œë³„ ëª¨ë¸ 0~24 ì‹œê°„ í‰ê·  RMSE: [2.7906078555329317, 3.041320604791241, 2.5634503364857433, 4.034106049607893, 2.294300130145386]\n",
      "6ì›” ê°œë³„ ëª¨ë¸ 25~47 ì‹œê°„ í‰ê·  RMSE: [3.502627926041254, 2.634079282079703, 3.5883960139862263, 4.405837268596728, 3.0285608463886065]\n",
      "model_predictions.shape: (14, 5, 48, 2)\n",
      "true_values.shape: (14, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.01769239 0.14774915 0.13385553 0.03646775 0.66423518]\n",
      "time_window: 48, output_steps: 48\n",
      "6ì›” ì˜ˆì¸¡ê°’: (14, 5, 48, 2), ì‹¤ì œê°’: (14, 48, 2), ê°€ì¤‘ì¹˜: [0.01769239 0.14774915 0.13385553 0.03646775 0.66423518]\n",
      "6ì›” ì•™ìƒë¸” 0~24 ì‹œê°„ í‰ê·  RMSE: 2.3078684009407544\n",
      "6ì›” ì•™ìƒë¸” 25~47 ì‹œê°„ í‰ê·  RMSE: 2.961765263769052\n",
      "7ì›” ê°€ì¤‘ì¹˜: [0.39083857 0.         0.10155258 0.37433248 0.13327637]\n",
      "7ì›” ê°œë³„ ëª¨ë¸ RMSE: [2.7987040982126623, 3.3618542389373647, 2.9263531603567157, 2.7616815653738267, 2.6010533188373284]\n",
      "7ì›” ê°œë³„ ëª¨ë¸ 0~24 ì‹œê°„ í‰ê·  RMSE: [2.584823754064329, 3.4237496744711238, 2.824166894275016, 2.524085520615319, 2.3653886885986855]\n",
      "7ì›” ê°œë³„ ëª¨ë¸ 25~47 ì‹œê°„ í‰ê·  RMSE: [2.9431413534750464, 3.1892538723317094, 2.9811648529859394, 2.9577242411389366, 2.7708132540127597]\n",
      "model_predictions.shape: (17, 5, 48, 2)\n",
      "true_values.shape: (17, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.39083857 0.         0.10155258 0.37433248 0.13327637]\n",
      "time_window: 48, output_steps: 48\n",
      "7ì›” ì˜ˆì¸¡ê°’: (17, 5, 48, 2), ì‹¤ì œê°’: (17, 48, 2), ê°€ì¤‘ì¹˜: [0.39083857 0.         0.10155258 0.37433248 0.13327637]\n",
      "7ì›” ì•™ìƒë¸” 0~24 ì‹œê°„ í‰ê·  RMSE: 2.3764999872149253\n",
      "7ì›” ì•™ìƒë¸” 25~47 ì‹œê°„ í‰ê·  RMSE: 2.7892115978844254\n",
      "8ì›” ê°€ì¤‘ì¹˜: [0.07853944 0.16892469 0.00805325 0.31325654 0.43122608]\n",
      "8ì›” ê°œë³„ ëª¨ë¸ RMSE: [2.999364425489275, 3.6204624936251553, 2.679115614574365, 2.570370747753765, 2.3872125114028773]\n",
      "8ì›” ê°œë³„ ëª¨ë¸ 0~24 ì‹œê°„ í‰ê·  RMSE: [2.5501515896531517, 3.4883831516199426, 2.480750946312221, 2.504380320038937, 2.1870665827727813]\n",
      "8ì›” ê°œë³„ ëª¨ë¸ 25~47 ì‹œê°„ í‰ê·  RMSE: [3.378973066006609, 3.726056617482022, 2.858004137657886, 2.6116036386963803, 2.554050659259218]\n",
      "model_predictions.shape: (14, 5, 48, 2)\n",
      "true_values.shape: (14, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.07853944 0.16892469 0.00805325 0.31325654 0.43122608]\n",
      "time_window: 48, output_steps: 48\n",
      "8ì›” ì˜ˆì¸¡ê°’: (14, 5, 48, 2), ì‹¤ì œê°’: (14, 48, 2), ê°€ì¤‘ì¹˜: [0.07853944 0.16892469 0.00805325 0.31325654 0.43122608]\n",
      "8ì›” ì•™ìƒë¸” 0~24 ì‹œê°„ í‰ê·  RMSE: 2.294668294052284\n",
      "8ì›” ì•™ìƒë¸” 25~47 ì‹œê°„ í‰ê·  RMSE: 2.673045074143381\n",
      "9ì›” ê°€ì¤‘ì¹˜: [0.43920469 0.0366207  0.1641563  0.         0.36001831]\n",
      "9ì›” ê°œë³„ ëª¨ë¸ RMSE: [2.745202248171645, 3.0293367773907502, 2.740490928984092, 2.606448344974634, 2.463495288769133]\n",
      "9ì›” ê°œë³„ ëª¨ë¸ 0~24 ì‹œê°„ í‰ê·  RMSE: [2.5855500262028785, 2.9976661091033407, 2.914318233375241, 2.6096872393226285, 2.6276119632479165]\n",
      "9ì›” ê°œë³„ ëª¨ë¸ 25~47 ì‹œê°„ í‰ê·  RMSE: [2.7446949215424143, 3.029887887622836, 2.3727754196329154, 2.5168792415263823, 2.091365678403367]\n",
      "model_predictions.shape: (21, 5, 48, 2)\n",
      "true_values.shape: (21, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.43920469 0.0366207  0.1641563  0.         0.36001831]\n",
      "time_window: 48, output_steps: 48\n",
      "9ì›” ì˜ˆì¸¡ê°’: (21, 5, 48, 2), ì‹¤ì œê°’: (21, 48, 2), ê°€ì¤‘ì¹˜: [0.43920469 0.0366207  0.1641563  0.         0.36001831]\n",
      "9ì›” ì•™ìƒë¸” 0~24 ì‹œê°„ í‰ê·  RMSE: 2.4969982941250297\n",
      "9ì›” ì•™ìƒë¸” 25~47 ì‹œê°„ í‰ê·  RMSE: 2.2101057530111556\n",
      "10ì›” ê°€ì¤‘ì¹˜: [0.62670923 0.         0.02065075 0.         0.35264002]\n",
      "10ì›” ê°œë³„ ëª¨ë¸ RMSE: [3.474911540348785, 3.547467496076598, 3.4601939793734138, 4.176348732130302, 3.1640627115988456]\n",
      "10ì›” ê°œë³„ ëª¨ë¸ 0~24 ì‹œê°„ í‰ê·  RMSE: [3.3707558525997157, 3.2876684437155133, 3.419058436802804, 4.125972151450225, 3.0571763021484526]\n",
      "10ì›” ê°œë³„ ëª¨ë¸ 25~47 ì‹œê°„ í‰ê·  RMSE: [3.5653243261964844, 3.7697996363751813, 3.4838294540802432, 4.218212996256098, 3.254944298713493]\n",
      "model_predictions.shape: (27, 5, 48, 2)\n",
      "true_values.shape: (27, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.62670923 0.         0.02065075 0.         0.35264002]\n",
      "time_window: 48, output_steps: 48\n",
      "10ì›” ì˜ˆì¸¡ê°’: (27, 5, 48, 2), ì‹¤ì œê°’: (27, 48, 2), ê°€ì¤‘ì¹˜: [0.62670923 0.         0.02065075 0.         0.35264002]\n",
      "10ì›” ì•™ìƒë¸” 0~24 ì‹œê°„ í‰ê·  RMSE: 3.1690629330995885\n",
      "10ì›” ì•™ìƒë¸” 25~47 ì‹œê°„ í‰ê·  RMSE: 3.3414405211091567\n",
      "11ì›” ê°€ì¤‘ì¹˜: [0.4905564  0.06569518 0.         0.         0.44374842]\n",
      "11ì›” ê°œë³„ ëª¨ë¸ RMSE: [2.9195060974274845, 3.817278909241105, 2.8289493985699523, 3.7597670003996626, 2.7192305677448467]\n",
      "11ì›” ê°œë³„ ëª¨ë¸ 0~24 ì‹œê°„ í‰ê·  RMSE: [2.8332498789905483, 3.3249471749044854, 2.594768295020055, 3.6839428156512635, 2.562193946289792]\n",
      "11ì›” ê°œë³„ ëª¨ë¸ 25~47 ì‹œê°„ í‰ê·  RMSE: [2.9407033926872352, 4.250762875437241, 3.025829121155346, 3.8270843381460393, 2.8427404973724433]\n",
      "model_predictions.shape: (26, 5, 48, 2)\n",
      "true_values.shape: (26, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.4905564  0.06569518 0.         0.         0.44374842]\n",
      "time_window: 48, output_steps: 48\n",
      "11ì›” ì˜ˆì¸¡ê°’: (26, 5, 48, 2), ì‹¤ì œê°’: (26, 48, 2), ê°€ì¤‘ì¹˜: [0.4905564  0.06569518 0.         0.         0.44374842]\n",
      "11ì›” ì•™ìƒë¸” 0~24 ì‹œê°„ í‰ê·  RMSE: 2.481395596135608\n",
      "11ì›” ì•™ìƒë¸” 25~47 ì‹œê°„ í‰ê·  RMSE: 2.7105507249346017\n",
      "12ì›” ê°€ì¤‘ì¹˜: [0.32626231 0.         0.         0.         0.67373769]\n",
      "12ì›” ê°œë³„ ëª¨ë¸ RMSE: [2.612939800120858, 3.9893200089890843, 2.669654849320429, 4.350810078521139, 2.3210774997297428]\n",
      "12ì›” ê°œë³„ ëª¨ë¸ 0~24 ì‹œê°„ í‰ê·  RMSE: [2.434126469633122, 4.254766670475678, 2.5515690943759255, 4.249905316488539, 2.2605738186790685]\n",
      "12ì›” ê°œë³„ ëª¨ë¸ 25~47 ì‹œê°„ í‰ê·  RMSE: [2.763103355469809, 3.5809403598665206, 2.754721930294465, 4.434428759449746, 2.341969199121218]\n",
      "model_predictions.shape: (28, 5, 48, 2)\n",
      "true_values.shape: (28, 48, 2)\n",
      "weights.shape: (5,)\n",
      "weights: [0.32626231 0.         0.         0.         0.67373769]\n",
      "time_window: 48, output_steps: 48\n",
      "12ì›” ì˜ˆì¸¡ê°’: (28, 5, 48, 2), ì‹¤ì œê°’: (28, 48, 2), ê°€ì¤‘ì¹˜: [0.32626231 0.         0.         0.         0.67373769]\n",
      "12ì›” ì•™ìƒë¸” 0~24 ì‹œê°„ í‰ê·  RMSE: 2.1606013478259127\n",
      "12ì›” ì•™ìƒë¸” 25~47 ì‹œê°„ í‰ê·  RMSE: 2.2880979733058435\n",
      "\n",
      "ì „ì²´ ì›” í‰ê·  ì•™ìƒë¸” RMSE:  2.94685\n",
      "\n",
      "êµ¬ê°„ë³„ í‰ê·  RMSE ë¹„êµ ê²°ê³¼:\n",
      "1ì›”:\n",
      "  ëª¨ë¸ 0~24 ì‹œê°„ í‰ê·  RMSE: [2.7113599895250564, 3.7549890097987966, 2.528991058192812, 3.03571091226746, 2.1059543190391694]\n",
      "  ëª¨ë¸ 25~47 ì‹œê°„ í‰ê·  RMSE: [2.8338674417916825, 2.9842861730224763, 3.2344797520361475, 3.263720778720573, 2.4422898468569874]\n",
      "  ì•™ìƒë¸” 0~24 ì‹œê°„ í‰ê·  RMSE: 2.2251\n",
      "  ì•™ìƒë¸” 25~47 ì‹œê°„ í‰ê·  RMSE: 2.4129\n",
      "2ì›”:\n",
      "  ëª¨ë¸ 0~24 ì‹œê°„ í‰ê·  RMSE: [2.9028742489818398, 2.8277906097205143, 2.628325985196125, 3.021098791798282, 2.4985661891411777]\n",
      "  ëª¨ë¸ 25~47 ì‹œê°„ í‰ê·  RMSE: [3.118568547365874, 3.3431991978036923, 3.0225549867268473, 3.3009052478569454, 2.9064260190846007]\n",
      "  ì•™ìƒë¸” 0~24 ì‹œê°„ í‰ê·  RMSE: 2.4189\n",
      "  ì•™ìƒë¸” 25~47 ì‹œê°„ í‰ê·  RMSE: 2.8174\n",
      "3ì›”:\n",
      "  ëª¨ë¸ 0~24 ì‹œê°„ í‰ê·  RMSE: [2.4158035145123433, 3.401225158860928, 2.412401703024746, 2.9269529892859505, 2.373126525342367]\n",
      "  ëª¨ë¸ 25~47 ì‹œê°„ í‰ê·  RMSE: [2.9028204924454677, 3.5862371469698253, 3.050572482313062, 3.217040836762408, 2.6822527494297135]\n",
      "  ì•™ìƒë¸” 0~24 ì‹œê°„ í‰ê·  RMSE: 2.2966\n",
      "  ì•™ìƒë¸” 25~47 ì‹œê°„ í‰ê·  RMSE: 2.6847\n",
      "4ì›”:\n",
      "  ëª¨ë¸ 0~24 ì‹œê°„ í‰ê·  RMSE: [3.837797397091262, 4.437174672451323, 3.9269774356581975, 4.165092116368467, 4.153054151911194]\n",
      "  ëª¨ë¸ 25~47 ì‹œê°„ í‰ê·  RMSE: [4.594165605060698, 5.492902924600419, 4.500444127106979, 4.387119978899296, 4.595316515980451]\n",
      "  ì•™ìƒë¸” 0~24 ì‹œê°„ í‰ê·  RMSE: 4.1651\n",
      "  ì•™ìƒë¸” 25~47 ì‹œê°„ í‰ê·  RMSE: 4.3871\n",
      "5ì›”:\n",
      "  ëª¨ë¸ 0~24 ì‹œê°„ í‰ê·  RMSE: [5.015933872271337, 5.836072575097241, 5.181724393175715, 4.511973497751534, 5.031639664125183]\n",
      "  ëª¨ë¸ 25~47 ì‹œê°„ í‰ê·  RMSE: [5.76263467620908, 5.770471261534222, 6.077988577565351, 4.692982163170572, 5.655712146335214]\n",
      "  ì•™ìƒë¸” 0~24 ì‹œê°„ í‰ê·  RMSE: 4.8922\n",
      "  ì•™ìƒë¸” 25~47 ì‹œê°„ í‰ê·  RMSE: 5.5338\n",
      "6ì›”:\n",
      "  ëª¨ë¸ 0~24 ì‹œê°„ í‰ê·  RMSE: [2.7906078555329317, 3.041320604791241, 2.5634503364857433, 4.034106049607893, 2.294300130145386]\n",
      "  ëª¨ë¸ 25~47 ì‹œê°„ í‰ê·  RMSE: [3.502627926041254, 2.634079282079703, 3.5883960139862263, 4.405837268596728, 3.0285608463886065]\n",
      "  ì•™ìƒë¸” 0~24 ì‹œê°„ í‰ê·  RMSE: 2.3079\n",
      "  ì•™ìƒë¸” 25~47 ì‹œê°„ í‰ê·  RMSE: 2.9618\n",
      "7ì›”:\n",
      "  ëª¨ë¸ 0~24 ì‹œê°„ í‰ê·  RMSE: [2.584823754064329, 3.4237496744711238, 2.824166894275016, 2.524085520615319, 2.3653886885986855]\n",
      "  ëª¨ë¸ 25~47 ì‹œê°„ í‰ê·  RMSE: [2.9431413534750464, 3.1892538723317094, 2.9811648529859394, 2.9577242411389366, 2.7708132540127597]\n",
      "  ì•™ìƒë¸” 0~24 ì‹œê°„ í‰ê·  RMSE: 2.3765\n",
      "  ì•™ìƒë¸” 25~47 ì‹œê°„ í‰ê·  RMSE: 2.7892\n",
      "8ì›”:\n",
      "  ëª¨ë¸ 0~24 ì‹œê°„ í‰ê·  RMSE: [2.5501515896531517, 3.4883831516199426, 2.480750946312221, 2.504380320038937, 2.1870665827727813]\n",
      "  ëª¨ë¸ 25~47 ì‹œê°„ í‰ê·  RMSE: [3.378973066006609, 3.726056617482022, 2.858004137657886, 2.6116036386963803, 2.554050659259218]\n",
      "  ì•™ìƒë¸” 0~24 ì‹œê°„ í‰ê·  RMSE: 2.2947\n",
      "  ì•™ìƒë¸” 25~47 ì‹œê°„ í‰ê·  RMSE: 2.6730\n",
      "9ì›”:\n",
      "  ëª¨ë¸ 0~24 ì‹œê°„ í‰ê·  RMSE: [2.5855500262028785, 2.9976661091033407, 2.914318233375241, 2.6096872393226285, 2.6276119632479165]\n",
      "  ëª¨ë¸ 25~47 ì‹œê°„ í‰ê·  RMSE: [2.7446949215424143, 3.029887887622836, 2.3727754196329154, 2.5168792415263823, 2.091365678403367]\n",
      "  ì•™ìƒë¸” 0~24 ì‹œê°„ í‰ê·  RMSE: 2.4970\n",
      "  ì•™ìƒë¸” 25~47 ì‹œê°„ í‰ê·  RMSE: 2.2101\n",
      "10ì›”:\n",
      "  ëª¨ë¸ 0~24 ì‹œê°„ í‰ê·  RMSE: [3.3707558525997157, 3.2876684437155133, 3.419058436802804, 4.125972151450225, 3.0571763021484526]\n",
      "  ëª¨ë¸ 25~47 ì‹œê°„ í‰ê·  RMSE: [3.5653243261964844, 3.7697996363751813, 3.4838294540802432, 4.218212996256098, 3.254944298713493]\n",
      "  ì•™ìƒë¸” 0~24 ì‹œê°„ í‰ê·  RMSE: 3.1691\n",
      "  ì•™ìƒë¸” 25~47 ì‹œê°„ í‰ê·  RMSE: 3.3414\n",
      "11ì›”:\n",
      "  ëª¨ë¸ 0~24 ì‹œê°„ í‰ê·  RMSE: [2.8332498789905483, 3.3249471749044854, 2.594768295020055, 3.6839428156512635, 2.562193946289792]\n",
      "  ëª¨ë¸ 25~47 ì‹œê°„ í‰ê·  RMSE: [2.9407033926872352, 4.250762875437241, 3.025829121155346, 3.8270843381460393, 2.8427404973724433]\n",
      "  ì•™ìƒë¸” 0~24 ì‹œê°„ í‰ê·  RMSE: 2.4814\n",
      "  ì•™ìƒë¸” 25~47 ì‹œê°„ í‰ê·  RMSE: 2.7106\n",
      "12ì›”:\n",
      "  ëª¨ë¸ 0~24 ì‹œê°„ í‰ê·  RMSE: [2.434126469633122, 4.254766670475678, 2.5515690943759255, 4.249905316488539, 2.2605738186790685]\n",
      "  ëª¨ë¸ 25~47 ì‹œê°„ í‰ê·  RMSE: [2.763103355469809, 3.5809403598665206, 2.754721930294465, 4.434428759449746, 2.341969199121218]\n",
      "  ì•™ìƒë¸” 0~24 ì‹œê°„ í‰ê·  RMSE: 2.1606\n",
      "  ì•™ìƒë¸” 25~47 ì‹œê°„ í‰ê·  RMSE: 2.2881\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "overall_rmse_list = []\n",
    "uniform_overall_rmse_list = []\n",
    "individual_model_rmse = []  # ì›”ë³„ ê°œë³„ ëª¨ë¸ RMSE ì €ì¥ ë¦¬ìŠ¤íŠ¸\n",
    "timewise_model_rmse = []  # ì‹œê°„ë³„ ê°œë³„ ëª¨ë¸ RMSE ì €ì¥ ë¦¬ìŠ¤íŠ¸\n",
    "comparison_results = []  # êµ¬ê°„ë³„ í‰ê·  RMSE ë¹„êµ ê²°ê³¼ ì €ì¥ ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "for month in range(1, 13):  # 1ì›”ë¶€í„° 12ì›”ê¹Œì§€ ë°˜ë³µ\n",
    "    try:\n",
    "        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ë° ì²˜ë¦¬\n",
    "        model_predictions, true_values = load_and_process_test_data(input_directory, month)\n",
    "\n",
    "        # ì›”ë³„ optimal_weights í™•ì¸\n",
    "        if isinstance(optimal_weights_list, list):\n",
    "            month_weights = optimal_weights_list[month - 1]\n",
    "        else:\n",
    "            raise ValueError(\"optimal_weights_listê°€ ì›”ë³„ ê°€ì¤‘ì¹˜ë¥¼ í¬í•¨í•œ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹™ë‹ˆë‹¤.\")\n",
    "\n",
    "        print(f\"{month}ì›” ê°€ì¤‘ì¹˜: {month_weights}\")\n",
    "\n",
    "        # ì›”ë³„ ê°œë³„ ëª¨ë¸ RMSE ê³„ì‚°\n",
    "        n_models = model_predictions.shape[1]\n",
    "        time_window = model_predictions.shape[2]\n",
    "        monthly_model_rmse = []  # í•´ë‹¹ ì›”ì˜ ê° ëª¨ë¸ RMSE ì €ì¥\n",
    "        monthly_timewise_rmse = {t: [] for t in range(time_window)}  # ì‹œê°„ë³„ RMSE ì €ì¥\n",
    "\n",
    "        for model_idx in range(n_models):\n",
    "            model_prediction = model_predictions[:, model_idx, :, :]  # í•´ë‹¹ ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ (n_samples, time_window, 2)\n",
    "            \n",
    "            # ì›”ë³„ RMSE\n",
    "            mse = mean_squared_error(true_values.reshape(-1, 2), model_prediction.reshape(-1, 2), multioutput=\"uniform_average\")\n",
    "            rmse = np.sqrt(mse)\n",
    "            monthly_model_rmse.append(rmse)\n",
    "\n",
    "            # ì‹œê°„ë³„ RMSE\n",
    "            for t in range(time_window):\n",
    "                time_mse = mean_squared_error(true_values[:, t, :], model_prediction[:, t, :], multioutput=\"uniform_average\")\n",
    "                time_rmse = np.sqrt(time_mse)\n",
    "                monthly_timewise_rmse[t].append(time_rmse)\n",
    "\n",
    "        individual_model_rmse.append(monthly_model_rmse)\n",
    "        timewise_model_rmse.append(monthly_timewise_rmse)\n",
    "\n",
    "        print(f\"{month}ì›” ê°œë³„ ëª¨ë¸ RMSE: {monthly_model_rmse}\")\n",
    "\n",
    "        # 0~24, 25~47 ì‹œê°„ êµ¬ê°„ë³„ ê°œë³„ ëª¨ë¸ í‰ê·  RMSE ê³„ì‚°\n",
    "        avg_rmse_0_24 = [np.mean([monthly_timewise_rmse[t][model_idx] for t in range(0, 25)]) for model_idx in range(n_models)]\n",
    "        avg_rmse_25_47 = [np.mean([monthly_timewise_rmse[t][model_idx] for t in range(25, 48)]) for model_idx in range(n_models)]\n",
    "\n",
    "        print(f\"{month}ì›” ê°œë³„ ëª¨ë¸ 0~24 ì‹œê°„ í‰ê·  RMSE: {avg_rmse_0_24}\")\n",
    "        print(f\"{month}ì›” ê°œë³„ ëª¨ë¸ 25~47 ì‹œê°„ í‰ê·  RMSE: {avg_rmse_25_47}\")\n",
    "\n",
    "        # ì•™ìƒë¸” RMSE ê³„ì‚°\n",
    "        ensemble_rmse, overall_rmse = calculate_ensemble_rmse(model_predictions, true_values, month_weights, 48)\n",
    "        print(f\"{month}ì›” ì˜ˆì¸¡ê°’: {model_predictions.shape}, ì‹¤ì œê°’: {true_values.shape}, ê°€ì¤‘ì¹˜: {month_weights}\")\n",
    "\n",
    "        # 0~24, 25~47 ì‹œê°„ êµ¬ê°„ë³„ ì•™ìƒë¸” í‰ê·  RMSE ê³„ì‚°\n",
    "        ensemble_predictions = np.tensordot(model_predictions, month_weights, axes=(1, 0))  # (n_samples, time_window, 2)\n",
    "        avg_ensemble_rmse_0_24 = np.mean([\n",
    "            np.sqrt(mean_squared_error(true_values[:, t, :], ensemble_predictions[:, t, :], multioutput=\"uniform_average\"))\n",
    "            for t in range(0, 25)\n",
    "        ])\n",
    "        avg_ensemble_rmse_25_47 = np.mean([\n",
    "            np.sqrt(mean_squared_error(true_values[:, t, :], ensemble_predictions[:, t, :], multioutput=\"uniform_average\"))\n",
    "            for t in range(25, 48)\n",
    "        ])\n",
    "\n",
    "        print(f\"{month}ì›” ì•™ìƒë¸” 0~24 ì‹œê°„ í‰ê·  RMSE: {avg_ensemble_rmse_0_24}\")\n",
    "        print(f\"{month}ì›” ì•™ìƒë¸” 25~47 ì‹œê°„ í‰ê·  RMSE: {avg_ensemble_rmse_25_47}\")\n",
    "\n",
    "        # ê²°ê³¼ ë¹„êµ ì €ì¥\n",
    "        comparison_results.append({\n",
    "            \"month\": month,\n",
    "            \"model_avg_rmse_0_24\": avg_rmse_0_24,\n",
    "            \"model_avg_rmse_25_47\": avg_rmse_25_47,\n",
    "            \"ensemble_avg_rmse_0_24\": avg_ensemble_rmse_0_24,\n",
    "            \"ensemble_avg_rmse_25_47\": avg_ensemble_rmse_25_47\n",
    "        })\n",
    "\n",
    "        overall_rmse_list.append(overall_rmse)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"{month}ì›” ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# ìµœì¢… í‰ê·  RMSE ì¶œë ¥\n",
    "if overall_rmse_list:\n",
    "    print(\"\\nì „ì²´ ì›” í‰ê·  ì•™ìƒë¸” RMSE: \", np.mean(overall_rmse_list))\n",
    "else:\n",
    "    print(\"\\nì•™ìƒë¸” RMSE ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# êµ¬ê°„ë³„ ê²°ê³¼ ì¶œë ¥\n",
    "print(\"\\nêµ¬ê°„ë³„ í‰ê·  RMSE ë¹„êµ ê²°ê³¼:\")\n",
    "for result in comparison_results:\n",
    "    print(f\"{result['month']}ì›”:\")\n",
    "    print(f\"  ëª¨ë¸ 0~24 ì‹œê°„ í‰ê·  RMSE: {result['model_avg_rmse_0_24']}\")\n",
    "    print(f\"  ëª¨ë¸ 25~47 ì‹œê°„ í‰ê·  RMSE: {result['model_avg_rmse_25_47']}\")\n",
    "    print(f\"  ì•™ìƒë¸” 0~24 ì‹œê°„ í‰ê·  RMSE: {result['ensemble_avg_rmse_0_24']:.4f}\")\n",
    "    print(f\"  ì•™ìƒë¸” 25~47 ì‹œê°„ í‰ê·  RMSE: {result['ensemble_avg_rmse_25_47']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GA ê²€ì¦ ì‹¤í—˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmse(model_predictions, true_values, individual):\n",
    "    \"\"\" ì£¼ì–´ì§„ ê°œì²´ì— ëŒ€í•´ ì•™ìƒë¸” ì˜ˆì¸¡ê°’ì„ ê³„ì‚°í•˜ê³  RMSEë¥¼ ë°˜í™˜ \"\"\"\n",
    "    ensemble_prediction = np.sum([weight * model_predictions[:, i, :, :] for i, weight in enumerate(individual)], axis=0)\n",
    "    rmse = np.sqrt(np.mean((true_values - ensemble_prediction) ** 2))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genetic_algorithm_with_elitism(model_predictions, true_values, population_size=100, generations=100, mutation_rate=0.03, seed=None):\n",
    "    \"\"\"\n",
    "    GAë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœì ì˜ ê°€ì¤‘ì¹˜ ì°¾ê¸°\n",
    "    Args:\n",
    "        model_predictions: (n_samples, models, time_window, 2) í˜•íƒœì˜ ëª¨ë¸ ì˜ˆì¸¡ê°’\n",
    "        true_values: (n_samples, time_window, 2) í˜•íƒœì˜ ì‹¤ì œê°’\n",
    "        population_size: ì´ˆê¸° ê°œì²´êµ° í¬ê¸°\n",
    "        generations: ì„¸ëŒ€ ìˆ˜\n",
    "        mutation_rate: ëŒì—°ë³€ì´ í™•ë¥ \n",
    "        seed: ë‚œìˆ˜ ì‹œë“œë¥¼ ê³ ì •í•˜ê¸° ìœ„í•œ ê°’\n",
    "    Returns:\n",
    "        ìµœì  ê°€ì¤‘ì¹˜ ë°°ì—´\n",
    "    \"\"\"\n",
    "    num_models = model_predictions.shape[1]  # ëª¨ë¸ ìˆ˜\n",
    "    time_window = model_predictions.shape[2]  # ì‹œê°„ ë‹¨ìœ„\n",
    "    \n",
    "    # ì´ˆê¸° population ìƒì„±\n",
    "    population = np.random.dirichlet(np.ones(num_models), size=population_size)  # ì´ˆê¸° ê°€ì¤‘ì¹˜ ê°œì²´êµ°\n",
    "\n",
    "    for generation in range(generations):\n",
    "        fitness_scores = []\n",
    "\n",
    "        # í˜„ì¬ populationì˜ fitness (RMSE) ê³„ì‚°\n",
    "        for individual in population:\n",
    "            ensemble_prediction = np.sum(\n",
    "                [weight * model_predictions[:, i, :, :] for i, weight in enumerate(individual)],\n",
    "                axis=0\n",
    "            )\n",
    "            rmse = np.sqrt(np.mean((true_values - ensemble_prediction) ** 2))\n",
    "            fitness_scores.append(rmse)\n",
    "        \n",
    "        fitness_scores = np.array(fitness_scores)\n",
    "\n",
    "        # ìƒˆë¡œìš´ population ìƒì„±\n",
    "        new_population = []\n",
    "        while len(new_population) < population_size:\n",
    "            # ë¶€ëª¨ ì„ íƒ\n",
    "            np.random.seed(seed + generation)  # ì„¸ëŒ€ë§ˆë‹¤ ë‹¤ë¥¸ ì‹œë“œ ì ìš©\n",
    "            parent1 = roulette_wheel_selection(population, fitness_scores)\n",
    "            parent2 = roulette_wheel_selection(population, fitness_scores)\n",
    "\n",
    "            # êµì°¨ ì—°ì‚°\n",
    "            np.random.seed(seed + generation + 1)  # ì„¸ëŒ€ë§ˆë‹¤ ë‹¤ë¥¸ ì‹œë“œ ì ìš©\n",
    "            crossover_point = np.random.randint(1, num_models)\n",
    "            child = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))\n",
    "\n",
    "            # ëŒì—°ë³€ì´\n",
    "            if np.random.rand() < mutation_rate:\n",
    "                np.random.seed(seed + generation + 2)  # ì„¸ëŒ€ë§ˆë‹¤ ë‹¤ë¥¸ ì‹œë“œ ì ìš©\n",
    "                mutation_vector = np.random.normal(0, 0.1, size=num_models)\n",
    "                child = np.clip(child + mutation_vector, 0, 1)\n",
    "\n",
    "            # ì •ê·œí™”\n",
    "            child = child / np.sum(child)\n",
    "            new_population.append(child)\n",
    "        \n",
    "        new_population = np.array(new_population)\n",
    "\n",
    "        # ì—˜ë¦¬í‹°ì¦˜ ì ìš©: ìƒìœ„ 50% ê°œì²´ ì„ íƒ\n",
    "        combined_population = np.vstack((population, new_population))\n",
    "        combined_fitness = np.concatenate((fitness_scores, np.zeros(len(new_population))))\n",
    "\n",
    "        for idx, individual in enumerate(new_population):\n",
    "            ensemble_prediction = np.sum(\n",
    "                [weight * model_predictions[:, i, :, :] for i, weight in enumerate(individual)],\n",
    "                axis=0\n",
    "            )\n",
    "            combined_fitness[len(fitness_scores) + idx] = np.sqrt(np.mean((true_values - ensemble_prediction) ** 2))\n",
    "\n",
    "        sorted_indices = np.argsort(combined_fitness)\n",
    "        population = combined_population[sorted_indices][:population_size]\n",
    "\n",
    "        print(f\"Generation {generation + 1}/{generations}, Best RMSE: {combined_fitness[sorted_indices][0]}\")\n",
    "\n",
    "    # ìµœì  ê°œì²´ ë°˜í™˜\n",
    "    best_weights = population[0]\n",
    "    print(f\"Optimal Weights: {best_weights}\")\n",
    "    return best_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def run_ga_experiment(model_predictions, true_values, population_size=100, generations=100, mutation_rate=0.03, seed=None):\n",
    "    \"\"\"\n",
    "    ìœ ì „ ì•Œê³ ë¦¬ì¦˜ ì‹¤í—˜ì„ í•œ ë²ˆ ì‹¤í–‰í•˜ê³ , GA ê³„ì‚° ì‹œê°„ì„ ì¸¡ì •í•˜ì—¬ ìµœì  ê°€ì¤‘ì¹˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)  # seed ì„¤ì •\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    optimal_weights = genetic_algorithm_with_elitism(model_predictions, true_values, \n",
    "                                                     population_size=population_size, \n",
    "                                                     generations=generations, mutation_rate=mutation_rate, seed=seed)\n",
    "\n",
    "    ga_time = time.time() - start_time\n",
    "    \n",
    "    # ì•™ìƒë¸” ì˜ˆì¸¡\n",
    "    ensemble_prediction = np.sum([weight * model_predictions[:, i, :, :] for i, weight in enumerate(optimal_weights)], axis=0)\n",
    "    \n",
    "    # 3D ë°°ì—´ì„ 2D ë°°ì—´ë¡œ ë³€í™˜ (n_samples, time_window * 2)\n",
    "    ensemble_prediction_2d = ensemble_prediction.reshape(-1, ensemble_prediction.shape[1] * ensemble_prediction.shape[2])\n",
    "    true_values_2d = true_values.reshape(-1, true_values.shape[1] * true_values.shape[2])\n",
    "\n",
    "    # RMSE ê³„ì‚°\n",
    "    rmse = np.sqrt(mean_squared_error(true_values_2d, ensemble_prediction_2d))\n",
    "\n",
    "    return optimal_weights, ga_time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def calculate_ensemble_rmse2(model_predictions, true_values, weights):\n",
    "    \"\"\"\n",
    "    ìµœì  ê°€ì¤‘ì¹˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì•™ìƒë¸” RMSEë¥¼ ê³„ì‚°\n",
    "\n",
    "    Args:\n",
    "        model_predictions (np.ndarray): ëª¨ë¸ ì˜ˆì¸¡ê°’ (n_samples, models, time_window, 2)\n",
    "        true_values (np.ndarray): ì‹¤ì œ ê°’ (n_samples, time_window, 2)\n",
    "        weights (np.ndarray): ìµœì  ê°€ì¤‘ì¹˜ (models,)\n",
    "\n",
    "    Returns:\n",
    "        ensemble_rmse_dict (dict): ì‹œê°„ë³„ RMSE ë”•ì…”ë„ˆë¦¬\n",
    "        overall_rmse (float): ì „ì²´ í‰ê·  RMSE\n",
    "    \"\"\"\n",
    "    n_samples, n_models, time_window, _ = model_predictions.shape\n",
    "    \n",
    "    # ì•™ìƒë¸” ì˜ˆì¸¡ê°’ ê³„ì‚° (ê°€ì¤‘ì¹˜ ì ìš©)\n",
    "    ensemble_predictions = np.tensordot(model_predictions, weights, axes=(1, 0))  # (n_samples, time_window, 2)\n",
    "\n",
    "    # ì‹œê°„ë³„ RMSEë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬\n",
    "    ensemble_rmse_dict = {}\n",
    "    \n",
    "    for time_step in range(time_window):\n",
    "        # ì‹œê°„ë³„ ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ ì¶”ì¶œ\n",
    "        preds = ensemble_predictions[:, time_step, :]\n",
    "        trues = true_values[:, time_step, :]\n",
    "        \n",
    "        # RMSE ê³„ì‚°\n",
    "        mse = mean_squared_error(trues, preds, multioutput='uniform_average')\n",
    "        rmse = np.sqrt(mse)\n",
    "        ensemble_rmse_dict[time_step] = round(rmse, 4)\n",
    "\n",
    "    # ì „ì²´ í‰ê·  RMSE ê³„ì‚°\n",
    "    overall_rmse = np.mean(list(ensemble_rmse_dict.values()))\n",
    "\n",
    "    return round(overall_rmse, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def save_to_csv_for_seed(seed, monthly_rmse_list, monthly_ga_time_list, output_dir=\"./ga_ê²€ì¦\"):\n",
    "    \"\"\"ê° seedë³„ë¡œ CSV íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    \n",
    "    valid_months = [i for i in range(1, 12)]\n",
    "    \n",
    "    # ì›”ë³„ RMSEì™€ GA ê³„ì‚° ì‹œê°„ì„ DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "    monthly_df_rmse = pd.DataFrame({\n",
    "        'Seed': [seed],\n",
    "        **{f'Month {month} RMSE': [monthly_rmse_list[idx]] for idx, month in enumerate(valid_months)}\n",
    "    })\n",
    "    \n",
    "    monthly_df_ga_time = pd.DataFrame({\n",
    "        'Seed': [seed],\n",
    "        **{f'Month {month} GA Time': [monthly_ga_time_list[idx]] for idx, month in enumerate(valid_months)}\n",
    "    })\n",
    "    \n",
    "    # ì €ì¥í•  ë””ë ‰í† ë¦¬ ìƒì„± (ì—†ëŠ” ê²½ìš° ìƒì„±)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # ê° seedì— ëŒ€í•´ ê²°ê³¼ ì €ì¥\n",
    "    monthly_df_rmse.to_csv(f'{output_dir}/seed_{seed}_monthly_rmse.csv', index=False)\n",
    "    monthly_df_ga_time.to_csv(f'{output_dir}/seed_{seed}_monthly_ga_time.csv', index=False)\n",
    "\n",
    "    print(f\"Seed {seed}ì˜ CSV íŒŒì¼ë“¤ì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def calculate_seed_statistics(output_dir=\"./ga_ê²€ì¦\"):\n",
    "    \"\"\"30ê°œì˜ seedì— ëŒ€í•œ ì „ì²´ í†µê³„ (í‰ê· , í‘œì¤€í¸ì°¨)ë¥¼ ê³„ì‚°í•˜ì—¬ ì €ì¥í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    all_rmse_list = []\n",
    "    all_ga_time_list = []\n",
    "    \n",
    "    # ê° seedë³„ í†µê³„ ê³„ì‚°ì„ ìœ„í•œ ë¦¬ìŠ¤íŠ¸\n",
    "    seed_statistics = []\n",
    "\n",
    "    for seed in range(31):  # 0ë¶€í„° 30ê¹Œì§€ 31ë²ˆ ë°˜ë³µ ì‹¤í—˜\n",
    "        # seedë³„ë¡œ ì €ì¥ëœ CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "        monthly_df_rmse = pd.read_csv(f'{output_dir}/seed_{seed}_monthly_rmse.csv')\n",
    "        monthly_df_ga_time = pd.read_csv(f'{output_dir}/seed_{seed}_monthly_ga_time.csv')\n",
    "        \n",
    "        # ì „ì²´ RMSEì™€ GA ì‹œê°„ì˜ ê°’ë§Œ ì €ì¥ (ëª¨ë“  ì›”ì„ í•©ì¹œ í†µê³„)\n",
    "        rmse_values = monthly_df_rmse.iloc[0, 1:].values  # ì›”ë³„ RMSE\n",
    "        ga_time_values = monthly_df_ga_time.iloc[0, 1:].values  # ì›”ë³„ GA Time\n",
    "        \n",
    "        all_rmse_list.append(rmse_values)\n",
    "        all_ga_time_list.append(ga_time_values)\n",
    "        \n",
    "        # ê° seedì— ëŒ€í•œ ì „ì²´ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ ê³„ì‚°\n",
    "        seed_rmse_mean = np.mean(rmse_values)\n",
    "        seed_ga_time_mean = np.mean(ga_time_values)\n",
    "        \n",
    "        # ê° seedë³„ í†µê³„ë¥¼ ì €ì¥\n",
    "        seed_statistics.append({\n",
    "            'Seed': seed,\n",
    "            'Mean RMSE': seed_rmse_mean,\n",
    "            'Mean GA Time': seed_ga_time_mean\n",
    "        })\n",
    "    \n",
    "    # ì „ì²´ RMSEì™€ GA ì‹œê°„ì— ëŒ€í•œ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ ê³„ì‚°\n",
    "    total_rmse_mean = np.mean(all_rmse_list)\n",
    "    total_ga_time_mean = np.mean(all_ga_time_list)\n",
    "\n",
    "    # ìµœì¢… í†µê³„ DataFrame ìƒì„± (ì „ì²´ í†µê³„ + ê° seedë³„ í†µê³„)\n",
    "    final_df = pd.DataFrame({\n",
    "        'Total Mean RMSE': [total_rmse_mean],\n",
    "        'Total Mean GA Time': [total_ga_time_mean],\n",
    "    })\n",
    "\n",
    "    # ê° seedë³„ í†µê³„ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "    seed_statistics_df = pd.DataFrame(seed_statistics)\n",
    "\n",
    "    # ì €ì¥í•  ë””ë ‰í† ë¦¬ ìƒì„± (ì—†ëŠ” ê²½ìš° ìƒì„±)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # ì „ì²´ í†µê³„ ê²°ê³¼ë¥¼ CSVë¡œ ì €ì¥\n",
    "    final_df.to_csv(f'{output_dir}/final_statistics.csv', index=False)\n",
    "    # ê° seedë³„ í†µê³„ ê²°ê³¼ë¥¼ CSVë¡œ ì €ì¥\n",
    "    seed_statistics_df.to_csv(f'{output_dir}/seed_statistics.csv', index=False)\n",
    "\n",
    "    print(f\"30ê°œì˜ seedì— ëŒ€í•œ í†µê³„ íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_ga(input_directory, population_size=100, generations=100, mutation_rate=0.03, output_dir=\"./ga_ê²€ì¦\"):\n",
    "    \"\"\"GA ê°€ì¤‘ì¹˜ë¥¼ êµ¬í•˜ê³ , í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ RMSE ê³„ì‚°\"\"\"\n",
    "    overall_rmse_list = []\n",
    "    ga_time_list = []\n",
    "\n",
    "    for seed in range(31):  # 0ë¶€í„° 30ê¹Œì§€ 31ë²ˆ ë°˜ë³µ ì‹¤í—˜\n",
    "        print(f\"\\nSeed {seed}ë¡œ ì‹¤í—˜ ì‹œì‘\")\n",
    "        \n",
    "        np.random.seed(seed)  # ê° seedë§ˆë‹¤ ë‚œìˆ˜ ì´ˆê¸°í™”\n",
    "        \n",
    "        monthly_rmse_list = []  # ë§¤ `seed`ë§ˆë‹¤ ì›”ë³„ RMSE ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”\n",
    "        monthly_ga_time_list = []  # ë§¤ `seed`ë§ˆë‹¤ ì›”ë³„ GA ê³„ì‚° ì‹œê°„ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”\n",
    "\n",
    "        # 1ì›”ë¶€í„° 12ì›”ê¹Œì§€ ì›”ë³„ë¡œ ì²˜ë¦¬\n",
    "        for month in range(1, 12):\n",
    "\n",
    "            # ê²€ì¦ ë°ì´í„°ë¥¼ í†µí•´ GA ê°€ì¤‘ì¹˜ êµ¬í•˜ê¸°\n",
    "            model_predictions, true_values = load_and_process_validation_data(input_directory, month)  # ì›”ë³„ë¡œ ê²€ì¦ ë°ì´í„° ë¡œë“œ\n",
    "            optimal_weights, ga_time = run_ga_experiment(model_predictions, true_values, population_size, generations, mutation_rate, seed)\n",
    "            \n",
    "            # í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì—¬ ìµœì  ê°€ì¤‘ì¹˜ë¡œ ì˜ˆì¸¡ ë° RMSE ê³„ì‚°\n",
    "            test_predictions, test_true_values = load_and_process_test_data(input_directory, month)  # ì›”ë³„ë¡œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ\n",
    "            test_rmse = calculate_ensemble_rmse2(test_predictions, test_true_values, optimal_weights)\n",
    "\n",
    "            monthly_rmse_list.append(test_rmse)  # ì›”ë³„ RMSE ì¶”ê°€\n",
    "            monthly_ga_time_list.append(ga_time)  # GA ê³„ì‚° ì‹œê°„ë„ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "\n",
    "        # ì „ì²´ ì‹¤í—˜ ê²°ê³¼ (í•´ë‹¹ seedì— ëŒ€í•œ ê²°ê³¼)\n",
    "        overall_rmse_list.append(np.mean(monthly_rmse_list))  # ì›”ë³„ RMSE í‰ê· ê°’ì„ overallì— ì¶”ê°€\n",
    "        ga_time_list.append(np.mean(monthly_ga_time_list))  # ì›”ë³„ GA ê³„ì‚° ì‹œê°„ í‰ê· ê°’ì„ ga_time_listì— ì¶”ê°€\n",
    "\n",
    "        # í•´ë‹¹ seedì— ëŒ€í•œ ê²°ê³¼ë¥¼ CSVë¡œ ì €ì¥\n",
    "        save_to_csv_for_seed(seed, monthly_rmse_list.copy(), monthly_ga_time_list.copy(), output_dir)  # ë³µì‚¬ëœ ë¦¬ìŠ¤íŠ¸ ì „ë‹¬\n",
    "\n",
    "    # ëª¨ë“  seedì— ëŒ€í•´ í†µê³„ ê³„ì‚° í›„ CSVë¡œ ì €ì¥\n",
    "    calculate_seed_statistics(output_dir)\n",
    "\n",
    "    return overall_rmse_list, ga_time_list  # ê²°ê³¼ ë°˜í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Seed 0ë¡œ ì‹¤í—˜ ì‹œì‘\n",
      "Generation 1/100, Best RMSE: 4.761268416323186\n",
      "Generation 2/100, Best RMSE: 4.761268416323186\n",
      "Generation 3/100, Best RMSE: 4.761268416323186\n",
      "Generation 4/100, Best RMSE: 4.761268416323186\n",
      "Generation 5/100, Best RMSE: 4.761268416323186\n",
      "Generation 6/100, Best RMSE: 4.761268416323186\n",
      "Generation 7/100, Best RMSE: 4.761268416323186\n",
      "Generation 8/100, Best RMSE: 4.761268416323186\n",
      "Generation 9/100, Best RMSE: 4.761268416323186\n",
      "Generation 10/100, Best RMSE: 4.761268416323186\n",
      "Generation 11/100, Best RMSE: 4.759915358486413\n",
      "Generation 12/100, Best RMSE: 4.759915358486413\n",
      "Generation 13/100, Best RMSE: 4.759915358486413\n",
      "Generation 14/100, Best RMSE: 4.759915358486413\n",
      "Generation 15/100, Best RMSE: 4.759915358486413\n",
      "Generation 16/100, Best RMSE: 4.759915358486413\n",
      "Generation 17/100, Best RMSE: 4.759915358486413\n",
      "Generation 18/100, Best RMSE: 4.759915358486413\n",
      "Generation 19/100, Best RMSE: 4.759915358486413\n",
      "Generation 20/100, Best RMSE: 4.759915358486413\n",
      "Generation 21/100, Best RMSE: 4.759915358486413\n",
      "Generation 22/100, Best RMSE: 4.759915358486413\n",
      "Generation 23/100, Best RMSE: 4.759915358486413\n",
      "Generation 24/100, Best RMSE: 4.759915358486413\n",
      "Generation 25/100, Best RMSE: 4.759915358486413\n",
      "Generation 26/100, Best RMSE: 4.759915358486413\n",
      "Generation 27/100, Best RMSE: 4.759915358486413\n",
      "Generation 28/100, Best RMSE: 4.759915358486413\n",
      "Generation 29/100, Best RMSE: 4.759915358486413\n",
      "Generation 30/100, Best RMSE: 4.759915358486413\n",
      "Generation 31/100, Best RMSE: 4.759915358486413\n",
      "Generation 32/100, Best RMSE: 4.759915358486413\n",
      "Generation 33/100, Best RMSE: 4.759915358486413\n",
      "Generation 34/100, Best RMSE: 4.759915358486413\n",
      "Generation 35/100, Best RMSE: 4.759915358486413\n",
      "Generation 36/100, Best RMSE: 4.759915358486413\n",
      "Generation 37/100, Best RMSE: 4.759915358486413\n",
      "Generation 38/100, Best RMSE: 4.759915358486413\n",
      "Generation 39/100, Best RMSE: 4.746740253879932\n",
      "Generation 40/100, Best RMSE: 4.746740253879932\n",
      "Generation 41/100, Best RMSE: 4.746740253879932\n",
      "Generation 42/100, Best RMSE: 4.746740253879932\n",
      "Generation 43/100, Best RMSE: 4.746740253879932\n",
      "Generation 44/100, Best RMSE: 4.746740253879932\n",
      "Generation 45/100, Best RMSE: 4.746740253879932\n",
      "Generation 46/100, Best RMSE: 4.746740253879932\n",
      "Generation 47/100, Best RMSE: 4.746740253879932\n",
      "Generation 48/100, Best RMSE: 4.746740253879932\n",
      "Generation 49/100, Best RMSE: 4.746740253879932\n",
      "Generation 50/100, Best RMSE: 4.746740253879932\n",
      "Generation 51/100, Best RMSE: 4.746740253879932\n",
      "Generation 52/100, Best RMSE: 4.746740253879932\n",
      "Generation 53/100, Best RMSE: 4.746740253879932\n",
      "Generation 54/100, Best RMSE: 4.746740253879932\n",
      "Generation 55/100, Best RMSE: 4.746740253879932\n",
      "Generation 56/100, Best RMSE: 4.746740253879932\n",
      "Generation 57/100, Best RMSE: 4.746740253879932\n",
      "Generation 58/100, Best RMSE: 4.746740253879932\n",
      "Generation 59/100, Best RMSE: 4.746740253879932\n",
      "Generation 60/100, Best RMSE: 4.746740253879932\n",
      "Generation 61/100, Best RMSE: 4.746740253879932\n",
      "Generation 62/100, Best RMSE: 4.746740253879932\n",
      "Generation 63/100, Best RMSE: 4.746740253879932\n",
      "Generation 64/100, Best RMSE: 4.746740253879932\n",
      "Generation 65/100, Best RMSE: 4.746740253879932\n",
      "Generation 66/100, Best RMSE: 4.746740253879932\n",
      "Generation 67/100, Best RMSE: 4.746740253879932\n",
      "Generation 68/100, Best RMSE: 4.746740253879932\n",
      "Generation 69/100, Best RMSE: 4.746740253879932\n",
      "Generation 70/100, Best RMSE: 4.746740253879932\n",
      "Generation 71/100, Best RMSE: 4.746740253879932\n",
      "Generation 72/100, Best RMSE: 4.746740253879932\n",
      "Generation 73/100, Best RMSE: 4.746740253879932\n",
      "Generation 74/100, Best RMSE: 4.746740253879932\n",
      "Generation 75/100, Best RMSE: 4.746740253879932\n",
      "Generation 76/100, Best RMSE: 4.746740253879932\n",
      "Generation 77/100, Best RMSE: 4.746740253879932\n",
      "Generation 78/100, Best RMSE: 4.746740253879932\n",
      "Generation 79/100, Best RMSE: 4.746740253879932\n",
      "Generation 80/100, Best RMSE: 4.746740253879932\n",
      "Generation 81/100, Best RMSE: 4.746740253879932\n",
      "Generation 82/100, Best RMSE: 4.746740253879932\n",
      "Generation 83/100, Best RMSE: 4.746740253879932\n",
      "Generation 84/100, Best RMSE: 4.746740253879932\n",
      "Generation 85/100, Best RMSE: 4.746740253879932\n",
      "Generation 86/100, Best RMSE: 4.746740253879932\n",
      "Generation 87/100, Best RMSE: 4.746740253879932\n",
      "Generation 88/100, Best RMSE: 4.746740253879932\n",
      "Generation 89/100, Best RMSE: 4.746740253879932\n",
      "Generation 90/100, Best RMSE: 4.746740253879932\n",
      "Generation 91/100, Best RMSE: 4.746740253879932\n",
      "Generation 92/100, Best RMSE: 4.746740253879932\n",
      "Generation 93/100, Best RMSE: 4.746740253879932\n",
      "Generation 94/100, Best RMSE: 4.746740253879932\n",
      "Generation 95/100, Best RMSE: 4.746740253879932\n",
      "Generation 96/100, Best RMSE: 4.746740253879932\n",
      "Generation 97/100, Best RMSE: 4.746740253879932\n",
      "Generation 98/100, Best RMSE: 4.746740253879932\n",
      "Generation 99/100, Best RMSE: 4.746740253879932\n",
      "Generation 100/100, Best RMSE: 4.746740253879932\n",
      "Optimal Weights: [0.13730062 0.0167808  0.57050898 0.27540961 0.        ]\n",
      "Generation 1/100, Best RMSE: 4.552369981929663\n",
      "Generation 2/100, Best RMSE: 4.552369981929663\n",
      "Generation 3/100, Best RMSE: 4.552369981929663\n",
      "Generation 4/100, Best RMSE: 4.552369981929663\n",
      "Generation 5/100, Best RMSE: 4.552369981929663\n",
      "Generation 6/100, Best RMSE: 4.552369981929663\n",
      "Generation 7/100, Best RMSE: 4.552369981929663\n",
      "Generation 8/100, Best RMSE: 4.547885377580273\n",
      "Generation 9/100, Best RMSE: 4.547885377580273\n",
      "Generation 10/100, Best RMSE: 4.547885377580273\n",
      "Generation 11/100, Best RMSE: 4.547885377580273\n",
      "Generation 12/100, Best RMSE: 4.547885377580273\n",
      "Generation 13/100, Best RMSE: 4.547885377580273\n",
      "Generation 14/100, Best RMSE: 4.547885377580273\n",
      "Generation 15/100, Best RMSE: 4.547885377580273\n",
      "Generation 16/100, Best RMSE: 4.547885377580273\n",
      "Generation 17/100, Best RMSE: 4.547885377580273\n",
      "Generation 18/100, Best RMSE: 4.547885377580273\n",
      "Generation 19/100, Best RMSE: 4.547885377580273\n",
      "Generation 20/100, Best RMSE: 4.547885377580273\n",
      "Generation 21/100, Best RMSE: 4.547885377580273\n",
      "Generation 22/100, Best RMSE: 4.547885377580273\n",
      "Generation 23/100, Best RMSE: 4.547885377580273\n",
      "Generation 24/100, Best RMSE: 4.547885377580273\n",
      "Generation 25/100, Best RMSE: 4.547885377580273\n",
      "Generation 26/100, Best RMSE: 4.547885377580273\n",
      "Generation 27/100, Best RMSE: 4.547885377580273\n",
      "Generation 28/100, Best RMSE: 4.547885377580273\n",
      "Generation 29/100, Best RMSE: 4.547885377580273\n",
      "Generation 30/100, Best RMSE: 4.547885377580273\n",
      "Generation 31/100, Best RMSE: 4.547885377580273\n",
      "Generation 32/100, Best RMSE: 4.547885377580273\n",
      "Generation 33/100, Best RMSE: 4.547885377580273\n",
      "Generation 34/100, Best RMSE: 4.547885377580273\n",
      "Generation 35/100, Best RMSE: 4.547885377580273\n",
      "Generation 36/100, Best RMSE: 4.547885377580273\n",
      "Generation 37/100, Best RMSE: 4.547885377580273\n",
      "Generation 38/100, Best RMSE: 4.547885377580273\n",
      "Generation 39/100, Best RMSE: 4.547885377580273\n",
      "Generation 40/100, Best RMSE: 4.547885377580273\n",
      "Generation 41/100, Best RMSE: 4.547885377580273\n",
      "Generation 42/100, Best RMSE: 4.547885377580273\n",
      "Generation 43/100, Best RMSE: 4.547885377580273\n",
      "Generation 44/100, Best RMSE: 4.547885377580273\n",
      "Generation 45/100, Best RMSE: 4.547885377580273\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./ga_ê²€ì¦_w2_2\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# ì €ì¥í•  ê²½ë¡œë¥¼ ì§€ì •\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# validate_ga í•¨ìˆ˜ ì‹¤í–‰í•˜ì—¬ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m overall_rmse_list, ga_time_list, \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_ga\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpopulation_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmutation_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.03\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[31], line 19\u001b[0m, in \u001b[0;36mvalidate_ga\u001b[1;34m(input_directory, population_size, generations, mutation_rate, output_dir)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m month \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m12\u001b[39m):\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# ê²€ì¦ ë°ì´í„°ë¥¼ í†µí•´ GA ê°€ì¤‘ì¹˜ êµ¬í•˜ê¸°\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     model_predictions, true_values \u001b[38;5;241m=\u001b[39m load_and_process_validation_data(input_directory, month)  \u001b[38;5;66;03m# ì›”ë³„ë¡œ ê²€ì¦ ë°ì´í„° ë¡œë“œ\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m     optimal_weights, ga_time \u001b[38;5;241m=\u001b[39m \u001b[43mrun_ga_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpopulation_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmutation_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì—¬ ìµœì  ê°€ì¤‘ì¹˜ë¡œ ì˜ˆì¸¡ ë° RMSE ê³„ì‚°\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     test_predictions, test_true_values \u001b[38;5;241m=\u001b[39m load_and_process_test_data(input_directory, month)  \u001b[38;5;66;03m# ì›”ë³„ë¡œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[27], line 10\u001b[0m, in \u001b[0;36mrun_ga_experiment\u001b[1;34m(model_predictions, true_values, population_size, generations, mutation_rate, seed)\u001b[0m\n\u001b[0;32m      6\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(seed)  \u001b[38;5;66;03m# seed ì„¤ì •\u001b[39;00m\n\u001b[0;32m      8\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 10\u001b[0m optimal_weights \u001b[38;5;241m=\u001b[39m \u001b[43mgenetic_algorithm_with_elitism\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mpopulation_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpopulation_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mgenerations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmutation_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmutation_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m ga_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# ì•™ìƒë¸” ì˜ˆì¸¡\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[26], line 45\u001b[0m, in \u001b[0;36mgenetic_algorithm_with_elitism\u001b[1;34m(model_predictions, true_values, population_size, generations, mutation_rate, seed)\u001b[0m\n\u001b[0;32m     43\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(seed \u001b[38;5;241m+\u001b[39m generation \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# ì„¸ëŒ€ë§ˆë‹¤ ë‹¤ë¥¸ ì‹œë“œ ì ìš©\u001b[39;00m\n\u001b[0;32m     44\u001b[0m crossover_point \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1\u001b[39m, num_models)\n\u001b[1;32m---> 45\u001b[0m child \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent1\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mcrossover_point\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent2\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcrossover_point\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# ëŒì—°ë³€ì´\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand() \u001b[38;5;241m<\u001b[39m mutation_rate:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ì‹¤í—˜ì— ì‚¬ìš©í•  ì…ë ¥ ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œë¥¼ ì§€ì •\n",
    "input_directory = \"./ga_w2\"  # ë°ì´í„°ê°€ ì €ì¥ëœ ë””ë ‰í† ë¦¬ ê²½ë¡œë¡œ ìˆ˜ì •í•´ì£¼ì„¸ìš”.\n",
    "# validate_ga í•¨ìˆ˜ í˜¸ì¶œ\n",
    "# ì‹¤í–‰ í›„ íŒŒì¼ì„ ì €ì¥í•  ë””ë ‰í† ë¦¬ ì§€ì •\n",
    "output_dir = \"./ga_ê²€ì¦_w2_2\"  # ì €ì¥í•  ê²½ë¡œë¥¼ ì§€ì •\n",
    "\n",
    "# validate_ga í•¨ìˆ˜ ì‹¤í–‰í•˜ì—¬ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°\n",
    "overall_rmse_list, ga_time_list, = validate_ga(input_directory, population_size=100, generations=100, mutation_rate=0.03, output_dir=output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ìµœì¢… í‰ê·  RMSE\n",
      "ì „ì²´ ì•™ìƒë¸” í‰ê·  RMSE: 3.142510850439882\n",
      "GA í‰ê·  ê³„ì‚° ì‹œê°„: 1.362541737095002\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nìµœì¢… í‰ê·  RMSE\")\n",
    "print(f\"ì „ì²´ ì•™ìƒë¸” í‰ê·  RMSE: {np.mean(overall_rmse_list)}\")\n",
    "print(f\"GA í‰ê·  ê³„ì‚° ì‹œê°„: {np.mean(ga_time_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
